---
title: "pipeline"
output: html_document
---

# Pipeline for contemporary samples

##  Overview & variable definition

This is the pipeline for Illumina read merging and bwa mapping of modern libraries generated using the double stranded protocol. Merged and unmerged PE reads are mapped.

${i} core name of input file
In order to keep samples reasonably sorted and facilitate coding each sample has a unique prefix (this should be filename for the file filename.fastq.gz) each step in the pipeline then has a suffix.

```{r, engine=bash, eval=FALSE}
# VARIABLES:

REF=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa					
THREADS=10   # No. of computer cores used by bwa and samtools. 20 = OK, >20 = ask people first!
ARRAY=($(ls *.fastq.gz |  cut -d'_' -f1-3 | uniq)) # The array will contain the names of all the samples and we'll loop through it to process all the samples. 

# BARCODE LYNX_06_08:
# declare -A BARCODEID=(["C5RR4ACXX_7_14nf"]="c_ll_no_0075" ["C5T3DACXX_1_14nf"]="c_ll_no_0075" ["C3553ACXX_4_15nf"]="c_ll_no_0076" ["C5TMDACXX_5_15nf"]="c_ll_no_0076" ["C4592ACXX_3_16nf"]="c_ll_no_0077" ["C5TMDACXX_3_16nf"]="c_ll_no_0077" ["C3553ACXX_4_18nf"]="c_ll_no_0078" ["C5TMDACXX_1_18nf"]="c_ll_no_0078" ["C3553ACXX_4_19nf"]="c_ll_no_0079" ["C5TMDACXX_1_19nf"]="c_ll_no_0079" ["C3553ACXX_5_20nf"]="c_ll_no_0080" ["C5TMDACXX_2_20nf"]="c_ll_no_0080" ["C4592ACXX_3_21nf"]="c_ll_no_0081" ["C5TMDACXX_2_21nf"]="c_ll_no_0081" ["C3553ACXX_5_22nf"]="c_ll_no_0082" ["C5TMDACXX_3_22nf"]="c_ll_no_0082" ["C3553ACXX_5_23nf"]="c_ll_ki_0091" ["C5TMDACXX_5_23nf"]="c_ll_ki_0091" ["C3553ACXX_6_25nf"]="c_ll_ki_0092" ["C5TMDACXX_4_25nf"]="c_ll_ki_0092" ["C3553ACXX_6_27nf"]="c_ll_ki_0093" ["C5TMDACXX_4_27nf"]="c_ll_ki_0093" ["C3553ACXX_6_1nf"]="c_ll_ki_0094" ["C5T3DACXX_4_1nf"]="c_ll_ki_0094" ["C5RRAACXX_6_8nf"]="c_ll_ki_0095" ["C5RRAACXX_6_9nf"]="c_ll_ki_0096" ["C5TMDACXX_8_9nf"]="c_ll_ki_0096" ["C5TMDACXX_4_10nf"]="c_ll_ki_0097" ["C5TMUACXX_4_10nf"]="c_ll_ki_0097" ["C5TMUACXX_4_11nf"]="c_ll_ki_0098" ["C5TN1ACXX_7_11nf"]="c_ll_ki_0098" ["C5TMDACXX_8_12nf"]="c_ll_ki_0099" ["C5TMUACXX_5_12nf"]="c_ll_ki_0099" ["C5TMDACXX_8_13nf"]="c_ll_ki_0100" ["C5TMUACXX_5_13nf"]="c_ll_ki_0100" ["C5TMDACXX_7_14nf"]="c_ll_ki_0101" ["C5TMTACXX_8_14nf"]="c_ll_ki_0101" ["C5TMDACXX_7_15nf"]="c_ll_ki_0102" ["C5TMTACXX_8_15nf"]="c_ll_ki_0102" ["C5TMUACXX_2_1nf"]="c_lp_sm_0134" ["C5TN1ACXX_7_1nf"]="c_lp_sm_0134" ["C5TMUACXX_2_2nf"]="c_lp_do_0141" ["C5RRAACXX_5_3nf"]="c_lp_do_0144" ["C5T3DACXX_2_3nf"]="c_lp_do_0144" ["C5RRAACXX_5_4nf"]="c_lp_sm_0155" ["C5TMUACXX_3_5nf"]="c_lp_sm_0156" ["C5TN1ACXX_7_5nf"]="c_lp_sm_0156" ["C5TMUACXX_3_6nf"]="c_lp_sm_0161" ["C5TMTACXX_6_7nf"]="c_lp_do_0162" ["C5TN1ACXX_7_7nf"]="c_lp_do_0162" ["C5RR4ACXX_1_1nf"]="c_lp_do_0163" ["C5TN1ACXX_8_1nf"]="c_lp_do_0163" ["C5RR4ACXX_1_2nf"]="c_lp_sm_0206" ["C5TN1ACXX_8_2nf"]="c_lp_sm_0206" ["C5RR4ACXX_2_3nf"]="c_lp_sm_0208" ["C5T3DACXX_1_3nf"]="c_lp_sm_0208" ["C5RR4ACXX_2_4nf"]="c_lp_sm_0213" ["C5T3DACXX_1_4nf"]="c_lp_sm_0213" ["C5RR4ACXX_3_5nf"]="c_lp_sm_0226" ["C5T3DACXX_1_5nf"]="c_lp_sm_0226" ["C5RR4ACXX_3_6nf"]="c_lp_sm_0276" ["C5T3DACXX_1_6nf"]="c_lp_sm_0276" ["C5RR4ACXX_4_7nf"]="c_lp_do_0300" ["C5T3DACXX_2_7nf"]="c_lp_do_0300" ["C5RR4ACXX_4_8nf"]="c_lp_sm_0320" ["C5T3DACXX_1_8nf"]="c_lp_sm_0320" ["C5RR4ACXX_5_9nf"]="c_lp_sm_0325" ["C5T3DACXX_2_9nf"]="c_lp_sm_0325" ["C5RR4ACXX_5_10nf"]="c_lp_do_0333" ["C5TMDACXX_5_10nf"]="c_lp_do_0333" ["C5RR4ACXX_6_11nf"]="c_lp_do_0335" ["C5T3DACXX_2_11nf"]="c_lp_do_0335" ["C5RR4ACXX_6_12nf"]="c_lp_do_0444" ["C5T3DACXX_2_12nf"]="c_lp_do_0444" ["C5RR4ACXX_7_13nf"]="c_lp_sm_0450" ["C5T3DACXX_2_13nf"]="c_lp_sm_0450")

# BARCODE LYNX_09:
# declare -A BARCODEID=(["C6DUUANXX_2_12nf"]="c_ll_po_0001" ["C6DV6ANXX_1_12nf"]="c_ll_po_0001" ["C6DUUANXX_3_13nf"]="c_ll_po_0002" ["C6DV6ANXX_1_13nf"]="c_ll_po_0002" ["C6DUUANXX_3_14nf"]="c_ll_po_0003" ["C6DV6ANXX_1_14nf"]="c_ll_po_0003" ["C6DUUANXX_3_15nf"]="c_ll_po_0011" ["C6DV6ANXX_1_15nf"]="c_ll_po_0011" ["C6DUUANXX_2_16nf"]="c_ll_po_0014" ["C6DV6ANXX_1_16nf"]="c_ll_po_0014" ["C6DUUANXX_3_18nf"]="c_ll_po_0019" ["C6DV6ANXX_1_18nf"]="c_ll_po_0019" ["C6DUUANXX_4_19nf"]="c_ll_po_0105" ["C6DV6ANXX_1_19nf"]="c_ll_po_0105" ["C6DUUANXX_4_20nf"]="c_ll_po_0106" ["C6DV6ANXX_1_20nf"]="c_ll_po_0106" ["C6DUUANXX_2_21nf"]="c_ll_vl_0107" ["C6DV6ANXX_1_21nf"]="c_ll_vl_0107" ["C6DV6ANXX_7_5nf"]="c_ll_vl_0108" ["C6DUUANXX_2_22nf"]="c_ll_vl_0109" ["C6DUUANXX_1_23nf"]="c_ll_vl_0110" ["C6DV6ANXX_1_23nf"]="c_ll_vl_0110")

# BARCODES LYNX_PROYECT:
# declare -A BARCODEID=(["B09HCABXX_2_0"]="c_lp_do_0153" ["B09HCABXX_1_0"]="c_lp_do_0153" ["B0B5KABXX_1_0"]="c_lp_do_0153" ["B0B5KABXX_2_0"]="c_lp_do_0153" ["B09HCABXX_5_0"]="c_lp_do_0173" ["B09HCABXX_6_0"]="c_lp_do_0173" ["B0B5KABXX_6_0"]="c_lp_do_0173" ["B0B5KABXX_5_0"]="c_lp_do_0173" ["D0D6JABXX_4_0"]="c_lp_do_0443" ["D0D6JABXX_3_0"]="c_lp_do_0443" ["B0999ABXX_3_0"]="c_lp_do_0443" ["B0999ABXX_4_0"]="c_lp_do_0443" ["B09HCABXX_3_0"]="c_lp_sm_0138" ["B09HCABXX_4_0"]="c_lp_sm_0138" ["B0B5KABXX_3_0"]="c_lp_sm_0138" ["B0B5KABXX_4_0"]="c_lp_sm_0138" ["C02CHABXX_1_0"]="c_lp_sm_0140" ["C02CHABXX_2_0"]="c_lp_sm_0140" ["C02CHABXX_4_0"]="c_lp_sm_0140" ["C02CHABXX_3_0"]="c_lp_sm_0140" ["D0D6JABXX_2_0"]="c_lp_sm_0185" ["D0D6JABXX_1_0"]="c_lp_sm_0185" ["B0999ABXX_2_0"]="c_lp_sm_0185" ["B0999ABXX_1_0"]="c_lp_sm_0185" ["D0D6JABXX_5_0"]="c_lp_sm_0186" ["D0D6JABXX_6_0"]="c_lp_sm_0186" ["B0999ABXX_6_0"]="c_lp_sm_0186" ["B0999ABXX_5_0"]="c_lp_sm_0186" ["621CYAAXX_lane1_sequence_0"]="c_lp_sm_0221" ["6220RAAXX_lane1_sequence_0"]="c_lp_sm_0221" ["6220RAAXX_lane5_sequence_0"]="c_lp_sm_0221" ["6220RAAXX_lane2_sequence_0"]="c_lp_sm_0221" ["D0D6JABXX_8_0"]="c_lp_sm_0298" ["D0D6JABXX_7_0"]="c_lp_sm_0298" ["B0999ABXX_7_0"]="c_lp_sm_0298" ["B0999ABXX_8_0"]="c_lp_sm_0298" ["C02CHABXX_6_0"]="c_lp_sm_0359" ["C02CHABXX_7_0"]="c_lp_sm_0359" ["C02CHABXX_5_0"]="c_lp_sm_0359" ["C02CHABXX_8_0"]="c_lp_sm_0359" ["B09HCABXX_8_0"]="h_lp_do_0007" ["B09HCABXX_7_0"]="h_lp_do_0007" ["B0B5KABXX_7_0"]="h_lp_do_0007" ["B0B5KABXX_8_0"]="h_lp_do_0007")

# BARCODE LYNX_13:
# declare -A BARCODEID=(["C9KJ0ANXX_1_22nf"]="c_ll_vl_0113" ["CA5U3ANXX_2_22nf"]="c_ll_vl_0113" ["C9KH1ANXX_7_25nf"]="c_ll_vl_0128" ["C9KH3ANXX_8_25nf"]="c_ll_vl_0128" ["C9KJ0ANXX_2_23nf"]="c_ll_vl_0132" ["CA5U3ANXX_2_23nf"]="c_ll_vl_0132" ["C9KH1ANXX_5_21nf"]="c_ll_ya_0138" ["C9KH3ANXX_7_21nf"]="c_ll_ya_0138" ["C9KH1ANXX_5_10nf"]="c_ll_ya_0139" ["C9KH3ANXX_7_10nf"]="c_ll_ya_0139" ["C9KH1ANXX_5_11nf"]="c_ll_ya_0140" ["C9KH3ANXX_7_11nf"]="c_ll_ya_0140" ["C9KH1ANXX_5_12nf"]="c_ll_ya_0142" ["C9KH3ANXX_7_12nf"]="c_ll_ya_0142" ["C9KH1ANXX_5_15nf"]="c_ll_ya_0143" ["C9KH3ANXX_7_15nf"]="c_ll_ya_0143" ["C9KH1ANXX_7_14nf"]="c_ll_ya_0145" ["C9KH3ANXX_7_14nf"]="c_ll_ya_0145" ["C9KH1ANXX_5_13nf"]="c_ll_ya_0147" ["C9KH3ANXX_7_13nf"]="c_ll_ya_0147" ["C9KJ0ANXX_4_19nf"]="c_ll_cr_0205" ["CA5U3ANXX_2_19nf"]="c_ll_cr_0205" ["CA2W6ANXX_4_16nf"]="c_ll_cr_0206" ["CA5U3ANXX_2_16nf"]="c_ll_cr_0206" ["C9KJ0ANXX_3_20nf"]="c_ll_cr_0207" ["CA5U3ANXX_2_20nf"]="c_ll_cr_0207" ["CA2W6ANXX_4_18nf"]="c_ll_cr_0208" ["CA5U3ANXX_2_18nf"]="c_ll_cr_0208" ["C9KH1ANXX_7_27nf"]="c_ll_cr_0209" ["C9KH3ANXX_8_27nf"]="c_ll_cr_0209")

# BARCODE LYNX_14:
# declare -A BARCODEID=(["C9KH6ANXX_5_LYNX7-702ii5-4"]="h_lp_mt_0884" ["C9KN6ANXX_7_LYNX7-702ii5-4"]="h_lp_mt_0884" ["C9KNWANXX_1_LYNX7-702ii5-4"]="h_lp_mt_0884" ["C9KNWANXX_2_LYNX7-702ii5-4"]="h_lp_mt_0884" ["C9KNWANXX_3_LYNX7-702ii5-4"]="h_lp_mt_0884" ["C9KNWANXX_4_LYNX7-702ii5-4"]="h_lp_mt_0884" ["C9KNWANXX_5_LYNX7-702ii5-4"]="h_lp_mt_0884" ["C9KH6ANXX_5_LYNX7-710ii5-4"]="h_lp_mt_0885" ["C9KN6ANXX_7_LYNX7-710ii5-4"]="h_lp_mt_0885" ["C9KNWANXX_1_LYNX7-710ii5-4"]="h_lp_mt_0885" ["C9KNWANXX_2_LYNX7-710ii5-4"]="h_lp_mt_0885" ["C9KNWANXX_3_LYNX7-710ii5-4"]="h_lp_mt_0885" ["C9KNWANXX_4_LYNX7-710ii5-4"]="h_lp_mt_0885" ["C9KNWANXX_5_LYNX7-710ii5-4"]="h_lp_mt_0885" ["C9KH6ANXX_5_LYNX7-625ii5-2"]="h_lp_mt_0976" ["C9KN6ANXX_7_LYNX7-625ii5-2"]="h_lp_mt_0976" ["C9KNWANXX_1_LYNX7-625ii5-2"]="h_lp_mt_0976" ["C9KNWANXX_2_LYNX7-625ii5-2"]="h_lp_mt_0976" ["C9KNWANXX_3_LYNX7-625ii5-2"]="h_lp_mt_0976" ["C9KNWANXX_4_LYNX7-625ii5-2"]="h_lp_mt_0976" ["C9KNWANXX_5_LYNX7-625ii5-2"]="h_lp_mt_0976" ["C9KH6ANXX_5_LYNX7-709ii5-4"]="h_lp_mt_0978" ["C9KN6ANXX_7_LYNX7-709ii5-4"]="h_lp_mt_0978" ["C9KNWANXX_1_LYNX7-709ii5-4"]="h_lp_mt_0978" ["C9KNWANXX_2_LYNX7-709ii5-4"]="h_lp_mt_0978" ["C9KNWANXX_3_LYNX7-709ii5-4"]="h_lp_mt_0978" ["C9KNWANXX_4_LYNX7-709ii5-4"]="h_lp_mt_0978" ["C9KNWANXX_5_LYNX7-709ii5-4"]="h_lp_mt_0978" ["C9KH6ANXX_5_LYNX7-604ii5-2"]="h_lp_mt_0979" ["C9KN6ANXX_7_LYNX7-604ii5-2"]="h_lp_mt_0979" ["C9KNWANXX_1_LYNX7-604ii5-2"]="h_lp_mt_0979" ["C9KNWANXX_2_LYNX7-604ii5-2"]="h_lp_mt_0979" ["C9KNWANXX_3_LYNX7-604ii5-2"]="h_lp_mt_0979" ["C9KNWANXX_4_LYNX7-604ii5-2"]="h_lp_mt_0979" ["C9KNWANXX_5_LYNX7-604ii5-2"]="h_lp_mt_0979" ["C9KH6ANXX_5_LYNX7-706ii5-4"]="h_lp_mt_1025" ["C9KN6ANXX_7_LYNX7-706ii5-4"]="h_lp_mt_1025" ["C9KNWANXX_1_LYNX7-706ii5-4"]="h_lp_mt_1025" ["C9KNWANXX_2_LYNX7-706ii5-4"]="h_lp_mt_1025" ["C9KNWANXX_3_LYNX7-706ii5-4"]="h_lp_mt_1025" ["C9KNWANXX_4_LYNX7-706ii5-4"]="h_lp_mt_1025" ["C9KNWANXX_5_LYNX7-706ii5-4"]="h_lp_mt_1025" ["CA3D2ANXX_3_LYNX7-706ii5-4"]="h_lp_mt_1025" ["C9KH6ANXX_5_LYNX7-687ii5-4"]="h_lp_mt_1087" ["C9KN6ANXX_7_LYNX7-687ii5-4"]="h_lp_mt_1087" ["C9KNWANXX_1_LYNX7-687ii5-4"]="h_lp_mt_1087" ["C9KNWANXX_2_LYNX7-687ii5-4"]="h_lp_mt_1087" ["C9KNWANXX_3_LYNX7-687ii5-4"]="h_lp_mt_1087" ["C9KNWANXX_4_LYNX7-687ii5-4"]="h_lp_mt_1087" ["C9KNWANXX_5_LYNX7-687ii5-4"]="h_lp_mt_1087" ["CA3D2ANXX_3_LYNX7-687ii5-4"]="h_lp_mt_1087" ["C9KH6ANXX_5_LYNX7-700ii5-4"]="h_lp_mt_1117" ["C9KN6ANXX_7_LYNX7-700ii5-4"]="h_lp_mt_1117" ["C9KNWANXX_1_LYNX7-700ii5-4"]="h_lp_mt_1117" ["C9KNWANXX_2_LYNX7-700ii5-4"]="h_lp_mt_1117" ["C9KNWANXX_3_LYNX7-700ii5-4"]="h_lp_mt_1117" ["C9KNWANXX_4_LYNX7-700ii5-4"]="h_lp_mt_1117" ["C9KNWANXX_5_LYNX7-700ii5-4"]="h_lp_mt_1117" ["CA3D2ANXX_3_LYNX7-700ii5-4"]="h_lp_mt_1117" ["C9KH6ANXX_5_LYNX7-693ii5-4"]="h_lp_mt_1141" ["C9KN6ANXX_7_LYNX7-693ii5-4"]="h_lp_mt_1141" ["C9KNWANXX_1_LYNX7-693ii5-4"]="h_lp_mt_1141" ["C9KNWANXX_2_LYNX7-693ii5-4"]="h_lp_mt_1141" ["C9KNWANXX_3_LYNX7-693ii5-4"]="h_lp_mt_1141" ["C9KNWANXX_4_LYNX7-693ii5-4"]="h_lp_mt_1141" ["C9KNWANXX_5_LYNX7-693ii5-4"]="h_lp_mt_1141" ["CA3D2ANXX_3_LYNX7-693ii5-4"]="h_lp_mt_1141" ["C9KH6ANXX_5_LYNX7-686ii5-4"]="h_lp_mt_1272" ["C9KN6ANXX_7_LYNX7-686ii5-4"]="h_lp_mt_1272" ["C9KNWANXX_1_LYNX7-686ii5-4"]="h_lp_mt_1272" ["C9KNWANXX_2_LYNX7-686ii5-4"]="h_lp_mt_1272" ["C9KNWANXX_3_LYNX7-686ii5-4"]="h_lp_mt_1272" ["C9KNWANXX_4_LYNX7-686ii5-4"]="h_lp_mt_1272" ["C9KNWANXX_5_LYNX7-686ii5-4"]="h_lp_mt_1272" ["C9KH6ANXX_5_LYNX7-695ii5-4"]="h_lp_mt_1295" ["C9KN6ANXX_7_LYNX7-695ii5-4"]="h_lp_mt_1295" ["C9KNWANXX_1_LYNX7-695ii5-4"]="h_lp_mt_1295" ["C9KNWANXX_2_LYNX7-695ii5-4"]="h_lp_mt_1295" ["C9KNWANXX_3_LYNX7-695ii5-4"]="h_lp_mt_1295" ["C9KNWANXX_4_LYNX7-695ii5-4"]="h_lp_mt_1295" ["C9KNWANXX_5_LYNX7-695ii5-4"]="h_lp_mt_1295" ["C9KH6ANXX_5_LYNX7-708ii5-4"]="h_lp_mt_1305" ["C9KN6ANXX_7_LYNX7-708ii5-4"]="h_lp_mt_1305" ["C9KNWANXX_1_LYNX7-708ii5-4"]="h_lp_mt_1305" ["C9KNWANXX_2_LYNX7-708ii5-4"]="h_lp_mt_1305" ["C9KNWANXX_3_LYNX7-708ii5-4"]="h_lp_mt_1305" ["C9KNWANXX_4_LYNX7-708ii5-4"]="h_lp_mt_1305" ["C9KNWANXX_5_LYNX7-708ii5-4"]="h_lp_mt_1305" ["CA3D2ANXX_3_LYNX7-708ii5-4"]="h_lp_mt_1305")

# BARCODE NEW_CANDILES (6 samples that I added lately):
# declare -A BARCODEID=(["6220RAAXX_lane3_sequence_0"]="c_lp_sm_0221" ["6220RAAXX_lane4_sequence_0"]="c_lp_sm_0221" ["6220RAAXX_lane6_sequence_0"]="c_lp_sm_0221" ["6220RAAXX_lane7_sequence_0"]="c_lp_sm_0221" ["6220RAAXX_lane8_sequence_0"]="c_lp_sm_0221" ["62AHEAAXX_lane1_sequence_0"]="c_lp_sm_0221")

# BARCODE LYNX_15:
# declare -A BARCODEID=(["C9KH1ANXX_7_1nf"]="c_ll_to_0191" ["C9KH1ANXX_7_7nf"]="c_ll_la_0053" ["C9KH1ANXX_7_10nf"]="c_ll_la_0054" ["C9KH1ANXX_8_11nf"]="c_ll_la_0044" ["C9KH1ANXX_8_12nf"]="c_ll_tu_0157" ["C9KH1ANXX_8_13nf"]="c_ll_tu_0158" ["C9KH1ANXX_8_14nf"]="c_ll_tu_0159" ["C9KH1ANXX_8_15nf"]="c_ll_tu_0165" ["C9KH1ANXX_8_18nf"]="c_ll_tu_0166" ["C9KH1ANXX_8_19nf"]="c_ll_tu_0153" ["C9KH3ANXX_7_1nf"]="c_ll_to_0191" ["C9KH3ANXX_8_7nf"]="c_ll_la_0053" ["C9KH3ANXX_8_10nf"]="c_ll_la_0054" ["C9KH3ANXX_8_11nf"]="c_ll_la_0044" ["C9KH3ANXX_8_12nf"]="c_ll_tu_0157" ["C9KH3ANXX_8_13nf"]="c_ll_tu_0158" ["CA2W6ANXX_1_1nf"]="c_ll_og_0181" ["CA2W6ANXX_1_2nf"]="c_ll_og_0187" ["CA2W6ANXX_1_3nf"]="c_ll_ka_0184" ["CA2W6ANXX_1_4nf"]="c_ll_ka_0186" ["CA2W6ANXX_2_5nf"]="c_ll_ka_0189" ["CA2W6ANXX_2_7nf"]="c_ll_to_0190" ["CA2W6ANXX_2_8nf"]="c_ll_la_0047" ["CA2W6ANXX_4_6nf"]="c_ll_ka_0188" ["CA3D2ANXX_5_1nf"]="c_ll_og_0181" ["CA3D2ANXX_5_2nf"]="c_ll_og_0187" ["CA3D2ANXX_5_3nf"]="c_ll_ka_0184" ["CA3D2ANXX_5_4nf"]="c_ll_ka_0186" ["CA3D2ANXX_5_5nf"]="c_ll_ka_0189" ["CA3D2ANXX_5_6nf"]="c_ll_ka_0188" ["CA3D2ANXX_6_7nf"]="c_ll_to_0190" ["CA3D2ANXX_6_8nf"]="c_ll_la_0047" ["CA3D2ANXX_6_9nf"]="c_ll_la_0048" ["CA3D2ANXX_6_21nf"]="c_ll_la_0052" ["CAABGANXX_5_14nf"]="c_ll_tu_0159" ["CAABGANXX_5_15nf"]="c_ll_tu_0165" ["CAABGANXX_5_18nf"]="c_ll_tu_0166" ["CAABGANXX_5_19nf"]="c_ll_tu_0153" ["CAABGANXX_5_9nf"]="c_ll_la_0048" ["CAABGANXX_5_21nf"]="c_ll_la_0052")

# BARCODE LYNX_16:
# declare -A BARCODEID=(["CA2W6ANXX_4_23nf"]="h_ll_ba_0214" ["CA2W6ANXX_4_25nf"]="c_ll_ba_0216" ["CA2W6ANXX_4_27nf"]="h_ll_ba_0215" ["CA3D2ANXX_6_23nf"]="h_ll_ba_0214" ["CA3D2ANXX_6_25nf"]="c_ll_ba_0216" ["CA3D2ANXX_6_27nf"]="h_ll_ba_0215")


```

## 	FastQC: quality summary of raw data 

```{r, engine=bash, eval=FALSE}

for i in ${ARRAY[@]}
do
echo "${i}"
fastqc ${i}_1.fastq.gz  # -a adapters.txt
done

for i in ${ARRAY[@]}
do
echo "${i}"
fastqc ${i}_2.fastq.gz  # -a adapters.txt
done

```

## 	Trimming

Trim adapter seqs and merge overlapping R1 and R2. 
To decide whether to trim or not, check fastQC files. 

Nosotro sólo trimamos para LYNX_14

LYNX_06 y LYNX_08_09 venían trimados. No los hemos trimado. 
LYNX_13, LYNX_15 y LYNX_16 también venían trimados. 
Los del proyecto genómca concluimos que no merece la pena trimarlos, porque aunque tienen adaptadores la proporción es muy poca, y el tiempo de computación es mucho. 

```{r, engine=bash, eval=FALSE}

for i in ${ARRAY[@]}
do

echo "${i}"
SeqPrep -f "${i}"_1.fastq.gz -r "${i}"_2.fastq.gz -1 "${i}"_R1_trimmed.fastq.gz -2 "${i}"_R2_trimmed.fastq.gz -A AGATCGGAAGAGCACACGTC -B AGATCGGAAGAGCGTCGTGT
done   

```

##	FastQC: quality summary of trimmed data 

Only if you have trimmed. 

```{r, engine=bash, eval=FALSE}

for i in ${ARRAY[@]}
do
fastqc "${i}"_R1_trimmed.fastq.gz   # -a adapters.txt;
done

for i in ${ARRAY[@]}
do
fastqc "${i}"_R2_trimmed.fastq.gz   # -a adapters.txt;	
done

```

## 	Aligment BWA-MEM	

Checked whether you are using trimmed or untrimmed data.

```{r, engine=bash, eval=FALSE}

bwa mem $REF ${i}_1.fastq.gz ${i}_2.fastq.gz -t $THREADS  >  ${i}.sam
samtools view -hbS  ${i}.sam -@ $THREADS | samtools sort -@ $THREADS -o ${i}_sorted.bam
rm ${i}.sam
samtools flagstat  ${i}_sorted.bam >  ${i}_raw.stats

# Para los de LYNX_14: Lanzado!
# bwa mem $REF ${i}_R1_trimmed.fastq.gz ${i}_R2_trimmed.fastq.gz -t $THREADS  >  ${i}.sam
# samtools view -hbS  ${i}.sam -@ $THREADS | samtools sort -@ $THREADS -o ${i}_sorted.bam && rm ${i}.sam

```

## 	Adding read groups

```{r, engine=bash, eval=FALSE}

run=($(echo $i | cut -d"_" -f 1))  #Sacar el run de i

java -jar /opt/picard-tools/picard.jar AddOrReplaceReadGroups I=${i}_sorted.bam O=${BARCODEID["${i}"]}_${i}_sorted_rg.bam RGID=${i} RGLB=${BARCODEID["${i}"]}_lib RGPL=Illumina RGPU=${run} RGSM=${BARCODEID["${i}"]} VALIDATION_STRINGENCY=SILENT \
&& rm ${i}_sorted.bam

done

```

## 	Merge BAM	

```{r, engine=bash, eval=FALSE}

SAMPLESLIST=($(echo ${BARCODEID[@]} | tr ' ' '\n' | sort | uniq | tr ' ' '\n'))

for sample in "${SAMPLESLIST[@]}"
do
echo "${sample}"
ls ./"${sample}"_*_sorted_rg.bam  > "${sample}".bam.list
echo;echo
echo `wc -l "${sample}".bam.list`;
lines=`wc -l "${sample}".bam.list | cut -f 1 -d " " `
if [ "$lines" -eq "1" ]; 
then echo "ONE";
cp `cat "${sample}".bam.list`  "${sample}".bam;
fi
if [ "$lines" -gt "1" ]; 
then echo "more than ONE";
samtools merge -r  "${sample}".bam `cat "${sample}".bam.list`;
fi
samtools flagstat "${sample}".bam >  "${sample}".stats;
samtools sort -@ 30 "${sample}".bam -o "${sample}"_sorted.bam;
done

```


## 	Remove duplicates	

```{r, engine=bash, eval=FALSE}

ARRAY_MERGED_BAM_SAMPLE_NAME=($(ls *_sorted.bam |  cut -d'_' -f1,2,3,4 | uniq))

for i in ${ARRAY_MERGED_BAM_SAMPLE_NAME[@]}
do
echo "${i}"
java -jar /opt/picard-tools/picard.jar MarkDuplicates METRICS_FILE=${i}_rmdup.txt I=${i}_sorted.bam O=${i}_sorted_rmdup.bam MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=2000 
samtools sort ${i}_sorted_rmdup.bam -@ 30 -o ${i}_sorted_rmdup_sorted.bam
samtools index ${i}_sorted_rmdup_sorted.bam
samtools flagstat ${i}_sorted_rmdup_sorted.bam > ${i}_sorted_rmdup_sorted.stats

done

```

## 	Realignment with GATK	

Requirement:
Coordinate-sorted and indexed BAM alignment data
This two-step indel realignment process:
A) first identifies such regions where alignments may potentially be improved 
B) then realigns the reads in these regions using a consensus model that takes all reads in the alignment context together.


```{r, engine=bash, eval=FALSE}

for i in ${ARRAY_MERGED_BAM_SAMPLE_NAME[@]}
do
echo "${i}"
# RealignerTargetCreator
java -jar /home/tmp/Software/GATK_3.4/GenomeAnalysisTK.jar -T RealignerTargetCreator -nt 24 -R $REF -I ${i}_sorted_rmdup_sorted.bam -o ${i}_realignertargetcreator.intervals
# IndelRealigner
java -jar /home/tmp/Software/GATK_3.4/GenomeAnalysisTK.jar -T IndelRealigner -R $REF -targetIntervals ${i}_realignertargetcreator.intervals -I ${i}_sorted_rmdup_sorted.bam -o ${i}_sorted_rmdup_sorted_indelrealigner.bam
done
```

##  Move all the samples to a common folder	  

```{r, engine=bash, eval=FALSE}

mv /home/GRUPOS/grupolince/lynx_genomes_5x/raw_data/LYNX_09/*bam /home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files
mv /home/GRUPOS/grupolince/lynx_genomes_5x/raw_data/LYNX_09/*stas /home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files
mv /home/GRUPOS/grupolince/lynx_genomes_5x/raw_data/LYNX_06_08/*bam /home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files
mv /home/GRUPOS/grupolince/lynx_genomes_5x/raw_data/LYNX_06_08/*stats /home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files

# Remove also intermediated files. 
```

## 	Recalibration with GATK	

The base recalibration process involves two key steps: 
A) first the program builds a model of covariation based on the data and a set of known variants (which you can bootstrap if there is none available for your organism) 
B) then it adjusts the base quality scores in the data based on the model. 

### SNP calling

```{r, engine=bash, eval=FALSE}
# Define new variables

POP=("cr")
ROUND=1
PREVIOUS_ROUND=$(expr $ROUND - 1)

for pop in ${POP[@]}
do
echo "${pop}"
if [ "$ROUND" -eq "1" ];
then
ls *_${pop}_*.bam | grep -v "recal" | cut -d' ' -f9 >  "${pop}"_round-"$ROUND".bam.list;
fi
if [ "$ROUND" -gt "1" ];
then
ls *_${pop}*recal_round-"$PREVIOUS_ROUND".bam | cut -d' ' -f9 > "${pop}"_round-"$ROUND".bam.list;
fi
number_id=$(printf "%03d" `wc -l  "${pop}"_round-"$ROUND".bam.list | tr -s ' ' | cut -d ' ' -f1`); # He cambiado el -f2 por -f1 porque si no los de macrogen no corrian, comprobar que siguen biuen
echo "${number_id}";
mv  "${pop}"_round-"$ROUND".bam.list  "${pop}"_round-"$ROUND"_n"$number_id".bam.list;
INPUT_BAMS_FOR_CALLING="${pop}"_round-"$ROUND"_n"$number_id".bam.list;
java  -XX:MaxMetaspaceSize=1g -XX:+UseG1GC  -XX:+UseStringDeduplication -Xms64g  -Xmx64g -jar /home/tmp/Software/GATK_3.4/GenomeAnalysisTK.jar -T HaplotypeCaller -nct 8 -R $REF -I $INPUT_BAMS_FOR_CALLING --genotyping_mode DISCOVERY -stand_emit_conf 10 -stand_call_conf 30 -o "${pop}"_n"$number_id"_raw_round-"$ROUND".vcf
/opt/vcflib/bin/vcffilter -f "QD > 2 & MQ > 40 & FS < 100 " "${pop}"_n"$number_id"_raw_round-"$ROUND".vcf > "${pop}"_n"$number_id"_raw_round-"$ROUND"_filtered.vcf
done

```

### Recalibration 

```{r, engine=bash, eval=FALSE}

REF=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa
POP=("mt")
ROUND=1
PREVIOUS_ROUND=$(expr $ROUND - 1)

for pop in ${POP[@]}
do
echo "${pop}"
# esto de number_id si corro todo junto está repetido:
number_id=$(printf "%03d" `wc -l  "${pop}"_round-"$ROUND"*.bam.list | tr -s ' ' | cut -d ' ' -f1`); # He cambiado el -f2 por -f1 porque si no los de macrogen no corrian, comprobar que siguen biuen
INPUT_BAMS_FOR_RECALIBRATING=($(cat "${pop}"_round-1_n*.bam.list))  # He cambiado el nombre del archivo porque corriendo los de macrogen me he dado cuenta de que estaban mal
echo $number_id
for id in ${INPUT_BAMS_FOR_RECALIBRATING[@]}
do
echo $id
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC  -XX:+UseStringDeduplication -Xms10g  -Xmx64g -jar /home/tmp/Software/GATK_3.4/GenomeAnalysisTK.jar   -T BaseRecalibrator -R $REF -I ${id} -knownSites "${pop}"_n"$number_id"_raw_round-"$ROUND"_filtered.vcf -o ${id/_sorted_rmdup_sorted_indelrealigner.bam/_recal_data_round-"$ROUND".table}
java -jar /home/tmp/Software/GATK_3.4/GenomeAnalysisTK.jar -T PrintReads -R $REF -I ${id} -BQSR ${id/_sorted_rmdup_sorted_indelrealigner.bam/_recal_data_round-"$ROUND".table} -o ${id/_sorted_rmdup_sorted_indelrealigner.bam/_recal_round-"$ROUND".bam}

# Be sure that you have install and running in R the following packages:
# R: library("ggplot2"), library("gplots"), library("reshape"), library("grid"), library("tools"), library("gsalib")

if [ "$ROUND" -eq "1" ]; 
then
echo "AnalyzeCovariates  round ""$ROUND" " sample ""${id}"
java -jar /home/tmp/Software/GATK_3.4/GenomeAnalysisTK.jar -T AnalyzeCovariates -R $REF -BQSR ${id/_sorted_rmdup_sorted_indelrealigner.bam/_recal_data_round-1.table} -plots ${id/_sorted_rmdup_sorted_indelrealigner.bam/_BQSR_round-1.pdf}
fi
if [ "$ROUND" -eq "2" ]; 
then
java -jar GenomeAnalysisTK.jar -T AnalyzeCovariates -R $REF -before ${id/_sorted_rmdup_sorted_indelrealigner.bam/_recal_data_round-1.table} -after ${id/_sorted_rmdup_sorted_indelrealigner.bam/_recal_data_round-2.table} -csv ${id/_sorted_rmdup_sorted_indelrealigner.bam/BQSR_round-2.csv} -plots ${id/_sorted_rmdup_sorted_indelrealigner.bam/BQSR_round-2.pdf}
fi   
if [ "$ROUND" -eq "3" ]; 
then
java -jar GenomeAnalysisTK.jar -T AnalyzeCovariates -R $REF -ignoreLMT -BQSR ${id/_sorted_rmdup_sorted_indelrealigner.bam/_recal_data_round-1.table} -before ${id/_sorted_rmdup_sorted_indelrealigner.bam/_recal_data_round-2.table} -after ${id/_sorted_rmdup_sorted_indelrealigner.bam/_recal_data_round-3.table} -plots BQSR_round-3.pdf
fi
done
done

```

## Report

```{r, engine=bash, eval=FALSE}

# Check ARRAY, SAMPLELIST AND BARCODEID

ARRAY=($(ls *.fastq.gz |  cut -d'_' -f1-3 | uniq))                     

# This part calculates how many reads do I have in the fastq file and name with the sample name so that latter we can added if they are coming from the same library.
# In case they are different libraries, you should use it, cause you have to calculate your statistics per library not per sample. 

for i in ${ARRAY[@]}
do
echo $i
echo ${BARCODEID["${i}"]}_${i}
zcat ${i}_1.fastq.gz | wc -l | awk '{print $1/4}' > ${BARCODEID["${i}"]}_${i}.borrar1.rawseq
zcat ${i}_2.fastq.gz | wc -l | awk '{print $1/4}' > ${BARCODEID["${i}"]}_${i}.borrar2.rawseq
done

rm stats_LYNX_14.csv
rm raw.R2 

for sample in "${SAMPLESLIST[@]}"
do
cat "${sample}"*.borrar1.rawseq | awk '{sum+=$1}END{print sum}' > "${sample}"_R1.rawseq
cat "${sample}"*.borrar2.rawseq | awk '{sum+=$1}END{print sum}' > "${sample}"_R2.rawseq
done


for sample in "${SAMPLESLIST[@]}"
do
echo "${sample}"
NAME="${sample}"
TOTAL_SEQ="$(cat "${sample}"*.rawseq | awk '{sum+=$1}END{print sum}')"
#TOTAL_MAPPED="$(grep "in total" "${sample}".stats | cut -d "+" -f 1 ')"
#DUPLICATES="$(grep "duplicates" "${sample}"_sorted_rmdup_sorted.stats | cut -d "+" -f 1 ')"
echo "$NAME, $TOTAL_SEQ" >> raw.stats 
done

```

## Coverage

```{r, engine=bash, eval=FALSE}
REF=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa					

SAMPLELIST=($(ls *bam | uniq ))
for sample in "${SAMPLELIST[@]}"
do
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC  -XX:+UseStringDeduplication -Xms10g  -Xmx64g -jar /home/tmp/Software/GATK_3.4/GenomeAnalysisTK.jar -I ${sample} -o ${sample/.bam/.coverage} -T DepthOfCoverage -R $REF
done

 -omitBaseOutput	false	
 -omitIntervals false

```

##  QC-test: MaxDepth. Creating BAMlist.

My populations are:

Lynx Pardinux
c_lp_do.bamlist #lynx pardinus 	contemporary donana samples
c_lp_sm.bamlist #lynx pardinus 	contemporary Esmo samples
h_lp_mt #lynx pardinus 	historical 	Montes de Toledo samples

Lynx lynx
c_ll_ki #lynx lynx 		contemporary 	kirov samples
c_ll_po #lynx lynx 		contemporary 	poland samples
c_ll_no #lynx lynx 		contemporary 	norway samples		
c_ll_vl #lynx lynx 		contemporary 	vladivostok samples
c_ll_ya #lynx lynx 		contemporary 	yakutia samples

### Defining Bamlist per pop

```{r, engine=bash, eval=FALSE}

# Hago un .bamlist por poblacion. los salvo en  /home/emarmesat/grupolince/immunocapture/ansgd/qc_test. A saber:
# Este script es una maravilla. Coje todas las poblaciones que tu hayas definido y hace los bamlist con su nombre adecuado.  
POPS=("c_ll_cr" "c_ll_ka" "c_ll_ki" "c_ll_la" "c_ll_no" "c_ll_og" "c_ll_po" "c_ll_to" "c_ll_tu" "c_ll_vl" "c_ll_ya" "c_lp_do" "c_lp_sm")


POPS=("c_ll_ki" "c_ll_po" "c_ll_no" "c_ll_vl" "c_ll_ya" "c_lp_sm" "c_lp_do" "c_lp_do-c_lp_sm" "c_ll_ki-c_ll_no-c_ll_po-c_ll_vl-c_ll_ya" "c_ll_ki-c_ll_no-c_ll_po-c_ll_vl-c_ll_ya-c_lp_do-c_lp_sm")

# POPS=("c_ll_tu")

cd /home/mlucena/grupolince/analysis_genomes_5x/ANGSD/qc_test

for POP in ${POPS[@]}
do
echo $POP
rm "$POP"_n*.bamlist
IFS='-' read -r -a POPS1 <<< "$POP" # this creates an array stripping by "-"
for POP1 in "${POPS1[@]}"
do
echo "$POP --> $POP1"
ls /home/mlucena/grupolince/lynx_genomes_5x/BAM_files_final/${POP1}_*_recal_round-1.bam  >> "$POP".bamlist
done
NUMBER_IND=$(printf "%03d" `wc -l "$POP".bamlist | cut -f1 -d " "`);
mv "$POP".bamlist "$POP"_n"$NUMBER_IND".bamlist
done

```

### MaxDepth

```{r, engine=bash, eval=FALSE}

cd /home/mlucena/grupolince/analysis_genomes_5x/ANGSD/qc_test
#To launch one by one
POP="c_ll_ka"  # <--CHANGE POP HERE
screen -S "$POP"_qc_test
POP="c_ll_ka"  # <--CHANGE POP HERE
script "$POP"_qc.log
POP="c_ll_ka"  # <--CHANGE POP HERE

REF="/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa"
THREADS=5                    # no. of computer cores used 20 = OK, >20 = ask people first!

BAMLIST=$(ls ../"$POP"_n*.bamlist)
NUMBER_IND=$(echo ${BAMLIST: -11}  | sed 's/.bamlist//g')
MAXDEPTH=$(expr $NUMBER_IND \* 1000)

/opt/angsd/angsd \
-P $THREADS \
-b $BAMLIST \
-ref $REF \
-out ${BAMLIST/.bamlist/.qc} \
-uniqueOnly 1 \
-remove_bads 1 \
-only_proper_pairs 1 \
-baq 1 \
-C 50 \
-doQsDist 1 \
-doDepth 1 \
-doCounts 1 \
-maxDepth $MAXDEPTH  


```

I have an issue with c_ll_ka and c_ll_og when calculating doDepth: 
bgzp read block error -1 after x of x bytes. ABORT

This error was reported for a given scaffold position, when I try to open it using igv it reported that the index file is likely to be corrupted: 
"Error encountered querying alignments: java.nio.BufferUnderflowException This is often caused by a corrupt index file."

First, I will try to validate sam
c_ll_ka_0184_recal_round-1.bam
c_ll_ka_0186_recal_round-1.bam
c_ll_ka_0188_recal_round-1.bam
c_ll_ka_0189_recal_round-1.bam

java -jar /opt/picard-tools/picard.jar ValidateSamFile I=c_ll_ka_0184_recal_round-1.bam  MODE=SUMMARY MAX_OPEN_TEMP_FILES=1000

Exception in thread "main" htsjdk.samtools.SAMException: Value was put into PairInfoMap more than once.  0: 7001450:312:CA3D2ANXX:5:1311:7301:38680
	at htsjdk.samtools.CoordinateSortedPairInfoMap.ensureSequenceLoaded(CoordinateSortedPairInfoMap.java:133)
	at htsjdk.samtools.CoordinateSortedPairInfoMap.access$300(CoordinateSortedPairInfoMap.java:53)
	at htsjdk.samtools.CoordinateSortedPairInfoMap$MapIterator.advanceToNextNonEmptyReferenceIndex(CoordinateSortedPairInfoMap.java:227)
	at htsjdk.samtools.CoordinateSortedPairInfoMap$MapIterator.<init>(CoordinateSortedPairInfoMap.java:221)
	at htsjdk.samtools.CoordinateSortedPairInfoMap$MapIterator.<init>(CoordinateSortedPairInfoMap.java:211)
	at htsjdk.samtools.CoordinateSortedPairInfoMap.iterator(CoordinateSortedPairInfoMap.java:208)
	at htsjdk.samtools.SamFileValidator$CoordinateSortedPairEndInfoMap.iterator(SamFileValidator.java:753)
	at htsjdk.samtools.SamFileValidator.validateUnmatchedPairs(SamFileValidator.java:233)
	at htsjdk.samtools.SamFileValidator.validateSamFile(SamFileValidator.java:201)
	at htsjdk.samtools.SamFileValidator.validateSamFileSummary(SamFileValidator.java:128)
	at picard.sam.ValidateSamFile.doWork(ValidateSamFile.java:187)
	at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:209)
	at picard.cmdline.PicardCommandLine.instanceMain(PicardCommandLine.java:95)
	at picard.cmdline.PicardCommandLine.main(PicardCommandLine.java:105)


Este error también lo da al correr una muestra cualquiera de c_ll_og_0181:

java -jar /opt/picard-tools/picard.jar ValidateSamFile I=c_ll_og_0181_recal_round-1.bam  MODE=SUMMARY MAX_OPEN_TEMP_FILES=1000


Vamos a probar una cualquiera porque lo que interpretamos es que son alineamientos secundarios. Ese error también lo daría en una muestra cualquiera:

java -jar /opt/picard-tools/picard.jar ValidateSamFile I=c_ll_ya_0143_recal_round-1.bam  MODE=SUMMARY MAX_OPEN_TEMP_FILES=1000


Vamos a correr el índice para las muestras:

ARRAY=($(c_ll_og*))
for i in ${ARRAY[@]}
do
echo ${i}
samtools index ${i}
done

Haciendo el índice nos devuelve error.
Probamos en el servidor a y tenemos el mismo problema. Por tanto voy a probar a hacer el índice en el archivo inmediatamente interior (indelrealign). 

Con esto no hemos tenido problema, por tanto he leído y parece que la muestra recal-1 no está ordenada. He procedido a ordenar y ya si hemos podido hacer el índice así que voy a ordenar todas las que han dado problemas:

ARRAY=($(ls c_ll_og*bam))
for i in ${ARRAY[@]}
do
echo ${i}
samtools sort ${i} ${i/.bam/_sort.bam}
mv ${i/.bam/_sort.bam} ${i}
samtools index ${i}
done

ARRAY=($(ls c_ll_ka*bam))
for i in ${ARRAY[@]}
do
echo ${i}
samtools sort ${i} ${i/.bam/_sort.bam}
mv ${i/.bam/_sort.bam} ${i}
samtools index ${i}
done




**********************************************************************************************

### MaxDepth R 
  
Cuando acabo me llevo los archivos generados de GlobalDepth a mi ordenador para aplicarles el script de R y calcular la cobertura mínima y máxima en cada caso.

```{r, engine=bash, eval=FALSE}
scp mlucena@genomics-b.ebd.csic.es:/home/mlucena/grupolince/analysis_genomes_5x/ANGSD/qc_test/*.depth* /Users/marialucenaperez/Dropbox/PhD/contemporary/ANGSD/qc_test/
scp mlucena@genomics-b.ebd.csic.es:/home/mlucena/grupolince/analysis_genomes_5x/ANGSD/qc_test/*.bamlist /Users/marialucenaperez/Dropbox/PhD/contemporary/ANGSD/qc_test/
```

RScript:

```{r}

library(dplyr)
library(plyr)
library(ggplot2)
library(gridExtra)

## Functions
get_mean <- function(dat) { with(dat, sum(as.numeric(freq)*value)/sum(as.numeric(freq))) }
get_sd <- function(dat) { mu <- get_mean (dat) 
with (dat, sqrt(sum(as.numeric(freq)*(value-mu)^2)/(sum(as.numeric(freq))-1))) } 

*******************************************************************************************

setwd("/Users/marialucenaperez/Dropbox/PhD/contemporary/ANGSD/qc_test")
my_files_depthGlobal = list.files(pattern="*.depthGlobal$") 
for (i in 1:length(my_files_depthGlobal)) { assign(my_files_depthGlobal[i], (scan(my_files_depthGlobal[i], sep = " ", dec = ".")) %>% .[!is.na(.)])}
sd_folds = 2
depth_per_sample <- data.frame()

#Compute globaldepth for all populations found
*******************************************************************************************
  
for (i in 1:length(my_files_depthGlobal)) 
  {
DF = read.table(my_files_depthGlobal[i],head=F, stringsAsFactors=F)

freq_table_DF <- data.frame (value = 1:length (DF), freq = t(DF))
freq_table_truncated_DF <- filter(freq_table_DF, value < (nrow(freq_table_DF)))

# Mean depth:

my_mean_DF <-  get_mean (freq_table_DF)
my_mean_truncated_DF <- get_mean (freq_table_truncated_DF)
my_sd_DF <-  get_sd (freq_table_DF)
my_sd_truncated_DF <- get_sd (freq_table_truncated_DF)

# Max and min depth:

maxDepth_DF = my_mean_DF + (sd_folds * my_sd_DF)
minDepth_DF  = my_mean_DF - (sd_folds * my_sd_DF)
maxDepth_truncated_DF = my_mean_truncated_DF + (sd_folds * my_sd_truncated_DF)
minDepth_truncated_DF  = my_mean_truncated_DF - (sd_folds * my_sd_truncated_DF)

#Per sample
epoch=unlist(strsplit(my_files_depthGlobal[i],"_"))[1]
specie=unlist(strsplit(my_files_depthGlobal[i],"_"))[2]
population2=unlist(strsplit(my_files_depthGlobal[i],"_"))[3]
population=unlist(strsplit(population2,"[.]"))[1]

depth_per_sample <- rbind(depth_per_sample, 
  data.frame( epoch=epoch,  sp=specie, pop = population,
  mean = my_mean_DF, sd = my_sd_DF, 
  mean_truncated =  my_mean_truncated_DF, sd_truncated = my_sd_truncated_DF,
  maxDepth = maxDepth_DF, minDepth = minDepth_DF,
  maxDepth_truncated = maxDepth_truncated_DF, minDepth_truncated = minDepth_truncated_DF)) 

# Plotting:

ggplot(freq_table_truncated_DF, aes(x = value, y = freq)) + 
  geom_bar(stat = "identity", color = "black") +
  scale_x_continuous(breaks = 0:250*10, limits = c(0, maxDepth_truncated_DF*1.5))+
  scale_y_continuous(expand=c(0,0))+
  ggtitle (paste(my_files_depthGlobal[i],"_",  maxDepth_truncated_DF, "_",maxDepth_DF) ) +
  geom_vline(xintercept=maxDepth_DF,
             linetype="dashed", size=0.5)+ 
  geom_vline(xintercept=minDepth_DF,
             linetype="dashed", size=0.5)+ 
  geom_vline(xintercept=maxDepth_truncated_DF, colour ="grey",
             linetype="dashed", size=0.5)+ 
  geom_vline(xintercept=minDepth_truncated_DF,colour ="grey",
             linetype="dashed", size=0.5)+ 
  theme_classic()+ 
  theme(text = element_text(size=10))

plot_name=paste(my_files_depthGlobal[i],".pdf",sep="")
ggsave(filename = plot_name)

}

#When finished write the table to sfs folder
write.csv(x = depth_per_sample,file = "/Users/marialucenaperez/Dropbox/PhD/contemporary/ANGSD/qc_test/mean_sd_depthGlobal_lynx_per_pop_sd_folds2.csv")
write.table(x = depth_per_sample,file = "/Users/marialucenaperez/Dropbox/PhD/contemporary/ANGSD/qc_test/mean_sd_depthGlobal_lynx_per_pop_sd_folds2_a.csv",quote=FALSE, col.names = FALSE, row.names = FALSE, sep= " ")

```
