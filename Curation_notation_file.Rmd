---
title: "curation_notation_file_gff3"
output: html_document
---


# Curation of gff3 notation file & Diversity calculus per diversity units

It is based in several scripts:

Dviersity calculus per unit (inmmunocapture elena's folder) 18/11/2016
modif_per_unit
promoters
telomers
subtelomeric-centromeric_filtering.R
plotting_subtelomeric_region(...).Rmk

Create an input bedfile that contains all the features we are interested in:

Asumimos ( mirando el archivo ) que es uno based.We are in server a.


```{r, engine=bash, eval=FALSE}

cd /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/

  
# I create a folder and store there everything that is older as we want to run this script again:
# mkdir /home/mlucena/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/maria_curation

```

## 1. Get a non-redundant (i.e., just the main isoform- and its CDS and exons- per gene) gff3.

```{r, engine=bash, eval=FALSE}

cat <(cut -f 2 /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/Anotacion_PrincipaIsoforms_Nando/genes2transcript.nr.list | awk '{print $1";"}' ) <(echo -e "EVM_PASA\tgene") | grep -f - /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/LYPA23C.all.fix.gff3 | sed 's/^\(.\{4\}\)/\1./' > /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/LYPA23C.all.fix.nr.gff3 

# Al usar "EVM_PASA\tgene" podemos seleccionar todos los genes y no solo aquellos que están en el file de la isoforma principal. Esto pasaría por ejemplo para genes que sólo tengan una isoforma.

```

---> Sanity check: They are OK! 

How many genes are not in genes2transcript.nr.list file and are in my file? 

```{r, engine=bash, eval=FALSE}

diff <(cut -f 9 /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/LYPA23C.all.fix.nr.gff3 | awk '{split ($0,a,"="); split (a[2],b,"T"); print b[1]}' | grep -v '^$' | sort | uniq | grep "LYPA" | sed 's/> //g') <(grep -v '^###$' /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/LYPA23C.all.fix.gff3 | awk '{split ($0,a,"="); split (a[2],b,"T"); print b[1]}' | grep -v '^$' | sort | uniq | grep -v "lnc" | grep "LYPA" | sed 's/> //g')
## NONE!
```



--- Sanity check para comprobar si la longitud de los mRNA y de los genes es igual o no. 
```{r, engine=bash, eval=FALSE}
while read GENEID ;
do
echo "$GENEID"
grep "$GENEID" /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/LYPA23C.all.fix.nr.gff3 | grep -P 'EVM_PASA\tgene' | awk -v OFS='\t' '{print $4,$5}' > temp.gene.to.merge.borrar
grep "$GENEID" /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/LYPA23C.all.fix.nr.gff3 | grep -P 'EVM_PASA\tmRNA' | awk -v OFS='\t' '{print $4,$5,$7}' > temp.mRNA.to.merge.borrar
paste <(echo $GENEID) <(cat temp.gene.to.merge.borrar ) <(cat temp.mRNA.to.merge.borrar) >> GENE_vs_mRNA1.borrar
done < <( zcat /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/APPRIS/p23A.v3.14Oct2013/appris_data.corsair.lynx_pardinus.gff3.gz |  awk '$6>3 {  print $0 }' | awk '{ split($0,a,"Parent="); print a[2] }' | sort | uniq |  tr -d '"' | sed 's/LYPA23A/LYPA23C/g' )
 

echo -e "GENE\tGENEstart\tGENEend\tmRNAstart\tmRNAend\tsense" > header.borrar
cat header.borrar GENE_vs_mRNA1.borrar > GENE_vs_mRNA
rm GENE_vs_mRNA1.borrar

cat GENE_vs_mRNA | awk '{if ($6=="+") print $1,$2,$3,$4,$5,$4-$2,$6; else print $1,$2,$3,$4,$5,$3-$5,$6}' | grep -v " 0 +" | grep -v " 0 -" > GENE_vs_mRNA_not_coincident.csv


rm *borrar
```
They are not always coincident, the file is called: "GENE_vs_mRNA_not_coincident.csv". What then?





## 2. Get the features represented in the bedfile

```{r, engine=bash, eval=FALSE}

cut -f 3 /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/LYPA23C.all.fix.nr.gff3  | sort | uniq

# CDS
# exon
# gene
# mRNA

```

## 3. Get the features not represented (i.e., promoters, introns, 5'UTR and 3'UTR, lncRNA & ncRNA, intergenic) 

La estructura que queremos es SCAFFOLD EVM_PASA FEATURE START END POINT STRANDNESS FRAME IDRAW

### 3.a. Gene promoters. 

- Vamos a usar sólo la lista de los genes que están completos en toda su longitud filtrado desde el archivo generado con APPRIS

- Lista de genes que nos interesan, son los genes que están en appris_data.corsair.lynx_pardinus.gff3.gz y tienen una puntuación mayor que 3 en la 6th columna. Escogemos este corte porque:

Email Michael Trees: 
Si quieres sacar datos ya el fichero correcto es appris_data.corsair.lynx_pardinus.gff3.
Aparte del gen y transcrito lo importante seria el score de CORSAIR, que es la
columna justo despues de las coordinadas. Como lo hemos calculado
entonces habia un punto para cada especia alineado corectamente (aunque
perro valia 0.8, pollo 2, xenopus 2 y danio 2.5. Entonces para asegurar
que han alineado bien proteinas al menos dos especies (y asi es menos
probable que el isoforma ha alineado contra fragmentos) pondria un corte de tres.
lp23.s10430	3817466	3817966	PROMOTER:LYPA23C008622T2	0	+


- No usamos la lista de Fede porque gracias a algunos sanity checks comprobé que al menos un promotor solapaba con un gen (si quieres saber cómo lo supe: script antiguo). Tras hablar con Fede, nos ha confirmado que para la dirección - los promotores no están bien definidos, por tanto vamos a volver a definirlos nosotros desde el principio. 

Como los tenemos que definir de nuevo, los vamos a definir en base a una lista de 250, 500 y 1000bp. 

```{r, engine=bash, eval=FALSE}

rm LYPA23C.promoters_full_length_genes.nr.250bp.gff3
while read GENEID ;
do
# 250
echo "$GENEID"
grep "$GENEID" /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/LYPA23C.all.fix.nr.gff3 | grep -P 'EVM_PASA\tmRNA'  | \
awk -v OFS='\t' '{split($0,a,":"); if ($7=="+") print $1,"manual","promoter",$4-250,$4-1,$6,$7,$8,$9"_promoter"; else print $1,"manual","promoter",$5+1,$5+250,$6,$7,$8,$9"_promoter"}'>> LYPA23C.promoters_full_length_genes.nr.250bp.gff3
done < <( zcat /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/APPRIS/p23A.v3.14Oct2013/appris_data.corsair.lynx_pardinus.gff3.gz |  awk '$6>3 {  print $0 }' | awk '{ split($0,a,"Parent="); print a[2] }' | sort | uniq |  tr -d '"' | sed 's/LYPA23A/LYPA23C/g')

rm LYPA23C.promoters_full_length_genes.nr.500bp.gff3
while read GENEID ;
do
# 500
echo "$GENEID"
grep "$GENEID" /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/LYPA23C.all.fix.nr.gff3 | grep -P 'EVM_PASA\tmRNA'  | \
awk -v OFS='\t' '{split($0,a,":"); if ($7=="+") print $1,"manual","promoter",$4-500,$4-1,$6,$7,$8,$9"_promoter"; else print $1,"manual","promoter",$5+1,$5+500,$6,$7,$8,$9"_promoter"}'>> LYPA23C.promoters_full_length_genes.nr.500bp.gff3
done < <( zcat /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/APPRIS/p23A.v3.14Oct2013/appris_data.corsair.lynx_pardinus.gff3.gz |  awk '$6>3 {  print $0 }' | awk '{ split($0,a,"Parent="); print a[2] }' | sort | uniq |  tr -d '"' | sed 's/LYPA23A/LYPA23C/g')

rm LYPA23C.promoters_full_length_genes.nr.1000bp.gff3
while read GENEID ;
do
# 1000
echo "$GENEID"
grep "$GENEID" /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/LYPA23C.all.fix.nr.gff3 | grep -P 'EVM_PASA\tmRNA'  | \
awk -v OFS='\t' '{split($0,a,":"); if ($7=="+") print $1,"manual","promoter",$4-1000,$4-1,$6,$7,$8,$9"_promoter"; else print $1,"manual","promoter",$5+1,$5+1000,$6,$7,$8,$9"_promoter"}'>> LYPA23C.promoters_full_length_genes.nr.1000bp.gff3
done < <( zcat /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/APPRIS/p23A.v3.14Oct2013/appris_data.corsair.lynx_pardinus.gff3.gz |  awk '$6>3 {  print $0 }' | awk '{ split($0,a,"Parent="); print a[2] }' | sort | uniq |  tr -d '"' | sed 's/LYPA23A/LYPA23C/g')


```



### 3.b. Introns 

--- Sanity check para comprobar que es seguro usar el bed de Fede.

```{r, engine=bash, eval=FALSE}

# Comprobar que están bien calculados con algún ej a ojo. Tomo para el ejemplo los 10 primeros genes
grep gene LYPA23C.all.fix.nr.gff3 | head | awk '{ split($0,a,"ID="); print a[2] }'

GENES=('LYPA23C013748' 'LYPA23C013847' 'LYPA23C013736' 'LYPA23C013679' 'LYPA23C013712' 'LYPA23C013832' 'LYPA23C013840' 'LYPA23C013755' 'LYPA23C013826' 'LYPA23C013809')
rm check.introns.borrar
for GENEID in "${GENES[@]}"
do
echo "---------------------GENE = $GENEID---------------------------" >> check.introns.borrar
grep "ID=$GENEID" LYPA23C.all.fix.nr.gff3 | grep gene  >> check.introns.borrar
echo "---------------------EXONS---------------------------" >> check.introns.borrar
grep "$GENEID" LYPA23C.all.fix.nr.gff3 | grep exon  >> check.introns.borrar
echo "---------------------INTRONS---------------------------" >> check.introns.borrar
grep "ID=$GENEID" LYPA23C.introns.nr.gff3 | grep intron  >> check.introns.borrar
echo >> check.introns.borrar
echo >> check.introns.borrar
done
 
# Hemos comprobado que tenemos definidos intrones para menos genes de los que hay. Comprobamos que estos genes en cuestión no tienen más de un exón y por tanto no tienen intrones definidos.

rm exon_per_genes_in_my_nr_file_and_not_in_introns_bed.list
while read GENE;
do 
echo $GENE
grep $GENE /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/LYPA23C.all.fix.nr.extra.genes.gff3 | grep -e $'\t''EVM_PASA'$'\t''CDS'$'\t' | awk '{split ($9,a,";"); print a[1]}' | uniq -c | sort -k1,1 | grep -v "1 Parent" >> CDS_per_genes_in_my_nr_file_and_not_in_introns_bed.list
done < <(cat genes_in_my_nr_file_and_not_in_introns_bed.list)

# Hablando con Fede y me ha comentado "Sólo he mirado el primero y el segundo. El intrón del gen LYPA23C001262 solapa con el UTR de otro gen. Por eso no se considera intrón “puro”. Lo mismo pasa con el segundo. Los genomas son muy raros ;-)". Por tanto estos intrones no se considerarían. 

```
Tras discutir con Fede las dudas que tenías vemos que los intrones están bien, solo tendríamos que corregir que están como 0based y nosotros queremos pasarlo a 1 based para el gff. 

Corregimos a 0 based:

```{r, engine=bash, eval=FALSE}
awk -v OFS='\t' '{split($4,a,":"); print $1,"MANUAL","intron",$2+1,$3,".",$6,$5,"ID="a[2]}' /home/GRUPOS/grupolince/copia_fabascal/FEATURES/introns.bed | awk -v OFS='\t' '{if ($9==prev) counter++; else counter=1; print ($1,$2,$3,$4,$5,$6,$7,$8,$9"_intron_"counter); prev=$9}'  > LYPA23C.introns.nr.gff3
```

### 3.c. UTRs

For each gene

Vamos a usar sólo la lista de los genes que están completos en toda su longitud filtrado desde el archivo generado con APPRIS

Lista de genes que nos interesan, son los genes que están en appris_data.corsair.lynx_pardinus.gff3.gz y tienen una puntuación mayor que 3 en la 6th columna. Escogemos este corte porque:

Email Michael Trees: 
Si quieres sacar datos ya el fichero correcto es appris_data.corsair.lynx_pardinus.gff3.
Aparte del gen y transcrito lo importante seria el score de CORSAIR, que es la
columna justo despues de las coordinadas. Como lo hemos calculado
entonces habia un punto para cada especia alineado corectamente (aunque
perro valia 0.8, pollo 2, xenopus 2 y danio 2.5. Entonces para asegurar
que han alineado bien proteinas al menos dos especies (y asi es menos
probable que el isoforma ha alineado contra fragmentos) pondria un corte de tres.

Las UTR se podrían definir como gene-exon,gene-cds y exon-cds. Tras discutir cual es la mejor aproximación, nos vamos a quedar con gene-cds

```{r, engine=bash, eval=FALSE}

rm LYPA23C.UTRs_gene-cds.nr.gff3
while read GENEID ;
do
echo "$GENEID" 
# gene
grep "$GENEID" /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/LYPA23C.all.fix.nr.gff3   | # Solo si uso el file con todas las isoformas sed 's/^\(.\{4\}\)/\1./'  | \
grep -e $'\t''EVM_PASA'$'\t''gene'$'\t' | awk -v OFS='\t' '{print $1,$2,$3,$4-1,$5,$6,$7,$8,$9}' \
> gene.iter.bed.borrar
# He convertido el archivo en 0-based para hacer el substract. 
# cds
grep "$GENEID" /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/LYPA23C.all.fix.nr.gff3  | # Solo si uso el file con todas las isoformassed 's/^\(.\{4\}\)/\1./'  | \
grep -e $'\t''EVM_PASA'$'\t''CDS'$'\t' | \
awk -v OFS='\t' 'NR == 1 {min = $4} NR>1 && $4<min {min = $4}; NR == 1 {max = $5} NR>1 && $5>max {max = $5} END {print  $1,min-1,max}'  \
> cds.iter.bed.borrar
# He convertido el archivo en 0-based para hacer el substract. 
# Get UTRs by doing gene-exon, gene-cds and exon-cds:
bedtools subtract -a gene.iter.bed.borrar -b cds.iter.bed.borrar > gene-cds.iter.bed.borrar
# Get UTRs
awk -v OFS='\t' 'NR==1 {if ($7=="+") print $1,$2,"5UTR",$4,$5,$6,$7,$8,$9,$5-$4 ; else print $1,$2,"3UTR",$4,$5,$6,$7,$8,$9,$5-$4} \
NR==2 {if ($7=="+") print $1,$2,"3UTR",$4,$5,$6,$7,$8,$9,$5-$4; else print $1,$2,"5UTR",$4,$5,$6,$7,$8,$9,$5-$4 }' gene-cds.iter.bed.borrar | \
awk -v OFS='\t' '$10>1 {print $1,$2,$3,$4+1,$5,$6,$7,$8,$9}' >>  LYPA23C.UTRs_gene-cds.nr.gff3  
# Lo que hace es quitarme todos los UTR que sean de un tamañao de 1 o 0. Además lo hago 1-based. 
done < <( zcat /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/APPRIS/p23A.v3.14Oct2013/appris_data.corsair.lynx_pardinus.gff3.gz |  awk '$6>3 {  print $0 }' | awk '{ split($0,a,"Parent="); print a[2] }' | sort | uniq |  tr -d '"' | sed 's/LYPA23A/LYPA23C/g')

# Este fallo se debe a que gene es igual a cds. 
# Error: Invalid record in file gene.iter.bed.borrar. Record is 
# lp23.s26762	EVM_PASA	gene	0	1635	.	-	.	ID=LYPA23C003834

# También se podría hacer como gene-exon o exon-cds. Esas combinaciones están en script antiguo. 
# Esto te daría 1-based directamente.

rm *.iter.bed.borrar

```


### 3.d. lncRNA

```{r, engine=bash, eval=FALSE}

# El archivo que tenemos es un archivo gtf que nos lo ha pasado Ionas Erb (Centre de Regulació Genòmica) de la última versión que hicieron del mismo. 
# El formato gtf es algo distinto a gff3. He encontrado un script de python que te los transforma y creo que ya los podríamos usar para lo que nos interesa.  

python /Users/marialucenaperez/Dropbox/PhD/contemporary/script/GTF_to_GFF3.py /Users/marialucenaperez/Desktop/lncRNAs_fixed.gtf > /Users/marialucenaperez/Desktop/lncRNAs_fixed.gff3
scp /Users/marialucenaperez/Desktop/lncRNAs_fixed.gtf GRUPOS@genomics-a.ebd.csic.es:///home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/
scp /Users/marialucenaperez/Desktop/lncRNAs_fixed.gff3 GRUPOS@genomics-a.ebd.csic.es:///home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/


sed 's/^\(.\{4\}\)/\1./' lncRNAs_fixed.gff3  | \
awk -v OFS='\t' '{split($9,a,";"); split (a[2],b,"\""); split ($11,c,"\""); print ($1,$2,$3,$4,$5,$6,$7,$8,b[1],c[2])}' | \
LANG=en_EN sort -k 9,9 -k 10,10 | \
awk -v OFS='\t' '{print ($1,$2,$3,$4,$5,$6,$7,$8,$9"_"$10)}' | \
awk -v OFS='\t' '{if ($9==prev) counter++; else counter=1; print ($1,$2,"lncRNA",$4,$5,$6,$7,$8,$9"_exon_"counter); prev=$9}' > lncRNAs_fixed_sorted.gff3 


# This is not coming from a bed file, so I assumed that is 1-based

```

### 3.e. sncRNA


```{r, engine=bash, eval=FALSE}

# We have the final output of infernal package, and also a report explaining what we have. 
# The file is: infernal_1e6.gff3.zip  

sed 's/^\(.\{4\}\)/\1./' infernal_1e6.gff3 > infernal_1e6_fixed.gff3

# This is not coming from a bed file, so I assumed that is 1-based


```


### 3.f. lncRNA introns

```{r, engine=bash, eval=FALSE}

rm LYPA23C.introns_lncRNA.gff3
rm cuentas.borrar
while read direction LNCRNA_ID ;
do
echo $LNCRNA_ID
grep "$LNCRNA_ID" lncRNAs_fixed_sorted.gff3 | awk -v OFS='\t' '{print $1, $4, $5}' > exons.lncRNA.iter.borrar
wc -l exons.lncRNA.iter.borrar >> cuentas.borrar # To check if I should have more than an intron for a lncRNA. 
grep "$LNCRNA_ID" lncRNAs_fixed_sorted.gff3 | \
awk -v OFS='\t' 'NR == 1 {min = $4} NR>1 && $4<min {min = $4}; NR == 1 {max = $5} NR>1 && $5>max {max = $5} END {print  $1,min,max}' > whole.lncRNA.iter.borrar
bedtools subtract -a whole.lncRNA.iter.borrar -b exons.lncRNA.iter.borrar > whole-exons.lncRNA.iter.bed.borrar
awk -v OFS='\t' '{print $1,"manual","intron_lncRNA",$2+1, $3-1,".","'${direction}'",".","GID='${LNCRNA_ID}'" }' whole-exons.lncRNA.iter.bed.borrar | awk -v OFS='\t' '{if ($9==prev) counter++; else counter=1; print ($1,$2,$3,$4,$5,$6,$7,$8,$9"_intron_"counter); prev=$9}'  >>  LYPA23C.introns_lncRNA.gff3
done < <( cat lncRNAs_fixed_sorted.gff3 | awk '{ split($0,a,"GID="); print $7, a[2] }' | awk '{ split($2,a,"_"); print $1, a[1]"_"a[2]"_"a[3]"_"a[4] }' | sort | uniq )

rm cuentas.borrar
```

### 3.f. lncRNA promoters

```{r, engine=bash, eval=FALSE}

rm LYPA23C.promoters_full_length_lncRNA.250bp.gff3
while read LNCRNA_ID ;
do
# 250
echo $LNCRNA_ID
grep "$LNCRNA_ID" lncRNAs_fixed_sorted.gff3 | \
awk -v OFS='\t' 'NR == 1 {min = $4} NR>1 && $4<min {min = $4}; NR == 1 {max = $5} NR>1 && $5>max {max = $5} END {print  $1,min,max,$7}' | 
awk -v OFS='\t' '{if ($4=="+") print $1,"manual","promoter_lncRNA",$2-250,$2-1,".",$4,".","GID='${LNCRNA_ID}'_promoter"; else print $1,"manual","promoter_lncRNA",$3+1,$3+250,".",$4,".","GID='${LNCRNA_ID}'_promoter"}' >> LYPA23C.promoters_full_length_lncRNA.250bp.gff3
done < <( cat lncRNAs_fixed_sorted.gff3 | awk '{ split($0,a,"GID="); print a[2] }' | awk '{ split($0,a,"_"); print a[1]"_"a[2] }' | sort | uniq )


rm LYPA23C.promoters_full_length_lncRNA.500bp.gff3
while read LNCRNA_ID ;
do
# 500
echo $LNCRNA_ID
grep "$LNCRNA_ID" lncRNAs_fixed_sorted.gff3 | \
awk -v OFS='\t' 'NR == 1 {min = $4} NR>1 && $4<min {min = $4}; NR == 1 {max = $5} NR>1 && $5>max {max = $5} END {print  $1,min,max,$7}' | 
awk -v OFS='\t' '{if ($4=="+") print $1,"manual","promoter_lncRNA",$2-500,$2-1,".",$4,".","GID='${LNCRNA_ID}'_promoter"; else print $1,"manual","promoter_lncRNA",$3+1,$3+500,".",$4,".","GID='${LNCRNA_ID}'_promoter"}' >> LYPA23C.promoters_full_length_lncRNA.500bp.gff3
done < <( cat lncRNAs_fixed_sorted.gff3 | awk '{ split($0,a,"GID="); print a[2] }' | awk '{ split($0,a,"_"); print a[1]"_"a[2] }' | sort | uniq )


rm LYPA23C.promoters_full_length_lncRNA.1000bp.gff3
while read LNCRNA_ID ;
do
# 1000
echo $LNCRNA_ID
grep "$LNCRNA_ID" lncRNAs_fixed_sorted.gff3 | \
awk -v OFS='\t' 'NR == 1 {min = $4} NR>1 && $4<min {min = $4}; NR == 1 {max = $5} NR>1 && $5>max {max = $5} END {print  $1,min,max,$7}' | 
awk -v OFS='\t' '{if ($4=="+") print $1,"manual","promoter_lncRNA",$2-1000,$2-1,".",$4,".","GID='${LNCRNA_ID}'_promoter"; else print $1,"manual","promoter_lncRNA",$3+1,$3+1000,".",$4,".","GID='${LNCRNA_ID}'_promoter"}' >> LYPA23C.promoters_full_length_lncRNA.1000bp.gff3
done < <( cat lncRNAs_fixed_sorted.gff3 | awk '{ split($0,a,"GID="); print a[2] }' | awk '{ split($0,a,"_"); print a[1]"_"a[2] }' | sort | uniq )

RLOC_00000001
RLOC_00000003
```


## 4. Merging functional part of the genome (merging)


```{r, engine=bash, eval=FALSE}


# FUNCTIONAL FILE:
# Name: LYPA23C.CDS.EXON.GENE.mRNA.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.nr.gff3 

# Files included:
# 	1. Original file LYPA23C.all.fix.nr.gff3 (CDS/EXON/GENE/mRNA)
# 	2. Promoters (Nos quedamos con el archivo de promoters 1000 pb para ser conservadores a la hora de        decir lo que es intergénico)
# 	introns
# 	5'UTR and 3'UTR (UTR es la región no traducida del gen por tanto nos quedamos con:                     LYPA23C.UTRs_gene-cds.nr.gff3)
# 	lncRNA
#   lncRNA promoters
# 	ncRNA

cat LYPA23C.all.fix.nr.gff3 LYPA23C.promoters_full_length_genes.nr.1000bp.gff3 LYPA23C.introns.nr.gff3 LYPA23C.UTRs_gene-cds.nr.gff3  lncRNAs_fixed_sorted.gff3 infernal_1e6_fixed.gff3 LYPA23C.promoters_full_length_lncRNA.250bp.gff3 LYPA23C.promoters_full_length_lncRNA.500bp.gff3 LYPA23C.promoters_full_length_lncRNA.1000bp.gff3| LANG=en_EN sort -k 1,1 -k 4,4n -k 5,5n > LYPA23C.CDS.EXON.GENE.mRNA.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.nr.gff3 


## Shall we add introns from lncRNA and promoters from lncRNA?

```



## 5. Defining intergenic regions

Fede tiene un bed de intergénico, pero dado que nosotros hemos:

1. Corregido los promotores que no estaban bien definidos para los genes -.
2. Añadido lncRNA y sncRNA
3. 

Por tanto, voy a usar mi file de funcional y restarle al genoma todas esas regiones. 

```{r, engine=bash, eval=FALSE}


# First create bed file based on the previous file. Como es un bed es 0-based.

awk -v OFS='\t' '{print $1, $4-1, $5 }' LYPA23C.CDS.EXON.GENE.mRNA.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.nr.gff3 | bedtools merge -i stdin -d 1 > LYPA.CDS.EXON.GENE.mRNA.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.nr.bed

# Define intergenic region

bedtools subtract -a /home/mlucena/grupolince/reference_genomes/lynx_pardinus_genome/bed_file_all_the_genome.bed -b LYPA.CDS.EXON.GENE.mRNA.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.nr.bed > LP

# Do we have intersect?

head intersect_functional_vs_intergenic.bed 
lp23.s00001	98144	98644
lp23.s00001	182045	182094
lp23.s00001	253081	253183
lp23.s00001	362028	362528
lp23.s00001	406838	407920
lp23.s00001	408133	408172
lp23.s00001	408528	408686
lp23.s00001	408829	408883
lp23.s00001	427565	427732

## YES!

head LYPA.functional.bed
lp23.s00001	16012	16984
lp23.s00001	33317	36294
lp23.s00001	42533	43669
lp23.s00001	57643	59375
lp23.s00001	98144	102823
lp23.s00001	124260	132558
lp23.s00001	140480	166118
lp23.s00001	172611	178853
lp23.s00001	182045	182094
lp23.s00001	209951	212866

head intergenic_sorted_nr.bed
lp23.s00001	0	16012
lp23.s00001	16984	33317
lp23.s00001	36294	42533
lp23.s00001	43669	57643
lp23.s00001	59375	98644
lp23.s00001	102823	124260
lp23.s00001	132558	140480
lp23.s00001	166118	172611
lp23.s00001	178853	209951
lp23.s00001	212866	216796

# For instances, the first intersect section is..

grep lp23.s00001  LYPA23C.CDS.EXON.GENE.mRNA.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.nr.gff3 | grep 98144
lp23.s00001	EVM_PASA	promoter	98144	98643	.	+	0	ID=LYPA23C013712
lp23.s00001	EVM_PASA	promoter	98144	98643	.	+	0	ID=LYPA23C013712

# And some others...

grep lp23.s00001 LYPA23C.CDS.EXON.GENE.mRNA.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.nr.gff3 | grep 182045
lp23.s00001	INFERNAL	ncRNA	182045	182094	1.1e-07	+	.	ID=RF00004-182045;Name=U2;Alias=RF00004;Is_truncate=no

grep lp23.s00001  LYPA23C.CDS.EXON.GENE.mRNA.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.nr.gff3 | grep 253081
lp23.s00001	INFERNAL	ncRNA	253081	253183	3e-08	-	.	ID=RF00998-253081;Name=mir-562;Alias=RF00998;Is_truncate=no

grep lp23.s00001  LYPA23C.CDS.EXON.GENE.mRNA.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.nr.gff3 | grep 408528
lp23.s00001	PipeR	exon	408528	408686	.	-	.	GID=RLOC_00000001_TCONS_00000014_exon_3


# So it seems that all of them are either ncRNA or promoters that I added lately. Therefore those areas should be remove from the intergenic regions. 


bedtools subtract -a intergenic_sorted_nr.bed -b intersect_functional_vs_intergenic.bed > intergenic_sorted_nr_fixed.bed

head intergenic_sorted_nr_fixed.bed
lp23.s00001	0	16012
lp23.s00001	16984	33317
lp23.s00001	36294	42533
lp23.s00001	43669	57643
lp23.s00001	59375	98144
lp23.s00001	102823	124260
lp23.s00001	132558	140480
lp23.s00001	166118	172611
lp23.s00001	178853	182045
lp23.s00001	182094	209951

### It is solved!! 
# Now I create an artificial intergenic gff3 file for the calculus of the diversity per unit. 

awk -v OFS='\t' '{print $1, "MANUAL", "intergenic", $2, $3,"x","x","x","ID=none"}' intergenic_sorted_nr_fixed.bed > intergenic_sorted_nr_fixed.gff3
# I included entries for strand frame etc so that it keeps the structure while running the calculus.

################################

## Therefore I created the definitive file with all the features; i.e., 

# ALL FEATURES FILE:
# Name: LYPA23C.CDS.EXON.GENE.mRNA.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.intergenic.nr.gff3 
# Files included:
# 	ORIGINAL FILE (CDS/EXON/GENE/mRNA)
# 	promoters
# 	introns
# 	5'UTR and 3'UTR (UTR es la región no traducida del gen por tanto nos quedamos con: LYPA23C.UTRs_gene-cds.nr.gff3)
# 	lncRNA
# 	ncRNA
# 	intergenic gff3 file

#Modify intergenic_sorted_nr_fixed.gff3 to change - by dots and pass it to one based

cat intergenic_sorted_nr_fixed.gff3 | tr '-' '.' | awk -v OFS='\t' '{ print $1,$2,$3,$4+1,$5,$6,$7,$8,$9;}' > intergenic_sorted_nr_fixed2.gff3

cat LYPA23C.all.fix.nr.extra.genes.gff3 LYPA23C.promoters_full_length_genes.nr.gff3 LYPA23C.introns.nr.gff3 LYPA23C.UTRs_gene-cds.nr.positions.fixed.gff3 lncRNAs_fixed_sorted.gff3 infernal_1e6_fixed.gff3 intergenic_sorted_nr_fixed2.gff3 | LANG=en_EN sort -k 1,1 -k 4,4n -k 5,5n > LYPA23C.CDS.EXON.GENE.mRNA.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.INTERGENIC.nr.gff3 

# I remove exons (=CDS) and mRNA (=gene) cause I don't need them:

cat LYPA23C.CDS.EXON.GENE.mRNA.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.INTERGENIC.nr.gff3 | awk '{if ($3!="exon") print $0}' | awk '{if ($3!="mRNA") print $0}' > LYPA23C.CDS.GENE.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.INTERGENIC.nr.gff3

# I had a look and it seems very good! 





# ¢ AÑADIR TELOMERO Y CENTRÓMERO Y PREGUNTAR A FEDE LO DE LOS GENES TAN GRANDES!
######################################################################################################################################################################################################################
######################################################################################################################################################################################################################
######################################################################################################################################################################################################################

######################################################################################################################################################################################################################
#
# MARIA's project
#
######################################################################################################################################################################################################################
# Now that I have the file to run over the calculus per unit. To do it in a efficient way I will split this file into as many files as scaffolds. I will do the same with my thetas file. 
# That way I will just have to search over the file that contains the scaffold, and bedtools will be faster.  


##### Thetas files:

cd /home/GRUPOS/grupolince/analysis_genomes_5x/diversity_per_unit

POPS=("KIR_separated_by_scaffold" "DON_separated_by_scaffold" "SMO_separated_by_scaffold" "BIA_separated_by_scaffold" "NOR_separated_by_scaffold")
for MYPOP in "${POPS[@]}"
do
echo "---------------------------------------------------$MYPOP---------------------------------------------------"
mkdir $MYPOP;
done
 

mv BIA.transformedThetas BIA_separated_by_scaffold/
mv DON.transformedThetas DON_separated_by_scaffold/
mv NOR.transformedThetas NOR_separated_by_scaffold/
mv SMO.transformedThetas SMO_separated_by_scaffold/
mv KIR.transformedThetas KIR_separated_by_scaffold/


POPS=("KIR" "DON" "SMO" "BIA" "NOR")
for POP in "${POPS[@]}"
do
echo $POP
cd  /home/GRUPOS/grupolince/analysis_genomes_5x/diversity_per_unit/"$POP"_separated_by_scaffold
# Create multiple files base on one column: transformedThetas:
awk '{print >> $1; close($1)}' "$POP".transformedThetas
rm scaffold 
done

# Rename the files: transformedThetas:
for POP in "${POPS[@]}"
do
cd /home/GRUPOS/grupolince/analysis_genomes_5x/diversity_per_unit/"$POP"_separated_by_scaffold
for file in lp23*
do
echo $file
mv $file ${file/lp23/"$POP".transformedThetas_lp23}
done
done



##### Gff3 files:
cd /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final
mkdir LYPA23C.CDS.GENE.mRNA.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.INTERGENIC.nr.gff3.PerScaffold
cd LYPA23C.CDS.GENE.mRNA.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.INTERGENIC.nr.gff3.PerScaffold
# Create multiple files base on one column: gff3:
awk '{print >> $1; close($1)}' ../LYPA23C.CDS.GENE.mRNA.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.INTERGENIC.nr.gff3
# Rename gff3.
for file in lp23*
do
echo $file
mv $file ${file/lp23/LYPA23C.CDS.GENE.mRNA.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.INTERGENIC.nr_lp23}
done



###
LANZADO PARA:
BIA: # running
KIR: # running
NOR: # running
DON: # running
SMO: # running


POPS=("SMO")

POP=c_ll_ki_n020
screen -S "$POP"_scaffold_per_unit
script log_screen_"$POP"_scaffold_per_unit

##WG variables
#SCAFFOLDS_FOLDER=/home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/
#SCAFFOLDS_PATH=/home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/LYPA23C.CDS.GENE.mRNA.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.INTERGENIC.nr.gff3.PerScaffold/#LYPA23C.CDS.GENE.mRNA.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.INTERGENIC.nr
#cd $SCAFFOLDS_FOLDER
#SCAFFOLDS=($(ls LYPA23C.CDS.GENE.mRNA.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.INTERGENIC.nr* | cut -d'_' -f2 | uniq))
#DIVERSITY_PER_UNIT_FOLDER=/home/GRUPOS/grupolince/analysis_genomes_5x/diversity_per_unit/

#immunome variables
POP=h_lp_al-h_lp_cr-h_lp_do-h_lp_mt-h_lp_pa_n056

screen -S perunit_$POP
POP=h_lp_al-h_lp_cr-h_lp_do-h_lp_mt-h_lp_pa_n056


script perunit_$POP.log
POP=h_lp_al-h_lp_cr-h_lp_do-h_lp_mt-h_lp_pa_n056


SCAFFOLDS_FOLDER=/home/emarmesat/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/immunocapture.PerScaffold/per_scaffold/
SCAFFOLDS_PATH=/home/emarmesat/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/immunocapture.PerScaffold/per_scaffold/LYPA23C.CDS.GENE.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.INTERGENIC.nr.immuno-intersect_
cd $SCAFFOLDS_FOLDER
SCAFFOLDS=($(ls LYPA23C.CDS.GENE.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.INTERGENIC.nr.immuno-intersect_* | cut -d'_' -f2 | uniq))
DIVERSITY_PER_UNIT_FOLDER=/home/emarmesat/grupolince/immunocapture/ansgd/diversity_per_unit/

#for POP in "${POPS[@]}"
#do

echo "---------------------------------------------------$POP---------------------------------------------------"

cd "$DIVERSITY_PER_UNIT_FOLDER""$POP"_separated_by_scaffold

# Create headers for the outfile
echo -e "scaffold\tstart\tend\tlength\tNAs\tfeature\tstrandness\tframe\tid_gene\tid\twatterson_ave\twatterson_sd\tpairwise_ave\tpairwise_sd\ttajimaD" > "$POP".per.unit.averages.tsv


for SCAFFOLD in "${SCAFFOLDS[@]}"
do
echo "---------------------$SCAFFOLD---------------------"


#For each unit
while read LOCATION METHOD FEATURE START_ONEBASED END POINT STRANDNESS FRAME IDRAW;
do
echo "--------$SCAFFOLD:$FEATURE--------"
LENGTH=$(expr $END - $START_ONEBASED) 
if [ "$METHOD" = "PipeR" ]; then
	ID_GENE=$(echo $IDRAW | awk -F "_" '{ split ($0, a, "ID="); split (a[2],b,"_"); print b[1]"_"b[2] }')
	else
	ID_GENE=$(echo $IDRAW | awk '{ split($0,a,"ID="); split (a[2],b,";"); split(b[1],c,"T"); print c[1] }') 
fi

if [ "$FEATURE" = "CDS" ]; then
	ID=$(echo $IDRAW | awk -F "_" '{split ($0,a,"Target="); split(a[2],b,";"); print b[1]}' |  awk '{print $1"_"$2"_"$3}' )
	else
	ID=$(echo $IDRAW | awk '{ split($0,a,"ID="); split (a[2],b,";"); print b[1] }')
fi

#Intersect bed of the unit (first remove header)
cat "$POP".transformedThetas_"$SCAFFOLD" | bedtools intersect -a stdin -b <(echo -e "$LOCATION\t$START_ONEBASED\t$END") > "$POP".iter.transformedThetas.borrar

WATTERSON_AVERAGE_PER_UNIT=$(cut -f 4 "$POP".iter.transformedThetas.borrar | awk -v OFS='\t' '{for(i=1;i<=NF;i++) {sum[i] += $i }} END {for (i=1;i<=NF;i++) {printf ("%.10e\n", sum[i]/NR )}}' | sed 's/[eE]+\{0,1\}/*10^/g')
WATTERSON_SD_PER_UNIT=$(cut -f 4 "$POP".iter.transformedThetas.borrar | awk -v OFS='\t' '{for(i=1;i<=NF;i++) {sum[i] += $i; sumsq[i] += ($i)^2}} END {for (i=1;i<=NF;i++) {printf ("%.10e\n", sqrt((sumsq[i]-sum[i]^2/NR)/NR))}}' | sed 's/[eE]+\{0,1\}/*10^/g')


PAIRWISE_AVERAGE_PER_UNIT=$(cut -f 5 "$POP".iter.transformedThetas.borrar | awk -v OFS='\t' '{for(i=1;i<=NF;i++) {sum[i] += $i }} END {for (i=1;i<=NF;i++) {printf ("%.10e\n", sum[i]/NR )}}' | sed 's/[eE]+\{0,1\}/*10^/g') 
PAIRWISE_SD_PER_UNIT=$(cut -f 5  "$POP".iter.transformedThetas.borrar | awk -v OFS='\t' '{for(i=1;i<=NF;i++) {sum[i] += $i; sumsq[i] += ($i)^2}} END {for (i=1;i<=NF;i++) {printf ("%.10e\n", sqrt((sumsq[i]-sum[i]^2/NR)/NR))}}' | sed 's/[eE]+\{0,1\}/*10^/g') 


DIFFERENCE_PAIRWISE_WATTERSON_SD_PER_UNIT=$(cut -f 6  "$POP".iter.transformedThetas.borrar   |  awk -v OFS='\t' '{for(i=1;i<=NF;i++) {sum[i] += $i; sumsq[i] += ($i)^2}} END {for (i=1;i<=NF;i++) {printf ("%.10e\n", sqrt((sumsq[i]-sum[i]^2/NR)/NR ))}}' | sed 's/[eE]+\{0,1\}/*10^/g') 
TAJIMAS_D_PER_UNIT=$(echo "(($PAIRWISE_AVERAGE_PER_UNIT) - ($WATTERSON_SD_PER_UNIT))/($DIFFERENCE_PAIRWISE_WATTERSON_SD_PER_UNIT)" | bc -l | awk '{printf ("%.10e\n",$1)}' |  sed 's/[eE]+\{0,1\}/*10^/g' )

NR=$(wc -l "$POP".iter.transformedThetas.borrar | cut -d" " -f1)
NAs=$(expr $LENGTH - $NR)

# Calculate averages, and standatd deviations and paste them
paste \
<(echo $LOCATION ) \
<(echo $START_ONEBASED ) \
<(echo $END ) \
<(echo $LENGTH ) \
<(echo $NAs) \
<(echo $FEATURE ) \
<(echo $STRANDNESS ) \
<(echo $FRAME ) \
<(echo $ID_GENE ) \
<(echo $ID) \
<(echo $WATTERSON_AVERAGE_PER_UNIT) \
<(echo $WATTERSON_SD_PER_UNIT) \
<(echo $PAIRWISE_AVERAGE_PER_UNIT) \
<(echo $PAIRWISE_SD_PER_UNIT) \
<(echo $TAJIMAS_D_PER_UNIT) |\
sed 's/ /\t/g'| sed 's/\t\+/\t/g' >>  "$POP".per.unit.averages.tsv
done < <(cat "$SCAFFOLDS_PATH""$SCAFFOLD")
done
# sed 's/ \* /\t/g' "$POP".per.unit.averages.tsv > borrar
rm "$POP".iter.transformedThetas.borrar


#done 









#########ESTOS SON PROBLEMÁTICOS!!!######### no me calcula watterson etc. check pq?

lp23.s00001     5963447 5963590 143     143     CDS     -       2       LYPA23C013812   LYPA23C013812P1_442_490 
lp23.s00001     5963800 5963912 112     0       CDS     -       1       LYPA23C013812   LYPA23C013812P1_404_442 5.0754623776*10^-06     9.5479321550*10^-06     3.6431904233*10^-06     8.2915919056*10^-06     -4.4002365131*10^00
lp23.s00001     5964104 5964116 12      12      CDS     -       2       LYPA23C013812   LYPA23C013812P1_400_404 




# Para hacer una pruebina cojo los 5 primeros scaffolds:



grep -nr lp23.s00005 SMO.per.unit.averages.tsv | tail

8825:lp23.s00005	4609089	4673100	64011	30278	intergenic	x	x	none	none	6.3901712366*10^-05	3.8870657122*10^-03	4.1396801326*10^-05	2.7664932224*10^-03	-2.1810913415*10^00

awk '{if (NR < 8825) print $0}' SMO.per.unit.averages.tsv > SMO.per.unit.averages_lp23.s00001-s00005.tsv
awk '{if (NR < 8825) print $0}' DON.per.unit.averages.tsv > DON.per.unit.averages_lp23.s00001-s00005.tsv


######################################################################################################################################################################################################################
######################################################################################################################################################################################################################
######################################################################################################################################################################################################################

##### ALL THIS PART IS IMPLEMENTED TO RUN OVER THE ENTIRE FILE. I WILL NOT USE THIS AS IT IS VERY TIME CONSUMING. I WILL BE USING THE SCRIPT BEFORE THIS AS IT SPLIT THE FILES AS IT IS WAY MORE FAST.
## I HAVEN'T CHECK IT LATELY --> DON'T KNOW IF IT WORKS ## 

# Compute the Thetas per unit defined in the input bedfile
# Infile product of running ANGSD-sfs...= "$MYPOP".transformedThetas

# cd /home/emarmesat/grupolince/immunocapture/ansgd/sfs
# ruta primera prueba maria: /home/GRUPOS/grupolince/analysis_genomes_5x/diversity_per_unit
# screen -S per_unint_diversity_run1
# script per_unint_diversity_run1.log

# Lanzado1 ( voy lanzando los que van estando listos
# POPS=(KIR DON SMO BIA NOR)

for MYPOP in "${POPS[@]}"
do
echo "---------------------------------------------------$MYPOP---------------------------------------------------"
# Create headers for the outfile
echo -e "scaffold\tstart\tend\tlength\tNAs\tfeature\tstrandness\tframe\tid_gene\tid\twatterson_ave\twatterson_sd\tpairwise_ave\tpairwise_sd\ttajimaD" > "$POP".per.unit.averages.tsv
#For each unit
while read SCAFFOLD METHOD FEATURE START_ONEBASED END POINT STRANDNESS FRAME IDRAW;
do
LENGTH=$(expr $END - $START_ONEBASED) 
if [ "$METHOD" = "PipeR" ]; then
	ID_GENE=$(echo $IDRAW | awk -F "_" '{ split ($0, a, "ID="); split (a[2],b,"_"); print b[1]"_"b[2] }')
	else
	ID_GENE=$(echo $IDRAW | awk '{ split($0,a,"ID="); split (a[2],b,";"); split(b[1],c,"T"); print c[1] }') 
fi
if [ "$FEATURE" = "CDS" ]; then
	ID=$(echo $IDRAW | awk -F "_" '{split ($0,a,"Target="); split(a[2],b,";"); print b[1]}' |  awk '{print $1"_"$2"_"$3}' )
	else
	ID=$(echo $IDRAW | awk '{ split($0,a,"ID="); split (a[2],b,";"); print b[1] }')
fi
#Intersect bed of the unit (first remove header)
tail -n +2 "$MYPOP".transformedThetas | bedtools intersect -a stdin -b <(echo -e "$SCAFFOLD\t$START_ONEBASED\t$END") > "$MYPOP".iter.transformedThetas.borrar
WATTERSON_AVERAGE_PER_UNIT=$(cut -f 4 "$MYPOP".iter.transformedThetas.borrar  | awk -v OFS='\t' '{for(i=1;i<=NF;i++) {sum[i] += $i }} END {for (i=1;i<=NF;i++) {printf ("%.10e\n", sum[i]/NR )}}' | sed 's/[eE]+\{0,1\}/*10^/g')
WATTERSON_SD_PER_UNIT=$(cut -f 4 "$MYPOP".iter.transformedThetas.borrar | awk -v OFS='\t' '{for(i=1;i<=NF;i++) {sum[i] += $i; sumsq[i] += ($i)^2}} END {for (i=1;i<=NF;i++) {printf ("%.10e\n", sqrt((sumsq[i]-sum[i]^2/NR)/NR))}}' | sed 's/[eE]+\{0,1\}/*10^/g')
PAIRWISE_AVERAGE_PER_UNIT=$(cut -f 5  "$MYPOP".iter.transformedThetas.borrar |  awk -v OFS='\t' '{for(i=1;i<=NF;i++) {sum[i] += $i }} END {for (i=1;i<=NF;i++) {printf ("%.10e\n", sum[i]/NR )}}' | sed 's/[eE]+\{0,1\}/*10^/g') 
PAIRWISE_SD_PER_UNIT=$(cut -f 5  "$MYPOP".iter.transformedThetas.borrar | awk -v OFS='\t' '{for(i=1;i<=NF;i++) {sum[i] += $i; sumsq[i] += ($i)^2}} END {for (i=1;i<=NF;i++) {printf ("%.10e\n", sqrt((sumsq[i]-sum[i]^2/NR)/NR))}}' | sed 's/[eE]+\{0,1\}/*10^/g') 
DIFFERENCE_PAIRWISE_WATTERSON_SD_PER_UNIT=$(cut -f 6  "$MYPOP".iter.transformedThetas.borrar   |  awk -v OFS='\t' '{for(i=1;i<=NF;i++) {sum[i] += $i; sumsq[i] += ($i)^2}} END {for (i=1;i<=NF;i++) {printf ("%.10e\n", sqrt((sumsq[i]-sum[i]^2/NR)/NR ))}}' | sed 's/[eE]+\{0,1\}/*10^/g') 
TAJIMAS_D_PER_UNIT=$(echo "(($PAIRWISE_AVERAGE_PER_UNIT) - ($WATTERSON_SD_PER_UNIT))/($DIFFERENCE_PAIRWISE_WATTERSON_SD_PER_UNIT)" | bc -l | awk '{printf ("%.10e\n",$1)}' |  sed 's/[eE]+\{0,1\}/*10^/g' )
NR=$(wc -l "$MYPOP".iter.transformedThetas.borrar | cut -d" " -f1)
NAs=$(expr $LENGTH - $NR)
# Calculate averages, and standatd deviations and paste them
paste \
<(echo $LOCATION ) \
<(echo $START_ONEBASED ) \
<(echo $END ) \
<(echo $LENGTH ) \
<(echo $NAs) \
<(echo $FEATURE ) \
<(echo $STRANDNESS ) \
<(echo $FRAME ) \
<(echo $ID_GENE ) \
<(echo $ID) \
<(echo $WATTERSON_AVERAGE_PER_UNIT) \
<(echo $WATTERSON_SD_PER_UNIT) \
<(echo $PAIRWISE_AVERAGE_PER_UNIT) \
<(echo $PAIRWISE_SD_PER_UNIT) \
<(echo $TAJIMAS_D_PER_UNIT) | \
sed 's/ /\t/g'| sed 's/\t\+/\t/g' >>  "$MYPOP".per.unit.averages.tsv
done < /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/LYPA23C.all.features.nr.gff3
# sed 's/ \* /\t/g' "$MYPOP".per.unit.averages.tsv > borrar
rm "$MYPOP".iter.transformedThetas.borrar
done 

######################################################################################################################################################################################################################
######################################################################################################################################################################################################################
######################################################################################################################################################################################################################
####################################################################################################################################################################################################################
#
# ELENA's IMMUNOCAPTURE project
#
######################################################################################################################################################################################################################
# Now that I have the file to run over the calculus per unit. To do it in a efficient way I will split this file into as many files as scaffolds. I will do the same with my thetas file. 
# That way I will just have to search over the file that contains the scaffold, and bedtools will be faster.  


######################################################################################
#                       IMMUNOCAPTURE      Gff3 REFERENCE files                      #
######################################################################################
#I'll work with a working version of the annotation where cds and intergenic is properly designes (which are the only features I'm interested in)
#I'll rename it so I'm sure that it's never erased

mv ../LYPA23C.CDS.GENE.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.INTERGENIC.nr.gff3 LYPA23C.CDS.GENE.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.INTERGENIC.nr.immunocapture20170303.gff3 


#I'll intersect the per scaffolds files with my capture so that I have even smaller files!

#I'll rename it so I'm sure that it's never erased

ANNOTATION_GFF3="LYPA23C.CDS.GENE.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.INTERGENIC.nr.immunocapture20170303.gff3"
TARGET="/home/emarmesat/grupolince/immunocapture/capture/nimblegene_final_design/140723_IMMUNOCAP_EMB_EZ_sorted.bed"
#Intersect the current file with the bed file so it only contaings regions of the capture
bedtools intersect -a $ANNOTATION_GFF3 -b $TARGET > ${ANNOTATION_GFF3/immunocapture20170303/immuno-intersect}

mkdir per_scaffold
cd per_scaffold
# Create multiple files base on one column: gff3:
awk '{print >> $1; close($1)}' ../LYPA23C.CDS.GENE.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.INTERGENIC.nr.immuno-intersect.gff3
# Rename gff3.
for file in lp23*
do
echo $file
mv $file ${file/lp23/LYPA23C.CDS.GENE.PROMOTERS.INTRONS.UTR.lncRNA.ncRNA.INTERGENIC.nr.immuno-intersect_lp23}
done






```









# Modification over per unit script: modif_per_unit_script:


```{r, engine=bash, eval=FALSE}
cat LYPA23C.all.features.nr.gff3 | grep -v "exon" > LYPA23C.all.features.nr.without_exons.gff3


##### Thetas files:

cd /home/mlucena/grupolince/analysis_genomes_5x/diversity_per_unit

POPS=("KIR_separated_by_scaffold" "DON_separated_by_scaffold" "SMO_separated_by_scaffold" "BIA_separated_by_scaffold" "NOR_separated_by_scaffold")
for MYPOP in "${POPS[@]}"
do
echo "---------------------------------------------------$MYPOP---------------------------------------------------"
mkdir $MYPOP;
done
 

mv BIA.transformedThetas BIA_separated_by_scaffold/
mv DON.transformedThetas DON_separated_by_scaffold/
mv NOR.transformedThetas NOR_separated_by_scaffold/
mv SMO.transformedThetas SMO_separated_by_scaffold/
mv KIR.transformedThetas KIR_separated_by_scaffold/


POPS=("KIR" "DON" "SMO" "BIA" "NOR")
for POP in "${POPS[@]}"
do
echo $POP
cd  /home/mlucena/grupolince/analysis_genomes_5x/diversity_per_unit/"$POP"_separated_by_scaffold
# Create multiple files base on one column: transformedThetas:
awk '{print >> $1; close($1)}' "$POP".transformedThetas
rm scaffold 
done

# Rename the files: transformedThetas:
for POP in "${POPS[@]}"
do
cd /home/mlucena/grupolince/analysis_genomes_5x/diversity_per_unit/"$POP"_separated_by_scaffold
for file in lp23*
do
echo $file
mv $file ${file/lp23/"$POP".transformedThetas_lp23}
done
done



##### Gff3 files:
cd /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final
mkdir LYPA.perScaffold
cd LYPA.perScaffold
# Create multiple files base on one column: gff3:
awk '{print >> $1; close($1)}' LYPA23C.all.features.nr.without_exons.gff3
# Rename gff3.
for file in lp23*
do
echo $file
mv $file ${file/lp23/LYPA23C.all.features.nr.without_exons_lp23}
done



###
LANZADO PARA:
BIA: # --> RUNNING!
KIR: # --> RUNNING!
NOR: # --> RUNNING!
DON: # --> RUNNING!
SMO: # --> RUNNING!



screen -S SMO_scaffold_per_unit
script log_screen_SMO_scaffold_per_unit
POPS=("SMO")
SCAFFOLDS=($(ls /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/LYPA.perScaffold/LYPA23C.all.features.nr.without_exons_* | cut -d'_' -f7 | uniq))


for MYPOP in "${POPS[@]}"
do

echo "---------------------------------------------------$MYPOP---------------------------------------------------"

cd /home/mlucena/grupolince/analysis_genomes_5x/diversity_per_unit/"$MYPOP"_separated_by_scaffold

# Create headers for the outfile
echo -e "scaffold\tstart\tend\tlength\tNAs\tfeature\tstrandness\tframe\tid\twatterson_ave\twatterson_sd\tpairwise_ave\tpairwise_sd\tpairwise-watterson" > "$MYPOP".per.unit.averages.tsv


for SCAFFOLD in "${SCAFFOLDS[@]}"
do
echo "---------------------$SCAFFOLD---------------------"


#For each unit
while read LOCATION METHOD FEATURE START_ONEBASED END POINT STRANDNESS FRAME IDRAW;

do
echo "--------$SCAFFOLD:$FEATURE--------"
LENGTH=$(expr $END - $START_ONEBASED) 
ID_GENE=$(echo $IDRAW | awk '{ split($0,a,"ID="); split (a[2],b,";"); split(b[1],c,"T"); print c[1] }') 
if [ "$FEATURE" = "CDS" ]; then
	ID=$(echo $IDRAW | awk -F "_" '{split ($0,a,"Target="); split(a[2],b,";"); print b[1]}' |  awk '{print $1"_"$2"_"$3}' )
	else
	ID=$(echo $IDRAW | awk '{ split($0,a,"ID="); split (a[2],b,";"); print b[1] }')
fi

#Intersect bed of the unit (first remove header)
cat "$MYPOP".transformedThetas_"$SCAFFOLD" | bedtools intersect -a stdin -b <(echo -e "$LOCATION\t$START_ONEBASED\t$END") > "$MYPOP".iter.transformedThetas.borrar

WATTERSON_AVERAGE_PER_UNIT=$(cut -f 4 "$MYPOP".iter.transformedThetas.borrar  | awk -v OFS='\t' '{for(i=1;i<=NF;i++) {sum[i] += $i }} END {for (i=1;i<=NF;i++) {printf ("%.10e\n", sum[i]/NR )}}' | sed 's/[eE]+\{0,1\}/*10^/g')
WATTERSON_SD_PER_UNIT=$(cut -f 4 "$MYPOP".iter.transformedThetas.borrar | awk -v OFS='\t' '{for(i=1;i<=NF;i++) {sum[i] += $i; sumsq[i] += ($i)^2}} END {for (i=1;i<=NF;i++) {printf ("%.10e\n", sqrt((sumsq[i]-sum[i]^2/NR)/NR))}}' | sed 's/[eE]+\{0,1\}/*10^/g')


PAIRWISE_AVERAGE_PER_UNIT=$(cut -f 5  "$MYPOP".iter.transformedThetas.borrar |  awk -v OFS='\t' '{for(i=1;i<=NF;i++) {sum[i] += $i }} END {for (i=1;i<=NF;i++) {printf ("%.10e\n", sum[i]/NR )}}' | sed 's/[eE]+\{0,1\}/*10^/g') 
PAIRWISE_SD_PER_UNIT=$(cut -f 5  "$MYPOP".iter.transformedThetas.borrar | awk -v OFS='\t' '{for(i=1;i<=NF;i++) {sum[i] += $i; sumsq[i] += ($i)^2}} END {for (i=1;i<=NF;i++) {printf ("%.10e\n", sqrt((sumsq[i]-sum[i]^2/NR)/NR))}}' | sed 's/[eE]+\{0,1\}/*10^/g') 


DIFFERENCE_PAIRWISE_WATTERSON_SD_PER_UNIT=$(cut -f 6  "$MYPOP".iter.transformedThetas.borrar   |  awk -v OFS='\t' '{for(i=1;i<=NF;i++) {sum[i] += $i; sumsq[i] += ($i)^2}} END {for (i=1;i<=NF;i++) {printf ("%.10e\n", sqrt((sumsq[i]-sum[i]^2/NR)/NR ))}}' | sed 's/[eE]+\{0,1\}/*10^/g') 
TAJIMAS_D_PER_UNIT=$(echo "(($PAIRWISE_AVERAGE_PER_UNIT) - ($WATTERSON_SD_PER_UNIT))/($DIFFERENCE_PAIRWISE_WATTERSON_SD_PER_UNIT)" | bc -l | awk '{printf ("%.10e\n",$1)}' |  sed 's/[eE]+\{0,1\}/*10^/g' )

NR=$(wc -l "$MYPOP".iter.transformedThetas.borrar | cut -d" " -f1)
NAs=$(expr $LENGTH - $NR)

# Calculate averages, and standatd deviations and paste them
paste \
<(echo $LOCATION ) \
<(echo $START_ONEBASED ) \
<(echo $END ) \
<(echo $LENGTH ) \
<(echo $NAs) \
<(echo $FEATURE ) \
<(echo $STRANDNESS ) \
<(echo $FRAME ) \
<(echo $ID_GENE ) \
<(echo $ID) \
<(echo $WATTERSON_AVERAGE_PER_UNIT) \
<(echo $WATTERSON_SD_PER_UNIT) \
<(echo $PAIRWISE_AVERAGE_PER_UNIT) \
<(echo $PAIRWISE_SD_PER_UNIT) \
<(echo $TAJIMAS_D_PER_UNIT) |\
sed 's/ /\t/g'| sed 's/\t\+/\t/g' >>  "$MYPOP".per.unit.averages.tsv

done < <( cat /home/GRUPOS/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/LYPA.perScaffold/LYPA23C.all.features.nr.without_exons_$SCAFFOLD)
done
# sed 's/ \* /\t/g' "$MYPOP".per.unit.averages.tsv > borrar
rm "$MYPOP".iter.transformedThetas.borrar
done 


## I stopped it after a while and rename files:
POPS=("KIR" "DON" "SMO" "BIA" "NOR")
for MYPOP in "${POPS[@]}"
do

echo "---------------------------------------------------$MYPOP---------------------------------------------------"

cd /home/mlucena/grupolince/analysis_genomes_5x/diversity_per_unit/"$MYPOP"_separated_by_scaffold
mv "$MYPOP".per.unit.averages.tsv "$MYPOP".per.unit.averages.test.tsv
done

```



# Telomers.sh
```{r, engine=bash, eval=FALSE}

# I extract a list of the scaffolds that have at least some bases in the subtelomeric region or in the centromere.

awk '{$1}' tel2m.bed | sort | uniq > scaffolds_tel2m.list
awk '{$1}' tel10m.bed | sort | uniq > scaffolds_tel10m.list
awk '{$1}' centr.bed | sort | uniq > scaffolds_centr.list


# How long is the longest scaffold?

join scaffolds_tel2m.list Length_scaffolds_lp23 | sort -k2n | tail

# lp23.s20863 3296142
# lp23.s31290 3370745
# lp23.s31287 3871840
# lp23.s00008 4038649
# lp23.s36495 4262991
# lp23.s00006 4480212
# lp23.s36493 4643072
# lp23.s26068 4986501
# lp23.s36488 7826823
# lp23.s31278 7976960

# I has 7.9M, and that is not possible as I am looking at a region of 2M.


join scaffolds_tel10m.list Length_scaffolds_lp23 | sort -k2n | tail

# lp23.s10428 5537880
# lp23.s00003 5556527
# lp23.s05215 5566334
# lp23.s15639 5809641
# lp23.s20852 6074816
# lp23.s05214 6149468
# lp23.s10426 6347329
# lp23.s20851 6824652
# lp23.s26065 6924262
# lp23.s26064 8029254



join scaffolds_centr.list Length_scaffolds_lp23 | sort -k2n | tail

# lp23.s20852 6074816
# lp23.s00002 6085556
# lp23.s10426 6347329
# lp23.s20851 6824652
# lp23.s26065 6924262
# lp23.s36488 7826823
# lp23.s31278 7976960
# lp23.s15637 8424978
# lp23.s05213 12220470
# lp23.s00001 13188378
 

# It looks like some scaffolds have just some bp homologous. 

# But before that...

# Is there a scaffold present in the centromere and the subtelomeric region?

grep -Fxf scaffolds_tel2m.list scaffolds_centr.list  > scaffolds_present_in_tel2_and_centr.list
# Yes! 41.

grep -Fxf scaffolds_tel10m.list scaffolds_centr.list  > scaffolds_present_in_tel10_and_centr.list
# Yes! 107.

# Are all the scaffolds present in tel2m in tel10m?

wc -l scaffolds_tel2m.list
# 575 scaffolds_tel2m.list

wc -l scaffolds_tel10m.list
# 1161 scaffolds_tel10m.list

grep -Fxf scaffolds_tel10m.list scaffolds_tel2m.list | wc -l
# No! only 54


# I asked Fede why and he mentioned that tel10m include subtelomeric region from 2 to 10Mb, therefore, from now on, we will include tel0-10 in our analysis. 

cat scaffolds_tel2m.list scaffolds_tel10m.list | sort | uniq > scaffolds_tel0-10m.list

wc -l scaffolds_tel0-10m.list 
# 1682 scaffolds_tel0-10m.list

join scaffolds_tel0-10m.list  Length_scaffolds_lp23 | sort -k2n | tail

# lp23.s05215 5566334
# lp23.s15639 5809641
# lp23.s20852 6074816
# lp23.s05214 6149468
# lp23.s10426 6347329
# lp23.s20851 6824652
# lp23.s26065 6924262
# lp23.s36488 7826823
# lp23.s31278 7976960
# lp23.s26064 8029254

#########################################

# Definimos tres niveles:

# 1. Scaffolds y longitud de los mismos: ya lo tenemos : Length_scaffolds_lp23 y scaffolds_tel2m.list/tel0-10m.list/centr.list
 
# 2. Región con homología:

## En este caso determinamos la región potencialmente subtelomérica:

sort -k1,1 -k2,2n /home/mlucena/grupolince/copia_fabascal/FEATURES/tel2m.bed | bedtools merge -d 7976960 | awk -v OFS='\t'  '{print $1, $3-$2}' > tel2m_merged.bed
cat /home/mlucena/grupolince/copia_fabascal/FEATURES/tel2m.bed /home/mlucena/grupolince/copia_fabascal/FEATURES/tel10m.bed | sort - -k1,1 -k2,2n | bedtools merge -d 8029254 | awk -v OFS='\t'  '{print $1, $3-$2}' > tel0-10m_merged.bed
sort -k1,1 -k2,2n /home/mlucena/grupolince/copia_fabascal/FEATURES/centr.bed | bedtools merge -d 13188378 | awk -v OFS='\t'  '{print $1, $3-$2}' > centr_merged.bed


# 3. Bases con homología. 

awk '{print $1, $3-$2}' /home/mlucena/grupolince/copia_fabascal/FEATURES/tel2m.bed | awk '{a[$1]+=$2}END{for(i in a) print i,a[i]}' | sort -k1 | join - tel2m_merged.bed | sort -k1 | join - Length_scaffolds_lp23 | sort -k1 > tel2m_bp_region_length.info 
cat /home/mlucena/grupolince/copia_fabascal/FEATURES/tel2m.bed /home/mlucena/grupolince/copia_fabascal/FEATURES/tel10m.bed | awk '{print $1, $3-$2}' | awk '{a[$1]+=$2}END{for(i in a) print i,a[i]}' | sort -k1 | join - tel0-10m_merged.bed | sort -k1 | join - Length_scaffolds_lp23 | sort -k1 > tel0-10m_bp_region_length.info 
awk '{print $1, $3-$2}' /home/mlucena/grupolince/copia_fabascal/FEATURES/centr.bed | awk '{a[$1]+=$2}END{for(i in a) print i,a[i]}' | sort -k1 | join - centr_merged.bed | sort -k1 | join - Length_scaffolds_lp23 | sort -k1 > centr_bp_region_length.info 


# En este último archivo ya tenemos todo:
# -------------------------------- Scaffold
#     -----------------			   Región
#     ..     .   ..   .			   Bases con homología.


# ---------------------------------------------------------------------------------#

# Con esta información exploramos un poquito los datos:

head scaffolds_present_in_tel2_and_centr.list
lp23.s00008
lp23.s00224
lp23.s00387
lp23.s10464

######################################

# Example: lp23.s00008: Aparece en ambos, tel2m y centr. 

grep lp23.s00008 tel2m_bp_region_length.info 
lp23.s00008 32 220 4038649

grep lp23.s00008 centr_bp_region_length.info 
lp23.s00008 7 2630019 4038649

grep lp23.s00008 /home/mlucena/grupolince/copia_fabascal/FEATURES/tel2m.bed 
lp23.s00008	2579970	2579993	chrF1:67576422
lp23.s00008	2580181	2580190	chrF1:67576225

grep lp23.s00008 /home/mlucena/grupolince/copia_fabascal/FEATURES/centr.bed 
lp23.s00008	531713	531715	chrA3:40467745
lp23.s00008	531831	531834	chrA3:40467629
lp23.s00008	3161730	3161732	chrC2:65834393

# Now we try to estimate % of the bp that have sinteny in the region and in the whole scaffold --> código para hacer histograma. 

# awk '{print $1, $2, $3, $4, ($2/$3)*100, ($3/$4)*100 ,($2/$4)*100}' centr_bp_region_length.info | awk '{if ($7==0) print $0}' | sort -k7,7 -d | head
awk '{print $1, $2, $3, $4, ($2/$3)*100, ($3/$4)*100 ,($2/$4)*100}' centr_bp_region_length.info | awk '{print $7}' | sort -g | awk '{split ($1,a, "."); print a[1]}' | uniq -c | awk '{print $2, $1}' | perl -pe 's/ (\d+)$/"="x$1/e'
awk '{print $1, $2, $3, $4, ($2/$3)*100, ($3/$4)*100 ,($2/$4)*100}' tel0-10m_bp_region_length.info | awk '{print $7}' | sort -g | awk '{split ($1,a, "."); print a[1]}' | uniq -c | awk '{print $2, $1}' | perl -pe 's/ (\d+)$/"="x$1/e'
awk '{print $1, $2, $3, $4, ($2/$3)*100, ($3/$4)*100 ,($2/$4)*100}' tel2_bp_region_length.info | awk '{print $5}' | sort -g | awk '{split ($1,a, "."); print a[1]}' | uniq -c | awk '{print $2, $1}' | perl -pe 's/ (\d+)$/"="x$1/e'


# Tras hablar con Fede check email (21/02/2017) voy a hacer un merge con dos filtros -d 1000 y -d 5000, a ver cual funciona mejor. Posteriormente voy a hacer un histograma y luego decidir un filtro de numero de bases del scaffold. 


## Aquí determinamos regiones separadas por un máximo de 1000pb y posteriormente las filtramos para número de bases 1000 y 5000. 

sort -k1,1 -k2,2n /home/mlucena/grupolince/copia_fabascal/FEATURES/tel2m.bed | bedtools merge -d 1000  > tel2m_merged_1000.bed
cat /home/mlucena/grupolince/copia_fabascal/FEATURES/tel2m.bed /home/mlucena/grupolince/copia_fabascal/FEATURES/tel10m.bed | sort - -k1,1 -k2,2n  | bedtools merge -d 1000 > tel0-10m_merged_1000.bed
sort -k1,1 -k2,2n /home/mlucena/grupolince/copia_fabascal/FEATURES/centr.bed | bedtools merge -d 1000  > centr_merged_1000.bed

sort -k1,1 -k2,2n /home/mlucena/grupolince/copia_fabascal/FEATURES/tel2m.bed | bedtools merge -d 5000  > tel2m_merged_5000.bed
cat /home/mlucena/grupolince/copia_fabascal/FEATURES/tel2m.bed /home/mlucena/grupolince/copia_fabascal/FEATURES/tel10m.bed | sort - -k1,1 -k2,2n  | bedtools merge -d 5000 > tel0-10m_merged_5000.bed
sort -k1,1 -k2,2n /home/mlucena/grupolince/copia_fabascal/FEATURES/centr.bed | bedtools merge -d 5000  > centr_merged_5000.bed

sort -k1,1 -k2,2n /home/mlucena/grupolince/copia_fabascal/FEATURES/tel2m.bed | bedtools merge -d 500  > tel2m_merged_500.bed
cat /home/mlucena/grupolince/copia_fabascal/FEATURES/tel2m.bed /home/mlucena/grupolince/copia_fabascal/FEATURES/tel10m.bed | sort - -k1,1 -k2,2n  | bedtools merge -d 500 > tel0-10m_merged_500.bed
sort -k1,1 -k2,2n /home/mlucena/grupolince/copia_fabascal/FEATURES/centr.bed | bedtools merge -d 500  > centr_merged_500.bed


########

cat /home/mlucena/grupolince/copia_fabascal/FEATURES/tel2m.bed /home/mlucena/grupolince/copia_fabascal/FEATURES/tel10m.bed | wc -l
2640677

wc -l tel0-10m_merged_1000.bed
53329 tel0-10m_merged_1000.bed

########

wc -l /home/mlucena/grupolince/copia_fabascal/FEATURES/tel2m.bed 
401564 /home/mlucena/grupolince/copia_fabascal/FEATURES/tel2m.bed
[mlucena@genomics_a Lyp_annotation_Apr14_final]$ wc -l tel2m_merged_1000.bed
11801 tel2m_merged_1000.bed

########

cat /home/mlucena/grupolince/copia_fabascal/FEATURES/tel2m.bed /home/mlucena/grupolince/copia_fabascal/FEATURES/tel10m.bed  | grep lp23.s05217

wc -l /home/mlucena/grupolince/copia_fabascal/FEATURES/centr.bed
2211773 

wc -l centr_merged_1000.bed
38532 centr_merged_1000.bed

# --> 385327 / 2211773 = 0.17

scp /home/mlucena/grupolince/copia_fabascal/FEATURES/tel2m.bed .
cat /home/mlucena/grupolince/copia_fabascal/FEATURES/tel2m.bed /home/mlucena/grupolince/copia_fabascal/FEATURES/tel10m.bed | sort - -k1,1 -k2,2n > tel0-10m.bed
scp /home/mlucena/grupolince/copia_fabascal/FEATURES/centr.bed .


## Correr desde aquí:


FILES=($(ls *merged_1000.bed | uniq))

rm *_density_regions.info

for FILE in "${FILES[@]}"
do
echo $FILE

while read SCAFFOLD START FINISH
do
echo ${FILE/_merged_1000.bed/.bed}
echo $SCAFFOLD
echo $START
echo $FINISH

NUM_BASES=$(awk -v SCAFFOLD=$SCAFFOLD -v START=$START -v FINISH=$FINISH '$1==SCAFFOLD && $2>=START && $3<=FINISH {print $1, $3-$2}' ${FILE/_merged_1000.bed/.bed} | awk -v OFS='\t' '{for(i=1;i<=NF;i++) {sum[i] += $i; sumsq[i] += ($i)^2}} END {for (i=1;i<=NF;i++) {printf  sum[i]}}')
paste \
<(echo $SCAFFOLD ) \
<(echo $START ) \
<(echo $FINISH ) \
<(echo $NUM_BASES ) | \
sed 's/ /\t/g'| sed 's/\t\+/\t/g' >>  ${FILE/.bed/_density_regions.info}

done < <( cat `echo $FILE` )
done


FILES=($(ls *_1000_density_regions.info | uniq))

for FILE in "${FILES[@]}"
do
echo $FILE
awk -v OFS='\t' '{print $1,$3-$2,$4,($4*100)/($3-$2)}' ${FILE} > ${FILE/.info/.info.counts}
done


##########



FILES=($(ls *merged_5000.bed | uniq))

rm *_density_regions.info

for FILE in "${FILES[@]}"
do
echo $FILE

while read SCAFFOLD START FINISH
do
echo ${FILE/_merged_5000.bed/.bed}
echo $SCAFFOLD
echo $START
echo $FINISH

NUM_BASES=$(awk -v SCAFFOLD=$SCAFFOLD -v START=$START -v FINISH=$FINISH '$1==SCAFFOLD && $2>=START && $3<=FINISH {print $1, $3-$2}' ${FILE/_merged_5000.bed/.bed} | awk -v OFS='\t' '{for(i=1;i<=NF;i++) {sum[i] += $i; sumsq[i] += ($i)^2}} END {for (i=1;i<=NF;i++) {printf  sum[i]}}')
paste \
<(echo $SCAFFOLD ) \
<(echo $START ) \
<(echo $FINISH ) \
<(echo $NUM_BASES ) | \
sed 's/ /\t/g'| sed 's/\t\+/\t/g' >>  ${FILE/.bed/_density_regions.info}

done < <( cat `echo $FILE` )
done


FILES=($(ls *_5000_density_regions.info | uniq))

for FILE in "${FILES[@]}"
do
echo $FILE
awk -v OFS='\t' '{print $1,$3-$2,$4,($4*100)/($3-$2)}' ${FILE} > ${FILE/.info/.info.counts}
done


##########
scp mlucena@genomics-a.ebd.csic.es:/home/mlucena/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/*density_regions.info.counts /Users/marialucenaperez/Dropbox/PhD/contemporary/subtelomeric_centromeric_analysis/
##########




FILES=($(ls *merged_500.bed | uniq))

rm *_density_regions.info

for FILE in "${FILES[@]}"
do
echo $FILE

while read SCAFFOLD START FINISH
do
echo ${FILE/_merged_500.bed/.bed}
echo $SCAFFOLD
echo $START
echo $FINISH

NUM_BASES=$(awk -v SCAFFOLD=$SCAFFOLD -v START=$START -v FINISH=$FINISH '$1==SCAFFOLD && $2>=START && $3<=FINISH {print $1, $3-$2}' ${FILE/_merged_500.bed/.bed} | awk -v OFS='\t' '{for(i=1;i<=NF;i++) {sum[i] += $i; sumsq[i] += ($i)^2}} END {for (i=1;i<=NF;i++) {printf  sum[i]}}')
paste \
<(echo $SCAFFOLD ) \
<(echo $START ) \
<(echo $FINISH ) \
<(echo $NUM_BASES ) | \
sed 's/ /\t/g'| sed 's/\t\+/\t/g' >>  ${FILE/.bed/_density_regions.info}

done < <( cat `echo $FILE` )
done


FILES=($(ls *_500_density_regions.info | uniq))

for FILE in "${FILES[@]}"
do
echo $FILE
awk -v OFS='\t' '{print $1,$3-$2,$4,($4*100)/($3-$2)}' ${FILE} > ${FILE/.info/.info.counts}
done


##########
scp mlucena@genomics-a.ebd.csic.es:/home/mlucena/grupolince/Lynx_annotation/Lyp_annotation_Apr14_final/*density_regions.info.counts /Users/marialucenaperez/Dropbox/PhD/contemporary/subtelomeric_centromeric_analysis/
##########





 
# -> Filtering:

awk '{}'tel2m_merged_1000.bed



awk -v OFS='\t' '{for(i=1;i<=NF;i++) {sum[i] += $i; sumsq[i] += ($i)^2}} END {for (i=1;i<=NF;i++) {printf ("%.10e\n", sqrt((sumsq[i]-sum[i]^2/NR)/NR ))}}'




## Aquí determinamos regiones separadas por un máximo de 5000pb y posteriormente las filtramos para número de bases 1000 y 2000. 

sort -k1,1 -k2,2n /home/mlucena/grupolince/copia_fabascal/FEATURES/tel2m.bed | bedtools merge -d 5000  > tel2m_merged_5000.bed
cat /home/mlucena/grupolince/copia_fabascal/FEATURES/tel2m.bed /home/mlucena/grupolince/copia_fabascal/FEATURES/tel10m.bed | sort - -k1,1 -k2,2n |  bedtools merge -d 5000 > tel0-10m_merged_5000.bed
sort -k1,1 -k2,2n /home/mlucena/grupolince/copia_fabascal/FEATURES/centr.bed | bedtools merge -d 5000  > centr_merged_5000.bed

# -> Filtering:

```

# subtelomeric-centromeric_filtering.R

```{r, engine=bash, eval=FALSE}
library (ggplot2) 
library(dplyr)

df_tel2 <- read.delim ("/Users/marialucenaperez/Dropbox/PhD/contemporary/subtelomeric_centromeric_analysis/tel2m_bp_region_length.info", sep =" ", header=F) 

pdf ("/Users/marialucenaperez/Dropbox/PhD/contemporary/subtelomeric_centromeric_analysis/tel2.pdf")
ggplot(data=df_tel2,mapping = aes(x=V2))+
  geom_histogram(aes(y=cumsum(..count..)), binwidth = 100)+
 # stat_bin(aes(y=cumsum(..count..)),geom="line",color="green", binwidth= 50)+
  ggtitle("tel2m")
dev.off()

ggplot(data=df_tel2,mapping = aes(x=V2, y=V3))+
  geom_point()

df_tel0_10 <- read.delim ("/Users/marialucenaperez/Dropbox/PhD/contemporary/subtelomeric_centromeric_analysis/tel0-10m_bp_region_length.info", sep =" ", header=F) 

pdf ("/Users/marialucenaperez/Dropbox/PhD/contemporary/subtelomeric_centromeric_analysis/tel0-10.pdf")
ggplot(data=df_tel0_10,mapping = aes(x=V2))+
  geom_histogram(aes(y=cumsum(..count..)), binwidth = 100)+
#  stat_bin(aes(y=cumsum(..count..)),geom="line",color="green")+
  ggtitle("tel0-10m")
dev.off()

df_centr <- read.delim ("/Users/marialucenaperez/Dropbox/PhD/contemporary/subtelomeric_centromeric_analysis/centr_bp_region_length.info", sep =" ", header=F) 


pdf ("/Users/marialucenaperez/Dropbox/PhD/contemporary/subtelomeric_centromeric_analysis/centr.pdf")
ggplot(data=df_centr ,mapping = aes(x=V2))+
  geom_histogram(aes(y=cumsum(..count..)), binwidth = 100)+
#  stat_bin(aes(y=cumsum(..count..)),geom="line",color="green")+
  ggtitle("centr")
dev.off()

```


# subtelomeric_centromeric_histogram_representation

```{r}
library("ggplot2")
library ("ggExtra")

setwd ("/Users/marialucenaperez/Dropbox/PhD/contemporary/subtelomeric_centromeric_analysis/")
fins = list.files(pattern="*_density_regions.info.counts") 

for (i in 1:length(fins)) 
{
  dat <- read.csv (fins[i], sep = '\t',stringsAsFactors = FALSE, dec = ".",header=F)
  name <- unlist(strsplit(fins[i], "[.]"))
#  pdf(file = paste(name[1], '.pdf', sep=''))
#  print(ggplot (dat, aes(x=V4))+
#    geom_histogram(binwidth =1) +
#    ggtitle(label = name[1]))
#  dev.off()
  sp2 <- ggplot(dat,aes(x=V4,y=V2)) + geom_point(size=0.3) +  xlab("Density of nt in the region (%)") +  ylab("Length of the region") 
  plot <- ggMarginal(sp2, type = 'histogram', xparams = list(bins=200), yparams = list(bins=1000))
  pdf(file = paste(name[1], '_density.pdf', sep=''))
  # Marginal density plot
  print(plot)
  dev.off()
}


a<-ggMarginal (sp2, type = 'histogram', xparams = list(bins=200), yparams = list(bins=1000))
print(a)


