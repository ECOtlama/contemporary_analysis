---
title: "recent_demographic_reconstruction"
output: html_document
---

# IBDNe

Quiero obtener la reconstrucción demográfica reciente de las distintas poblaciones. Una forma de hacerlo es con IBDne que usa los tracks IBD. 

```{bash}
# Pruebo con ibdne: http://faculty.washington.edu/browning/ibdne.html#download
mkdir /home/mlucena/recent_demographic_reconstruction

# Copiamos el archivo IBD de Dani para probar: 
scp /home/GRUPOS/grupolince/lynx_genomes_5x/IBD_analysis/ngsF-HMM/c_ll_ki-c_ll_no-c_ll_po-c_lp_do-c_lp_sm_n060_ngsF-HMM.ibd recent_demographic_reconstruction/

# Copiamos un archivo VCF de Dani para probar: 
scp /home/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/annotation/ll_perspecies.trimmed_filtered1.ann.vcf /home/mlucena/recent_demographic_reconstruction

cd /home/mlucena/recent_demographic_reconstruction

# Obtengo un archivo map en plink 
/opt/plink_1.9/plink_1.9 --vcf /home/mlucena/recent_demographic_reconstruction/ll_perspecies.trimmed_filtered1.ann.vcf --maf 0.05 --recode --out /home/mlucena/recent_demographic_reconstruction/ll_perspecies.trimmed_filtered1.ann --const-fid 0 --allow-extra-chr


# Corro IBDNe:
cat c_ll_ki-c_ll_no-c_ll_po-c_lp_do-c_lp_sm_n060_ngsF-HMM.ibd | java -jar ibdne.07May18.6a4.jar map=/home/mlucena/recent_demographic_reconstruction/ll_perspecies.trimmed_filtered1.ann.map out=output

# No puedo pq necesita mapa gnetico de verdad.
# http://methodspopgen.com/methods-to-infer-populations-history/
# Saco la equivalencia basada en el mapa de ligamiento de gato (LaDeana et al. 2016) de bases a morgan. 
# Transformo el .map. --> Equivalencia: Si 100Mb son 1.9Morgan; 1 base=1900cM

cd /home/mlucena/recent_demographic_reconstruction

awk -v OFS='\t'  '{print $1, $4, $4*0.00000000019, $4}' ll_perspecies.trimmed_filtered1.ann.map > ll_perspecies.trimmed_filtered1.ann.w_genetic_distances.map

# 0.00000000019 son los cM a los que equivale una base. 

cat c_ll_ki-c_ll_no-c_ll_po-c_lp_do-c_lp_sm_n060_ngsF-HMM.ibd | java -jar ibdne.07May18.6a4.jar map=/home/mlucena/recent_demographic_reconstruction/ll_perspecies.trimmed_filtered1.ann.w_genetic_distances.map out=output

# Error tengo que eliminar los que sean valores unicos.

awk '{print $1}'  ll_perspecies.trimmed_filtered1.ann.w_genetic_distances.map | sort | uniq -u > scaffold_list_uniq_values.txt 

grep -v -F -f scaffold_list_uniq_values.txt ll_perspecies.trimmed_filtered1.ann.w_genetic_distances.map > ll_perspecies.trimmed_filtered1.ann.w_genetic_distances_no_unique.map

cat c_ll_ki-c_ll_no-c_ll_po-c_lp_do-c_lp_sm_n060_ngsF-HMM.ibd | java -jar ibdne.07May18.6a4.jar map=ll_perspecies.trimmed_filtered1.ann.w_genetic_distances_no_unique.map out=output


# Error en reading IBD
# Creo el IBD con IBDseq: http://faculty.washington.edu/browning/ibdseq.html

java -jar ibdseq.r1206.jar gt=ll_perspecies.trimmed_filtered1.ann.vcf out=ll_perspecies.trimmed_filtered1.ann.IBDseq

# Done! y está bien

# Pruebo a correr de nuevo el archivo ibd recién creado con ibdseq:

cat ll_perspecies.trimmed_filtered1.ann.IBDseq.ibd | java -jar ibdne.07May18.6a4.jar map=ll_perspecies.trimmed_filtered1.ann.w_genetic_distances_no_unique.map out=output filtersamples=false mincm=5e-06 nboots=0


# Exception in thread "main" java.lang.IllegalStateException: trim parameter for trimmed mean is too large
# Los trozos de IBD son demasiado pequeños. De hecho, si miro como es el más grande del scaffold 1 que es uno de los más largos: 
# lp23.s00001	13187672	0.00250566	13187672. 
# 0.00250566 es la distancia en cM al comienzo del scaffold. Si tenemos en cuenta que por defecto el programa filtra todo lo que sea menor a 2cM y además trima 0.2 cM para evitar problemas con el final del cromosoma; claramente nuestros fragmentos son muy pequeños. 

# mincm=[positive number]
#The mincm argument specifies the minimum IBD segment length in centiMorgan units. Any input IBD segments that have length shorter than the minimum length are ignored. The minimum IBD segment length should be sufficiently large so that IBD segments exceeding the minimum length are detected with high power and low false discovery rate (default: mincm=2).


``` 

Dead end. Siguiente aproximación.
(Primero limpio la carpeta porque nada de lo que hay aquí me va a servir).

# 1. SNeP

Para esta aproximación necesito un archivo ped y un archivo map. El programa me puede calcular el archivo de ld. 
Leer manual y artículo de Barbato donde presentan el método. 

Basicamente usan el calculo de LD para inferir Ne. LD se calcula como la r2 entre dos SNPs. Para ello la distancia genética puede ser una funcion de la distancia física y la tasa de recombinación, o se pueden añadir algunas correcciones para distancias muy grandes donde LD aparece saturado. 

Lo primero que tengo que hacer es lograr un VCF por población.

Para ello, uso los VCF de Dani que se supone que están limpios y filtrados. 

La carpeta donde voy a hacer los análisis ya la tengo generada y es: /home/mlucena/recent_demographic_reconstruction

## Split VCF into different pops.


```{bash}

cd /home/mlucena/recent_demographic_reconstruction

# VCF que voy a usar están en la carpeta: /home/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/annotation/

# Los dos archivos útiles son:

# ll_perspecies.trimmed_filtered1.ann.vcf
# lp_perspecies.trimmed_filtered1.ann.vcf

# Los voy a copiar a mi carpeta de reconstrucción demográfica para que no haya ningún problema si los rompo.

scp /home/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/annotation/ll_perspecies.trimmed_filtered1.ann.vcf /home/mlucena/recent_demographic_reconstruction
scp /home/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/annotation/lp_perspecies.trimmed_filtered1.ann.vcf /home/mlucena/recent_demographic_reconstruction

# Primero tengo que sacar una lista con todos los individuos de cada población que hay. 

bcftools query -l ll_perspecies.trimmed_filtered1.ann.vcf > list_of_samples_c_ll
bcftools query -l lp_perspecies.trimmed_filtered1.ann.vcf > list_of_samples_c_lp

# Lista de las poblaciones que tenemos. 
declare POPS=$(bcftools query -l ll_perspecies.trimmed_filtered1.ann.vcf | cut -c1-7 | sort | uniq)
declare POPS=$(bcftools query -l lp_perspecies.trimmed_filtered1.ann.vcf | cut -c1-7 | sort | uniq)

# Voy a iterar sobre las distintas poblaciones para hacer una lista con los ind de esa poblacion. 
for POP in ${POPS[@]}
do
echo $POP
grep $POP list_of_samples_c_ll > $POP.list
done

rm list_of_samples_c_ll

for POP in ${POPS[@]}
do
echo $POP
grep $POP list_of_samples_c_lp > $POP.list
done

rm list_of_samples_c_lp


# Ahora lo modifico un poco a mano. Voy a eliminar las de balcanes que no nos interesan y voy a unir mongolia, que lo vamos a considerar una población. 

# Compruebo que así borro lo que me interesa 
ls -ltr *ba*
# Borro
# rm *ba*

# Borro también pais vasco
rm h_ll_pv.list

# Hago cat de mongolia
cat c_ll_og.list c_ll_to.list c_ll_ka.list > c_ll_mo.list

rm c_ll_og.list 
rm c_ll_to.list 
rm c_ll_ka.list


# Perfecto!
# Ahora lanzo el script para separa por poblaciones.

screen -S separate_VCF_by_pop_pardinus

GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
#VCF=ll_perspecies.trimmed_filtered1.ann.vcf
VCF=lp_perspecies.trimmed_filtered1.ann.vcf
REF=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome

for POP_list in c_lp*.list
  do
  declare POP=$(echo $POP_list | cut -d "." -f1 )
  echo "${POP}"
     java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
    -T SelectVariants \
    -R $REF \
    -V $VCF \
    -o ${VCF/.vcf/.$POP.vcf} \
    --sample_file $POP_list \
    --preserveAlleles
    done

# Sanity check
# ¿Está quitando lo que me interesa?

bcftools query -l ll_perspecies.trimmed_filtered1.ann.c_ll_ya.vcf 


# Ahora nos vamos a quedar solo con los de intergénico.


task(){
   bedtools intersect -a $i -b /GRUPOS/grupolince/Lyp_annotation_Apr14_final/LYPA23C.intergenic.PLUS1000.bed -sorted -g /home/mlucena/grupolince/lynx_genomes_5x/BAM_files_final/BAM_intergenic_5x/lp23.version.sorted.genome -header > ${i/.vcf/_intergenic.vcf}
}


for i in *c_l*vcf
do
echo $i
 task "$i" 
done


# De todas formas hay muchos scaffold que tiene muy pocos SNPs, así que el autor me recomienda que lo filtre. Puedo filtrar primero para los scaffolds que tiene al menos 1000 SNPs y luego los que tienen 2000 SNPs. Y así hacer una pruebecilla para ver si los datos son parecidos, me puedo quedar con el dataset más pequeño. 

for vcf_POP in *c_l*_intergenic.vcf
do
echo $vcf_POP
declare POP=$(echo $vcf_POP | cut -d "." -f4 )
# Ahora contamos el número de SNPS por scaffold

grep -v -E '^#'  $vcf_POP | cut -f 1 | sort | uniq -c | sort -n | awk '$1>2000{print $2}' | sort | sed -n -e 'H;${x;s/\n/,/g;s/^,//;p;}' > "${POP}"_more_than_2000_SNPS_per_scaffold.list
grep -v -E '^#'  $vcf_POP | cut -f 1 | sort | uniq -c | sort -n | awk '$1>1000{print $2}' | sort | sed -n -e 'H;${x;s/\n/,/g;s/^,//;p;}' > "${POP}"_more_than_1000_SNPS_per_scaffold.list
bcftools query -l $vcf_POP 
bgzip $vcf_POP 
bcftools index "${vcf_POP}".gz
bcftools view -r `cat "${POP}"_more_than_2000_SNPS_per_scaffold.list` "${vcf_POP}".gz -Ov -o "${vcf_POP/.vcf/_filtered_more_than_2000_SNPS.vcf}"
bcftools view -r `cat "${POP}"_more_than_1000_SNPS_per_scaffold.list` "${vcf_POP}".gz -Ov -o "${vcf_POP/.vcf/_filtered_more_than_1000_SNPS.vcf}"
done

```


Ahora que ya tengo los VCF por población para las dos especies lo que tengo que hacer es generar el archivo map y ped de cada población.

## Generate ped and map file

```{bash}

cd /home/mlucena/recent_demographic_reconstruction


VCFs=$(ls *.c_l*more_than_2000_SNPS.vcf)

for VCF_per_pop in ${VCFs[@]}
do 
echo $VCF_per_pop
declare POP=$(echo $VCF_per_pop | cut -d "." -f4 )
/opt/plink_1.9/plink_1.9 --vcf $VCF_per_pop --maf 0.05 --recode --out "${POP}"_maf005 --const-fid 0 --allow-extra-chr
done



```


## Copy to UBUNTU local

SNeP sólo corre en Ubunto 14.04 o en windows, por tanto me he tenido que crear una máquina virtual en local que tenga instalado ubuntu. Así que lo primero que tngo que hacer es bajarme los archivos a este ordenador. 

Me meto en mi máquina virtual, y una vez ahí me los bajo.

```{bash}

# En local--> Maquina virtual --> Ubuntu. 

mkdir /home/maria/SneP

scp mlucena@genomics-b.ebd.csic.es:/home/mlucena/recent_demographic_reconstruction/*ped /home/maria/SneP
scp mlucena@genomics-b.ebd.csic.es:/home/mlucena/recent_demographic_reconstruction/*map /home/maria/SneP

```

## SNeP

```{bash}

cd /home/maria/SneP

for PED_FILE in *.ped
do
declare POP=$(echo $PED_FILE | cut -d "." -f 1)
#declare SAMPLE_SIZE=$(grep $POP sample_size_file.csv | cut -d"," -f 2)
SNePv1.1 -ped $PED_FILE -out ./$POP -ld -recrate 1.9e-8  -svedf -samplesize 1 #The sex-averaged recombination rate across the cat genome was 1.9 cM/Mb (see: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4889657/)
done

# Otras variantes del script están en mi máquina virtual en UBUNTU.
```

## Copy back to the server & to mac local

```{bash}
# Copy to server

cd /home/maria/SneP

scp /home/maria/SneP/*Ne* mlucena@genomics-b.ebd.csic.es:/home/mlucena/recent_demographic_reconstruction/

mkdir /Users/marialucenaperez/Owncloud/publico/Eurasian_lynx_phylogeography/recent_demographic_reconstruction

scp mlucena@genomics-b.ebd.csic.es:/home/mlucena/recent_demographic_reconstruction/SNeP/*NeAll /Users/marialucenaperez/Owncloud/publico/PhD/Eurasian_lynx_phylogeography/recent_demographic_reconstruction/SNeP/

```


## R representation

```{r}
# Leo la tabla de Ne.

library (data.table)
library(ggplot2)
library (dplyr)
library (magrittr)
library(plyr)
library (tidyr)
library(viridis)

wd <- "/Users/marialucenaperez/Owncloud/publico/PhD/Eurasian_lynx_phylogeography/recent_demographic_reconstruction/SNeP/"


sample_files = list.files(path = wd, pattern="*NeAll$")
list_Ne<- lapply( sample_files, function (x) 
     # Aquí leo la tabla
  fread(paste0(wd,x)))
#names the list using the basename from `l`
# this also is the step to manipuly the filesnamaes to whatever you like
names(list_Ne) <- basename( sample_files )
#bind the rows from the list togetgher, putting the filenames into the colum "id"
Ne_reconstruction <- rbindlist( list_Ne, idcol = "pop1" ) %>% 
  # Corto este string para que sea igual en los dos dataset
  mutate(pop=substr(.$pop1, 1, 7) ) %>% 
  # Elimino el valor que no me interesa
  select (-pop1)%>% 
  mutate (., Populations =  ifelse (pop == "c_ll_po", "NE-Poland",
                          ifelse (pop == "c_ll_ur", "Urals",
                          ifelse (pop == "c_ll_ki", "Kirov",
                          ifelse (pop == "c_ll_la", "Latvia",
                          ifelse (pop == "c_ll_no", "Norway",
                          ifelse (pop == "c_ll_ba" | pop == "h_ll_ba", "Balkans" ,
                          ifelse (pop == "c_ll_cr","Carpathians",
                          ifelse (pop == "c_ll_to", "Töv",
                          ifelse (pop == "c_ll_tu", "Tuva",
                          ifelse (pop == "c_ll_ka", "Khentii-Aimag",
                          ifelse (pop == "c_ll_mo", "Mongolia",
                          ifelse (pop == "c_ll_og", "Ömnögovi", 
                          ifelse (pop == "c_ll_vl", "Vladivostok", 
                          ifelse (pop == "c_ll_ya", "Yakutia",
                          ifelse (pop == "c_lp_sm", "Sierra Morena",
                          ifelse (pop == "c_lp_do", "Doñana", NA))))))))))))))))) %>% 
  mutate(YBP=GenAgo*5)


cols <- c("NE-Poland"=viridis_pal()(5)[3], 
          "Urals"="#0F4909", 
          "Carpathians"=brewer.pal(12,"Paired")[9], 
          "Kirov"=viridis_pal()(5)[1], 
          "Latvia"=brewer.pal(12,"Paired")[3], 
          "Norway"=viridis_pal()(5)[2], 
          "Mongolia"=brewer.pal(12,"Paired")[12], 
          "Tuva"=brewer.pal(12,"Paired")[8], 
          "Vladivostok"=brewer.pal(12,"Paired")[5], 
          "Yakutia"=brewer.pal(12,"Paired")[6])


 ggplot (Ne_reconstruction, aes(YBP, Ne, fill=Populations, colour=Populations)) +
    geom_point(alpha=0.1) +
    geom_smooth() + 
    theme_classic() +
    scale_colour_manual(values = cols)+
    scale_fill_manual(values = cols) +
   ggsave(paste(wd,"all_pop.pdf", sep=""), device = "pdf")


 
 



for (i in 1:length(finsNeAll))
{
  datNeAll <- read.csv (paste(wd,finsNeAll [i],sep=""), header = T, sep = '\t')  
  name_NeAll <- unlist(strsplit(finsNeAll [i], "[.]"))
  ggplot (datNeAll, aes(GenAgo, Ne)) +
    geom_point(alpha=0.1) +
    geom_smooth(color="grey24", fill="grey64") +
    theme_classic() +
    ggtitle(paste(name_NeAll[1]))
  ggsave(paste(wd,name_NeAll[1],"_", name_NeAll[2],".pdf", sep=""), device = "pdf")
}
 

```

# 2. Stairway plot

Vamos a correr un programa que se llama stairway plot que genera un skyline plot demográfico. Este programa corre en java. Como entrada necesita: numero de sitios monomórficos + polimorficos, el sfs, y el número de alelos (numero de individuos * 2). Todos estos datos los tengo en el espectro de frecuencias alélicas, que aunque está expresado en likelihood, el programa lo acepta. 

Para que corra tienes que generar un archivos txt que el programa transforma en sh usando java, y despues este .sh se lanza. 
Un ejemplo de un archivo de entrada es este (en mi ordenador):


```{bash}
cat /Users/marialucenaperez/Documents/stair_way_plot/stairway_plot_v2/two-epoch.blueprint 
#example blueprint file
#input setting
popid: two-epoch # id of the population (no white space)
nseq: 30 # number of sequences
L: 10000000 # total number of observed nucleic sites, including polymorphic and monomorphic
whether_folded: false # whethr the SFS is folded (true or false)
SFS: 9513.26	3796.47	2106.24	1351.505	962.91	736.865	597.75	499.845	429.99	381.62	341.965	310.27	284.87	261.28	242.11	230.055	217.975	204.48	197.28	185.545	176.055	167.62	161.55	154.935	147.83	142.17	137.31	133.3	124.955   # snp frequency spectrum: number of singleton, number of doubleton, etc. (separated by white space)
#smallest_size_of_SFS_bin_used_for_estimation: 2 # default is 1; to ignore singletons, change this number to 2
#largest_size_of_SFS_bin_used_for_estimation: 28 # default is n-1; to ignore singletons, change this number to nseq-2
pct_training: 0.67 # percentage of sites for training
nrand: 7	15	22	28 # number of random break points for each try (separated by white space)
project_dir: two-epoch # project directory
stairway_plot_dir: stairway_plot_es # directory to the stairway plot files
ninput: 200 # number of input files to be created for each estimation
#output setting
mu: 1.2e-8 # assumed mutation rate per site per generation
year_per_generation: 24 # assumed generation time (in years)
#plot setting
plot_title: two-epoch # title of the plot
xrange: 0.1,10000 # Time (1k year) range; format: xmin,xmax; "0,0" for default
yrange: 0,0 # Ne (1k individual) range; format: xmin,xmax; "0,0" for default
xspacing: 2 # X axis spacing
yspacing: 2 # Y axis spacing
fontsize: 12 # Font size
```

Los parámetros que cambiamos son:
popid --> nombre de la población.
nseq --> numero de individuos * 2
L --> numero total de sitios incluyendo ambos, monomórficos y polimórficos.
whether_folded --> en mi caso, false, porque tengo un unfolded.
pct_training --> se deja igual.
nrand --> se calcula según la formula: number of random break points for each try (separated by white space). We suggest to use 4 numbers, roughly (nseq-2)/4, (nseq-2)/2, (nseq-2)*3/4, nseq-2. The range of the numbers is between 1 and nseq-2. The smaller the number, the more likely the estimation may underfit the training data. The larger the number, the more likely the estimation may overfit the training data. Stairway plot will pick the best number (among the numbers specified here) to control overfitting based on the remaining 1-pct_training sites used as testing data.
project_dir --> en esta carpeta se guarda el resultado.
stairway_plot_dir --> no se toca.
ninput --> no se toca.
mu --> mutation_rate, en mi caso voy a poner la de lince: 6e-9
year_per_generation --> 5 en mi caso.
plot_title --> nombre del plot
xrange --> no se toca
yrange --> no se toca
xspacing --> no se toca
yspacing --> no se toca
fontsize --> no se toca

Lo primero que voy a hacer es hacerme uno base para poder modificarlo.

## Template generation

Creo un template para poder completarlo

nano POPULATION.blueprint

```{}
#!/bin/sh

#define parameters which are passed in
POP=$1
NSEQ=$2
NSITES=$3

#define the template.
cat  << EOF
popid: $POP
nseq: $NSEQ
L: $NSITES
whether_folded: false 
SFS: $SFS
#smallest_size_of_SFS_bin_used_for_estimation: 2 
#largest_size_of_SFS_bin_used_for_estimation: 28 
pct_training: 0.67 
nrand: $NRAD
project_dir: $POP/
stairway_plot_dir: stairway_plot_es 
ninput: 200 
#output setting
mu: 6e-9
year_per_generation: 5
#plot setting
plot_title: $POP
xrange: 0.1,10000 
yrange: 0,0 
xspacing: 2 
yspacing: 2 
fontsize: 12
EOF

```


Ahora hago un loop para que rellene los campos que tiene que modificar

## Loop for generating the files

Primero miro la carpeta donde están mis sfs.

```{bash}
locate *intergenic_sfs*sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_cr_n006.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_ki_n013.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_la_n006.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_no_n008.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_po_n008.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_to-c_ll_ka-c_ll_og_n008.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_tu_n006.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_ur_n006.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_vl_n008.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_ya_n008.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/x_ll_ba_n003.unfolded-lr.sfs
```

Ahora por cada uno de los sfs, debo hacer el loop correspondiente:

```{bash}

# El script para que rellene los campos serían este:
cd /home/mlucena/recent_demographic_reconstruction/stairway_plot
# RUTA_SFS="/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs" # para boreal
# RUTA_SFS="/home/mlucena/ANGSD_analysis/whole_genome_analysis/sfs" # para pardinus

for SFS_FILE in $RUTA_SFS/c_lp*sfs;
do

SFS_FILE_NAME=`echo $SFS_FILE | rev | cut -d"/" -f 1 | rev ` 
POP=${SFS_FILE_NAME/\.unfolded\-lr\.sfs/}
echo $POP
NSEQ=`echo ${POP: -3}*2 | bc`
NSITES=`gawk '{for(i=1;i<=NF;i++)s+=$i;printf("%.0f\n", s)}' $SFS_FILE`
SFS=`cat $SFS_FILE | cut -d" " -f 2- $SFS_FILE | rev | sed -e 's/^[ \t]*//' | cut -d" " -f 2- | rev`
NRAD1=`echo $(( (NSEQ -2) / 4 ))`
NRAD2=`echo $(( (NSEQ -2) / 2 ))`
NRAD3=`echo $(( (NSEQ -2) * 3/4 ))`
NRAD4=`echo $(( NSEQ -2 ))`
NRAD=`echo $NRAD1 $NRAD2 $NRAD3 $NRAD4`

mkdir $POP
cd $POP

scp -r ../stairway_plot_es .

../POPULATION.blueprint """$POP""" """$NSEQ""" """$NSITES""" """$SFS""" """$NRAD""" > $POP.blueprint
# Así creo las carpetas
java -cp ../stairway_plot_es Stairbuilder $POP.blueprint
# Voy a lanzar de una en una, porque quiero lanzar varias a la vez. 
# HOW TO RUN THE ANALYSIS
echo RUN $POP!

chmod 700 $POP.blueprint.sh
./$POP.blueprint.sh

cd ..
touch $POP.borrar

done


```

# Run the analysis

```{bash}
./two-epoch_c_ll_ya_n008.blueprint.sh 

# Para pintar solo el plot

java -Xmx1g -cp stairway_plot_es/ Stairpainter c_lp_sm_n012.blueprint

```


# R: Custom drawing

Primero tengo que coger los dtos de los que se hace el dibujo. Estan en un archivo que se llama .final.summary, en cada carpeta de cada poblacion. Voy a pintarlos todos juntos, así que creo una super carpeta, que ya separaré si lo necesito en R. Aquí solo añado la info que me interesa. 


En el archivo que se llama summary con el que puedo pintar:

1st col: time measured in the expected number of mutation(s) per site
2nd col: number of estimates used
3rd col: the median of the population size measured in θ per site
4th col: the 2.5 percentile estimation of the population size measured in θ per site
5th col: the 97.5 percentile estimation of the population size measured in θ per site
6th col: time measured in years
7th col: the median of the population size measured in individuals
8th col: the 2.5 percentile estimation of the population size measured in individuals
9th col: the 97.5 percentile estimation of the population size measured in individuals
10th col: the 12.5 percentile estimation of the population size measured in individuals
11th col: the 87.5 percentile estimation of the population size measured in individuals

Copio la columna 7, 8, 9, 10, 11.

```{bash}

cd /home/mlucena/recent_demographic_reconstruction/stairway_plot
# Creo la carpeta donde vamos a guardar nuestro archivo de interes =
mkdir /home/mlucena/recent_demographic_reconstruction/stairway_plot/custom_output

# Creo el header para el archivo que voy a generar
cd /home/mlucena/recent_demographic_reconstruction/stairway_plot/c_ll_cr_n006/c_ll_cr_n006
head -n1 c_ll_cr_n006.final.summary |  awk -v OFS='\t' '{print $6, $7, $8, $9, $10, $11, "population", "specie"}' > /home/mlucena/recent_demographic_reconstruction/stairway_plot/custom_output/final_summary_custom_output.tsv 

# First we summarise the output files, and add a column with info of interest
populations=(c_ll_cr_n006 c_ll_ki_n013 c_ll_la_n006 c_ll_no_n008 c_ll_po_n008 c_ll_to-c_ll_ka-c_ll_og_n008 c_ll_tu_n006 c_ll_ur_n006 c_ll_vl_n008 c_ll_ya_n008 c_lp_do_n012 c_lp_sm_n019)


# Loop para concatenar las distintas poblaciones. 
cd /home/mlucena/recent_demographic_reconstruction/stairway_plot
for population in ${populations[@]}
do
echo $population
cd /home/mlucena/recent_demographic_reconstruction/stairway_plot/$population/$population
sp=`echo $population | cut -d'.' -f 1 | cut -d '_' -f 2`
if [ -z ${sp} ]; then  sp=NA;  fi
awk -v OFS='\t' -v pop="$population" -v sp="$sp" '{print $6, $7, $8, $9, $10, $11, pop, sp }' <(tail -n+2 "${population}".final.summary) >> /home/mlucena/recent_demographic_reconstruction/stairway_plot/custom_output/final_summary_custom_output.tsv
unset sp
cd /home/mlucena/recent_demographic_reconstruction/stairway_plot

done

```

Me lo copio al local

```{bash}

scp mlucena@genomics-b.ebd.csic.es://home/mlucena/recent_demographic_reconstruction/stairway_plot/custom_output/final_summary_custom_output.tsv /Users/marialucenaperez/Owncloud/publico/PhD/Eurasian_lynx_phylogeography/recent_demographic_reconstruction/stairway_plot/custom_plot_script 

```

Script para pintarlo

```{r}
library(viridis)
library(ggplot2); theme_set(theme_minimal())
library(tidyr)
library(tidyverse)
library(plyr)
library(dplyr)
library(data.table)
library(RColorBrewer)



wd <- "/Users/marialucenaperez/Owncloud/publico/PhD/Eurasian_lynx_phylogeography/recent_demographic_reconstruction/stairway_plot/custom_plot_script/"
wd_output <- "/Users/marialucenaperez/Owncloud/publico/PhD/Eurasian_lynx_phylogeography/recent_demographic_reconstruction/stairway_plot/custom_plot_script/output_R/"

demographic_data_all_pops <- read.table(paste(wd, "final_summary_custom_output.tsv", sep=""), header=T, na.strings = c("NA", "na")) 

# Lynx pardinus

demographic_data_lp <- demographic_data_all_pops %>% filter(specie=="lp") %>% filter(year>100) %>% filter(year<100000)

# https://ggplot2.tidyverse.org/reference/annotation_logticks.html
ggplot () +
  geom_line(data=demographic_data_lp , aes(x=year, y=Ne_median, group=population, colour=population)) +
  #scale_colour_manual(values = cols) +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))
) +
  annotation_logticks()


# Lynx lynx

demographic_data_ll <- demographic_data_all_pops %>% filter(specie=="ll") %>% filter(year>1) %>% 
  mutate (., Populations =  ifelse (population == "c_ll_po_n008", "NE-Poland",
                           ifelse (population == "c_ll_ur_n006", "Urals", 
                           ifelse (population == "c_ll_ki_n013", "Kirov", 
                           ifelse (population == "c_ll_la_n006", "Latvia", 
                           ifelse (population == "c_ll_no_n008", "Norway", 
                           ifelse (population == "c_ll_cr_n006","Carpathians", 
                           ifelse (population == "c_ll_to-c_ll_ka-c_ll_og_n008", "Mongolia", 
                           ifelse (population == "c_ll_tu_n006", "Tuva", 
                           ifelse (population == "c_ll_vl_n008", "Vladivostok",  
                           ifelse (population == "c_ll_ya_n008", "Yakutia", NA))))))))))) %>% 
  mutate (., region =  ifelse (population == "c_ll_po_n008", "West",
                           ifelse (population == "c_ll_ur_n006", "West", 
                           ifelse (population == "c_ll_ki_n013", "West", 
                           ifelse (population == "c_ll_la_n006", "West", 
                           ifelse (population == "c_ll_no_n008", "West", 
                           ifelse (population == "c_ll_cr_n006","West", 
                           ifelse (population == "c_ll_to-c_ll_ka-c_ll_og_n008", "East", 
                           ifelse (population == "c_ll_tu_n006", "East", 
                           ifelse (population == "c_ll_vl_n008", "East",  
                           ifelse (population == "c_ll_ya_n008", "East", NA))))))))))) %>%  
  mutate (., conservation = ifelse (population == "c_ll_po_n008", "Impacted",
                           ifelse (population == "c_ll_ur_n006", "Not_impacted", 
                           ifelse (population == "c_ll_ki_n013", "Not_impacted", 
                           ifelse (population == "c_ll_la_n006", "Not_impacted", 
                           ifelse (population == "c_ll_no_n008", "Impacted", 
                           ifelse (population == "c_ll_cr_n006","Impacted", 
                           ifelse (population == "c_ll_to-c_ll_ka-c_ll_og_n008", "Not_impacted", 
                           ifelse (population == "c_ll_tu_n006", "Not_impacted", 
                           ifelse (population == "c_ll_vl_n008", "Not_impacted",  
                           ifelse (population == "c_ll_ya_n008", "Not_impacted", NA))))))))))) %>% filter(year<100000) %>% # filter(year>100) %>%
  mutate(.,period = ifelse (year<1000, "recent", 
                            ifelse (year<10000, "holocene",
                                    ifelse(year<100000, "pleistocene", NA)))
)


### PLOTS:



cols <- c("NE-Poland"=viridis_pal()(5)[3], 
          "Urals"="#0F4909", 
          "Carpathians"=brewer.pal(12,"Paired")[9], 
          "Kirov"=viridis_pal()(5)[1], 
          "Latvia"=brewer.pal(12,"Paired")[3], 
          "Norway"=viridis_pal()(5)[2], 
          "Mongolia"=brewer.pal(12,"Paired")[12], 
          "Tuva"=brewer.pal(12,"Paired")[8], 
          "Vladivostok"=brewer.pal(12,"Paired")[5], 
          "Yakutia"=brewer.pal(12,"Paired")[6])



# Last 100 yrs
ggplot () +
  geom_line(data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=Populations, linetype=region)) +
  scale_colour_manual(values = cols) +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))
) +
  annotation_logticks() +
  coord_cartesian(xlim=c(1,100),ylim=c(0,1000)) 
ggsave(paste(wd_output, "stairway_plot_custom_xlim1-100_ylim0-1000_color_per_pop_line_type_region.pdf",sep=""))


twelve_col_pals = brewer.pal.info[brewer.pal.info$maxcolors == '12',] 
col_vector = unlist(mapply(brewer.pal, twelve_col_pals$maxcolors, rownames(twelve_col_pals)))
# pie(rep(1,n), col=sample(col_vector, n))
my_paired_colours <- as.vector(col_vector)


ggplot () +
  geom_line(data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=region, linetype=region)) +
scale_fill_manual(values=my_paired_colours) +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))
) +
  annotation_logticks() +
  coord_cartesian(xlim=c(1,100),ylim=c(0,1000)) 
ggsave(paste(wd_output, "stairway_plot_custom_xlim1-100_ylim0-1000_color_region_line_type_region.pdf",sep=""))



# Last 200 yrs
ggplot () +
  geom_line(data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=Populations, linetype=region)) +
  scale_colour_manual(values = cols) +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))
) +
  annotation_logticks() +
  coord_cartesian(xlim=c(1,200),ylim=c(0,2000)) 
ggsave(paste(wd_output, "stairway_plot_custom_xlim1-200_ylim0-2000_color_per_pop_line_type_region.pdf",sep=""))


twelve_col_pals = brewer.pal.info[brewer.pal.info$maxcolors == '12',] 
col_vector = unlist(mapply(brewer.pal, twelve_col_pals$maxcolors, rownames(twelve_col_pals)))
# pie(rep(1,n), col=sample(col_vector, n))
my_paired_colours <- as.vector(col_vector)


ggplot () +
  geom_line(data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=region, linetype=region)) +
scale_fill_manual(values=my_paired_colours) +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))
) +
  annotation_logticks() +
  coord_cartesian(xlim=c(1,200),ylim=c(0,2000)) 
ggsave(paste(wd_output, "stairway_plot_custom_xlim1-200_ylim0-2000_color_region_line_type_region.pdf",sep=""))


# Last 1000ya
ggplot () +
  geom_line(data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=Populations, linetype=region)) +
  scale_colour_manual(values = cols) +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))
) +
  annotation_logticks() +
  coord_cartesian(xlim=c(1,1000),ylim=c(0,5000)) 
ggsave(paste(wd_output, "stairway_plot_custom_xlim1-1000_ylim0-5000_color_per_pop_line_type_region.pdf",sep=""))


twelve_col_pals = brewer.pal.info[brewer.pal.info$maxcolors == '12',] 
col_vector = unlist(mapply(brewer.pal, twelve_col_pals$maxcolors, rownames(twelve_col_pals)))
# pie(rep(1,n), col=sample(col_vector, n))
my_paired_colours <- as.vector(col_vector)


ggplot () +
  geom_line(data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=region, linetype=region)) +
scale_fill_manual(values=my_paired_colours) +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))
) +
  annotation_logticks() +
  coord_cartesian(xlim=c(1,1000),ylim=c(0,5000)) 
ggsave(paste(wd_output, "stairway_plot_custom_xlim1-1000_ylim0-5000_color_region_line_type_region.pdf",sep=""))




# All periods

ggplot () +
  geom_line(data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=Populations, linetype=region)) +
  scale_colour_manual(values = cols) +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))
) +
  theme_classic() +
  annotation_logticks() +
ggsave(paste(wd_output, "stairway_plot_custom_color_per_pop_line_type_region.pdf",sep=""), width = 5, height = 7)



ggplot () +
  geom_line(data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=Populations, linetype=region)) +
  #geom_point(data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=region))+
  geom_smooth(method="lm", data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=Populations)) +
  scale_colour_manual(values = cols) +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))) +
   scale_y_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  annotation_logticks() +
  theme_classic() +
ggsave(paste(wd_output, "stairway_plot_custom_color_region_line_type_region.pdf",sep=""), width = 5, height = 7)


```

#### Effect of drift on the populations
```{r}


# Formula of lost of diversity:

ratio_Hf_Ho_formula <- function(Ne, t) {
  ratio_Hf_Ho <- (1 - 1/Ne)^t
  return(ratio_Hf_Ho)}

# Time
t=5000-200

# 
harmonic_mean_Ne_ratio_Hf_Ho_by_pop <- demographic_data_ll %>%  filter(year>200) %>%  filter(year<5000) %>% group_by(population) %>% summarise(media_harmonica=harmonic.mean(Ne_median), ratio_Hf_Ho=ratio_Hf_Ho_formula(media_harmonica, t))

# Tengo que ratio Hf/Ho para mis poblaciones segun la formula es uno. 
# Como asumo que parten de una población inicial que es igual, puedo ver como se relaciona con mi ratio de diversidad empirica.

# Valor para kirov del ratio: 0.102
# Valor para polonia: 0.00414

# Ratio de ambas Hfhealthy/Hferoded

# kirov-poland
0.102/0.00414
#24.63768
0.153/0.0109
# Kirov-Norway
0.102/0.00104
# 98.07692


# Ratio empírico
# pop     watterson pi
# Yakutia	4,50E-04	5,27E-04
# Ural m.	3,95E-04	4,51E-04
# Tuva	4,89E-04	5,45E-04
# Primorsky Krai	4,25E-04	5,01E-04
# Norway	2,66E-04	3,41E-04
# NE-Poland	2,86E-04	3,67E-04
# Mongolia	4,63E-04	5,36E-04
# Latvia	3,74E-04	4,38E-04
# Kirov	3,58E-04	4,64E-04
# Carpathian m.	3,15E-04	3,74E-04

# kirov-poland

# Pi kirov/Poland
4.64E-04/3.67E-04
# 1.26
# Watterson Kirov/Poland
3.58E-04/2.86E-04
# 1.251748

# Kirov-Norway

# Pi kirov/Norway
3.58E-04/2.66E-04
# 1.345865

# Mi ratio empírico es más pequeño, porque o bien la diversidad de polonia/Norway es mayor que la esperada, o la de kirov, menor. 




```

# 3. NE-Estimator

Primero voy a generar 5 dataset por poblacion con un 1% de los SNPs que tienen en el original para que pueda correr el programa.

```{bash}
# los files con SNPs están en la carpeta: home/mlucena/recent_demographic_reconstruction/SNeP

cd /home/mlucena/recent_demographic_reconstruction/SNeP
VCF_FILES=($(ls *intergenic_filtered_more_than_2000_SNPS.vcf | uniq))
mkdir /home/mlucena/recent_demographic_reconstruction/Ne_Estimator
OUTPUT_PATH="/home/mlucena/recent_demographic_reconstruction/Ne_Estimator"


for VCF_FILE in ${VCF_FILES[@]}
do
echo $VCF_FILE
echo 1
vcfrandomsample -r 0.04 $VCF_FILE > $OUTPUT_PATH/${VCF_FILE/.vcf/_subset1.vcf}
echo 2
vcfrandomsample -r 0.04 $VCF_FILE > $OUTPUT_PATH/${VCF_FILE/.vcf/_subset2.vcf}
echo 3
vcfrandomsample -r 0.04 $VCF_FILE > $OUTPUT_PATH/${VCF_FILE/.vcf/_subset3.vcf}
echo 4
vcfrandomsample -r 0.04 $VCF_FILE > $OUTPUT_PATH/${VCF_FILE/.vcf/_subset4.vcf}
echo 5
vcfrandomsample -r 0.04 $VCF_FILE > $OUTPUT_PATH/${VCF_FILE/.vcf/_subset5.vcf}
done


# ¿Cuantos SNPs me quedan?

cd /home/mlucena/recent_demographic_reconstruction/Ne_Estimator
VCF_FILES=($(ls *.vcf | uniq))
for VCF_FILE in ${VCF_FILES[@]}
do
echo $VCF_FILE
grep -v "#" $VCF_FILE | wc -l
done


# Me los copio

scp -p mlucena@genomics-b.ebd.csic.es:///home/mlucena/recent_demographic_reconstruction/Ne_Estimator/*vcf /Users/marialucenaperez/Owncloud/publico/PhD/Eurasian_lynx_phylogeography/recent_demographic_reconstruction/Ne_estimator 

```


Ahora sobre estos archivos genero los GENEPOP usando PGD spider. 
Despues el archivo genepop generado lo corro en Ne-Estimator. 


# 4. LinkNe

Daniel Kleinman y María Lucena. Seguimos las indicaciones de https://github.com/chollenbeck/LinkNe

##Puesta a punto del programa:
```{bash}

#Primero descargo el programa de https://github.com/chollenbeck/LinkNe y lo guardo en mi ordenador en /Users/dani/ownCloud/publico/Eurasian lynx phylogeography/recent_demographic_reconstruction/LinkNe/input/LinkNe-master/

#Pruebo a lanzarlo sin archivos de entrada y me da un error de perl de ausencia de dependencias necesarias. Desde la terminal, descargo en mi ordenador los siguientes módulos:
cpan Data::Dumper
cpan Getopt::Long
cpan Pod::Usage
cpan Statistics::Distributions

```

##Obtención de los archivos input:
###Matrices de tasas de recombinación (muy lento, descartado).
```{bash}

cd /Users/dani/ownCloud/publico/Eurasian\ lynx\ phylogeography/recent_demographic_reconstruction/LinkNe/input/

#En primer lugar, pasamos de vcf a bed para que los archivos sean más manejables.
INPUT_VCFS=$(ls *.vcf)
for vcf in ${INPUT_VCFS[@]}
  do
  POP=$(echo ${vcf} | cut -d'.' -f 4 | cut -d'_' -f-3)
  echo ${POP}
  ggrep -v '#' ${vcf} | awk -F"\t" '{printf ("%s\t%s\t%s\n", $1,$2-1,$2)}' > ${vcf/.vcf/.bed}
  done

#En segundo lugar, para cada archivo de población iteramos sobre cada posición y calculamos la distancia física respecto a cada una de las otras posiciones (si están en el mismo scaffold), y convertimos a distancia genética (asumimos 0.5 si están en distintos scaffolds). Guardamos dichos valores en columnas (una por cada posición) que vamos uniendo en un solo archivo. Es lentísimo, tardaría meses o años.
FILE=lp_perspecies.trimmed_filtered1.ann.c_lp_sm_intergenic_filtered_more_than_2000_SNPS.bed
TOTAL=$(< $FILE wc -l)
COUNTER=0
awk -F"\t" '{printf ("%s_%s\n", $1,$3)}' $FILE > ../output/${FILE/.bed/.rec_matrix}
mapfile -t ROWS < $FILE
for row in "${ROWS[@]}"
  do
  SCAFFOLD=$(echo "$row" | cut -f1)
  rm ../output/temporary_column.borrar
  for row_bis in "${ROWS[@]}"
    do
    SCAFFOLD_BIS=$(echo "$row_bis" | cut -f1)
    if [ $SCAFFOLD == $SCAFFOLD_BIS ]
      then
      POSITION=$(echo "$row" | cut -f3)
      POSITION_BIS=$(echo "$row_bis" | cut -f3)
      PHYSICAL_DISTANCE=$((POSITION-POSITION_BIS))
      GENETIC_DISTANCE=$(echo ${PHYSICAL_DISTANCE#-}*0.000000019 | bc) #1.9cM/Mb means 0.019M for 10^6bp, which means 1.9*10^-8M/bp
      else
      GENETIC_DISTANCE=0.5
    fi
    echo -e "$GENETIC_DISTANCE" >> ../output/temporary_column.borrar
    done
  paste ../output/${FILE/.bed/.rec_matrix} ../output/temporary_column.borrar
  rm ../output/temporary_column.borrar
  ((COUNTER++))
  if [ $(( $COUNTER % 1000 )) == 0 ]
    then
    echo "processed $COUNTER rows out of $TOTAL"
  fi
  done

#Opción alternativa que calcula tasas de recombinación dentro de cada scaffold y las guarda como tabla. Posteriormente, en R se puede importar la tabla y convertirla a matriz (paquete reshape o muchas otras opciones), automáticamente rellenando con NAs las comparaciones que falten. Reemplazar los NAs por 0.5 sería el último paso. Aunque es mucho más rápido que el anterior método, sigue siendo demasiado lento, tardaría muchos días.
cd /Users/dani/ownCloud/publico/Eurasian\ lynx\ phylogeography/recent_demographic_reconstruction/LinkNe/input/
rm ../output/${FILE/.bed/.distance}
FILE=lp_perspecies.trimmed_filtered1.ann.c_lp_sm_intergenic_filtered_more_than_2000_SNPS.bed
SCAFFOLDS=$(cut -f1 $FILE | uniq)
for s in ${SCAFFOLDS[@]}
  do
  echo ${s}
  SUBSET=$(grep $s $FILE)
  while IFS="\n" read -r row
    do
    #echo $row
    POSITION=$(echo "${row}" | cut -f3)
    while IFS="\n" read -r row_bis
      do
      #echo $row_bis
      POSITION_BIS=$(echo "$row_bis" | cut -f3)
      PHYSICAL_DISTANCE=$((POSITION-POSITION_BIS))
      GENETIC_DISTANCE=$(echo ${PHYSICAL_DISTANCE#-}*0.000000019 | bc) #1.9cM/Mb means 0.019M for 10^6bp, which means 1.9*10^-8M/bp
      echo -e "$s_$POSITION\t$s_$POSITION_BIS\t$GENETIC_DISTANCE" >> ../output/${FILE/.bed/.distance}
      done <<< "$SUBSET"
    done <<< "$SUBSET"
  done

```

###Mapas genéticos:
```{bash}

cd /Users/dani/ownCloud/publico/Eurasian\ lynx\ phylogeography/recent_demographic_reconstruction/LinkNe/input/

INPUT_BEDS=$(ls *.bed)
for pop in ${INPUT_BEDS[@]}
  do 
  #echo ${pop}
  echo -e "locus\tchromosome\tposition" > ${pop/.bed/.map}
  POP=$(echo ${pop} | cut -d'.' -f 4 | cut -d'_' -f-3)
  echo ${POP}
  LC_NUMERIC=C awk -F"\t" '{printf ("%s_%s\t%s\t%.9f\n", $1,$3,$1,$3*0.000000019)}' ${pop} | sed 's/lp23\.s//g' >> ${pop/.bed/.map} #LC_NUMERIC=C to force a dot as the decimal separator. Otherwise it will print commas even though I've set my mac to use dots as the default...
  done

```

###Genotipos en formato genepop:
```{bash}

#Copio los vcf con mas de 2000 SNPs que hemos usado para SNeP en local para transformarlos a GENEPOP usando PDGSpider:

scp -p mlucena@genomics-b.ebd.csic.es:/home/mlucena/recent_demographic_reconstruction/SNeP/ll*_filtered_more_than_2000_SNPS.vcf /Users/marialucenaperez/Owncloud/publico/PhD/Eurasian_lynx_phylogeography/recent_demographic_reconstruction/LinkNe/input
scp -p mlucena@genomics-b.ebd.csic.es:/home/mlucena/recent_demographic_reconstruction/SNeP/lp*_filtered_more_than_2000_SNPS.vcf /Users/marialucenaperez/Owncloud/publico/PhD/Eurasian_lynx_phylogeography/recent_demographic_reconstruction/LinkNe/input

#Ahora los transformo en local, para que Dani los lance.

#Como los nombres de los SNPs son diferentes que en los map, modifico los genepop.
cd /Users/dani/ownCloud/publico/Eurasian\ lynx\ phylogeography/recent_demographic_reconstruction/LinkNe/input/
GENEPOP_LIST=$(ls *intergenic_filtered_more_than_2000_SNPs.txt)
for file in ${GENEPOP_LIST[@]}
  do
  #echo ${file}
  POP=$(echo ${file} | cut -d'_' -f-3)
  echo ${POP}
  SPECIES=$(echo ${file} | cut -d'_' -f 2)
  N_PED=$(sed '/Pop/q' ${file} | ghead -n -1 | wc -l)
  N_MAP=$(< ${SPECIES}_perspecies.trimmed_filtered1.ann.${file/txt/map} wc -l)
  if [ $N_PED == $N_MAP ]
    then echo "correct SNP number"
    else echo "wrong SNP number"
  fi
  GENOTYPES=$(sed -n '/Pop/,$p' ${file})
  echo $POP > ${file/txt/genepop}
  gtail -n +2 ${SPECIES}_perspecies.trimmed_filtered1.ann.${file/txt/map} | cut -f 1 >> ${file/txt/genepop}
  echo "$GENOTYPES" >> ${file/txt/genepop}
  done

```

##Ejecución del programa:
```{bash}

cd /Users/dani/ownCloud/publico/Eurasian\ lynx\ phylogeography/recent_demographic_reconstruction/LinkNe/input/

POPS=$(ls *.bed | cut -d'.' -f 4 | cut -d'_' -f-3)
for pop in ${POPS[@]}
  do
  echo ${pop}
  SPECIES=$(echo ${pop} | cut -d'_' -f 2)
  perl LinkNe-master/LinkNe.pl -i ${pop}_intergenic_filtered_more_than_2000_SNPs.genepop -map ${SPECIES}_perspecies.trimmed_filtered1.ann.${pop}_intergenic_filtered_more_than_2000_SNPs.map -o ../output/${pop}_intergenic_filtered_more_than_2000_SNPs.linkne
  done

```

