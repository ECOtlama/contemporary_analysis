---
title: "recent_demographic_reconstruction"
output: html_document
---

# IBDNe

Quiero obtener la reconstrucción demográfica reciente de las distintas poblaciones. Una forma de hacerlo es con IBDne que usa los tracks IBD. 

```{bash}
# Pruebo con ibdne: http://faculty.washington.edu/browning/ibdne.html#download
mkdir /home/mlucena/recent_demographic_reconstruction

# Copiamos el archivo IBD de Dani para probar: 
scp /home/GRUPOS/grupolince/lynx_genomes_5x/IBD_analysis/ngsF-HMM/c_ll_ki-c_ll_no-c_ll_po-c_lp_do-c_lp_sm_n060_ngsF-HMM.ibd recent_demographic_reconstruction/

# Copiamos un archivo VCF de Dani para probar: 
scp /home/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/annotation/ll_perspecies.trimmed_filtered1.ann.vcf /home/mlucena/recent_demographic_reconstruction

cd /home/mlucena/recent_demographic_reconstruction

# Obtengo un archivo map en plink 
/opt/plink_1.9/plink_1.9 --vcf /home/mlucena/recent_demographic_reconstruction/ll_perspecies.trimmed_filtered1.ann.vcf --maf 0.05 --recode --out /home/mlucena/recent_demographic_reconstruction/ll_perspecies.trimmed_filtered1.ann --const-fid 0 --allow-extra-chr


# Corro IBDNe:
cat c_ll_ki-c_ll_no-c_ll_po-c_lp_do-c_lp_sm_n060_ngsF-HMM.ibd | java -jar ibdne.07May18.6a4.jar map=/home/mlucena/recent_demographic_reconstruction/ll_perspecies.trimmed_filtered1.ann.map out=output

# No puedo pq necesita mapa gnetico de verdad.
# http://methodspopgen.com/methods-to-infer-populations-history/
# Saco la equivalencia basada en el mapa de ligamiento de gato (LaDeana et al. 2016) de bases a morgan. 
# Transformo el .map. --> Equivalencia: Si 100Mb son 1.9Morgan; 1 base=1900cM

cd /home/mlucena/recent_demographic_reconstruction

awk -v OFS='\t'  '{print $1, $4, $4*0.00000000019, $4}' ll_perspecies.trimmed_filtered1.ann.map > ll_perspecies.trimmed_filtered1.ann.w_genetic_distances.map

# 0.00000000019 son los cM a los que equivale una base. 

cat c_ll_ki-c_ll_no-c_ll_po-c_lp_do-c_lp_sm_n060_ngsF-HMM.ibd | java -jar ibdne.07May18.6a4.jar map=/home/mlucena/recent_demographic_reconstruction/ll_perspecies.trimmed_filtered1.ann.w_genetic_distances.map out=output

# Error tengo que eliminar los que sean valores unicos.

awk '{print $1}'  ll_perspecies.trimmed_filtered1.ann.w_genetic_distances.map | sort | uniq -u > scaffold_list_uniq_values.txt 

grep -v -F -f scaffold_list_uniq_values.txt ll_perspecies.trimmed_filtered1.ann.w_genetic_distances.map > ll_perspecies.trimmed_filtered1.ann.w_genetic_distances_no_unique.map

cat c_ll_ki-c_ll_no-c_ll_po-c_lp_do-c_lp_sm_n060_ngsF-HMM.ibd | java -jar ibdne.07May18.6a4.jar map=ll_perspecies.trimmed_filtered1.ann.w_genetic_distances_no_unique.map out=output


# Error en reading IBD
# Creo el IBD con IBDseq: http://faculty.washington.edu/browning/ibdseq.html

java -jar ibdseq.r1206.jar gt=ll_perspecies.trimmed_filtered1.ann.vcf out=ll_perspecies.trimmed_filtered1.ann.IBDseq

# Done! y está bien

# Pruebo a correr de nuevo el archivo ibd recién creado con ibdseq:

cat ll_perspecies.trimmed_filtered1.ann.IBDseq.ibd | java -jar ibdne.07May18.6a4.jar map=ll_perspecies.trimmed_filtered1.ann.w_genetic_distances_no_unique.map out=output filtersamples=false mincm=5e-06 nboots=0


# Exception in thread "main" java.lang.IllegalStateException: trim parameter for trimmed mean is too large
# Los trozos de IBD son demasiado pequeños. De hecho, si miro como es el más grande del scaffold 1 que es uno de los más largos: 
# lp23.s00001	13187672	0.00250566	13187672. 
# 0.00250566 es la distancia en cM al comienzo del scaffold. Si tenemos en cuenta que por defecto el programa filtra todo lo que sea menor a 2cM y además trima 0.2 cM para evitar problemas con el final del cromosoma; claramente nuestros fragmentos son muy pequeños. 

# mincm=[positive number]
#The mincm argument specifies the minimum IBD segment length in centiMorgan units. Any input IBD segments that have length shorter than the minimum length are ignored. The minimum IBD segment length should be sufficiently large so that IBD segments exceeding the minimum length are detected with high power and low false discovery rate (default: mincm=2).


``` 

Dead end. Siguiente aproximación.
(Primero limpio la carpeta porque nada de lo que hay aquí me va a servir).

# 1. SNeP

Para esta aproximación necesito un archivo ped y un archivo map. El programa me puede calcular el archivo de ld. 
Leer manual y artículo de Barbato donde presentan el método. 

Basicamente usan el calculo de LD para inferir Ne. LD se calcula como la r2 entre dos SNPs. Para ello la distancia genética puede ser una funcion de la distancia física y la tasa de recombinación, o se pueden añadir algunas correcciones para distancias muy grandes donde LD aparece saturado. 

Lo primero que tengo que hacer es lograr un VCF por población.

Para ello, uso los VCF de Dani que se supone que están limpios y filtrados. 

La carpeta donde voy a hacer los análisis ya la tengo generada y es: /home/mlucena/recent_demographic_reconstruction

## Split VCF into different pops.


```{bash}

cd /home/mlucena/recent_demographic_reconstruction

# VCF que voy a usar están en la carpeta: /home/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/annotation/

# Los dos archivos útiles son:

# ll_perspecies.trimmed_filtered1.ann.vcf
# lp_perspecies.trimmed_filtered1.ann.vcf

# Los voy a copiar a mi carpeta de reconstrucción demográfica para que no haya ningún problema si los rompo.

scp /home/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/annotation/ll_perspecies.trimmed_filtered1.ann.vcf /home/mlucena/recent_demographic_reconstruction
scp /home/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/annotation/lp_perspecies.trimmed_filtered1.ann.vcf /home/mlucena/recent_demographic_reconstruction

# Primero tengo que sacar una lista con todos los individuos de cada población que hay. 

bcftools query -l ll_perspecies.trimmed_filtered1.ann.vcf > list_of_samples_c_ll
bcftools query -l lp_perspecies.trimmed_filtered1.ann.vcf > list_of_samples_c_lp

# Lista de las poblaciones que tenemos. 
declare POPS=$(bcftools query -l ll_perspecies.trimmed_filtered1.ann.vcf | cut -c1-7 | sort | uniq)
declare POPS=$(bcftools query -l lp_perspecies.trimmed_filtered1.ann.vcf | cut -c1-7 | sort | uniq)

# Voy a iterar sobre las distintas poblaciones para hacer una lista con los ind de esa poblacion. 
for POP in ${POPS[@]}
do
echo $POP
grep $POP list_of_samples_c_ll > $POP.list
done

rm list_of_samples_c_ll

for POP in ${POPS[@]}
do
echo $POP
grep $POP list_of_samples_c_lp > $POP.list
done

rm list_of_samples_c_lp


# Ahora lo modifico un poco a mano. Voy a eliminar las de balcanes que no nos interesan y voy a unir mongolia, que lo vamos a considerar una población. 

# Compruebo que así borro lo que me interesa 
ls -ltr *ba*
# Borro
# rm *ba*

# Borro también pais vasco
rm h_ll_pv.list

# Hago cat de mongolia
cat c_ll_og.list c_ll_to.list c_ll_ka.list > c_ll_mo.list

rm c_ll_og.list 
rm c_ll_to.list 
rm c_ll_ka.list


# Perfecto!
# Ahora lanzo el script para separa por poblaciones.

screen -S separate_VCF_by_pop_pardinus

GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
#VCF=ll_perspecies.trimmed_filtered1.ann.vcf
VCF=lp_perspecies.trimmed_filtered1.ann.vcf
REF=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome

for POP_list in c_lp*.list
  do
  declare POP=$(echo $POP_list | cut -d "." -f1 )
  echo "${POP}"
     java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
    -T SelectVariants \
    -R $REF \
    -V $VCF \
    -o ${VCF/.vcf/.$POP.vcf} \
    --sample_file $POP_list \
    --preserveAlleles
    done

# Sanity check
# ¿Está quitando lo que me interesa?

bcftools query -l ll_perspecies.trimmed_filtered1.ann.c_ll_ya.vcf 


# Ahora nos vamos a quedar solo con los de intergénico.


task(){
   bedtools intersect -a $i -b /GRUPOS/grupolince/Lyp_annotation_Apr14_final/LYPA23C.intergenic.PLUS1000.bed -sorted -g /home/mlucena/grupolince/lynx_genomes_5x/BAM_files_final/BAM_intergenic_5x/lp23.version.sorted.genome -header > ${i/.vcf/_intergenic.vcf}
}


for i in *c_l*vcf
do
echo $i
 task "$i" 
done


# De todas formas hay muchos scaffold que tiene muy pocos SNPs, así que el autor me recomienda que lo filtre. Puedo filtrar primero para los scaffolds que tiene al menos 1000 SNPs y luego los que tienen 2000 SNPs. Y así hacer una pruebecilla para ver si los datos son parecidos, me puedo quedar con el dataset más pequeño. 

for vcf_POP in *c_l*_intergenic.vcf
do
echo $vcf_POP
declare POP=$(echo $vcf_POP | cut -d "." -f4 )
# Ahora contamos el número de SNPS por scaffold

grep -v -E '^#'  $vcf_POP | cut -f 1 | sort | uniq -c | sort -n | awk '$1>2000{print $2}' | sort | sed -n -e 'H;${x;s/\n/,/g;s/^,//;p;}' > "${POP}"_more_than_2000_SNPS_per_scaffold.list
grep -v -E '^#'  $vcf_POP | cut -f 1 | sort | uniq -c | sort -n | awk '$1>1000{print $2}' | sort | sed -n -e 'H;${x;s/\n/,/g;s/^,//;p;}' > "${POP}"_more_than_1000_SNPS_per_scaffold.list
bcftools query -l $vcf_POP 
bgzip $vcf_POP 
bcftools index "${vcf_POP}".gz
bcftools view -r `cat "${POP}"_more_than_2000_SNPS_per_scaffold.list` "${vcf_POP}".gz -Ov -o "${vcf_POP/.vcf/_filtered_more_than_2000_SNPS.vcf}"
bcftools view -r `cat "${POP}"_more_than_1000_SNPS_per_scaffold.list` "${vcf_POP}".gz -Ov -o "${vcf_POP/.vcf/_filtered_more_than_1000_SNPS.vcf}"
done

```


Ahora que ya tengo los VCF por población para las dos especies lo que tengo que hacer es generar el archivo map y ped de cada población.

## Generate ped and map file

```{bash}

cd /home/mlucena/recent_demographic_reconstruction


VCFs=$(ls *.c_l*more_than_2000_SNPS.vcf)

for VCF_per_pop in ${VCFs[@]}
do 
echo $VCF_per_pop
declare POP=$(echo $VCF_per_pop | cut -d "." -f4 )
/opt/plink_1.9/plink_1.9 --vcf $VCF_per_pop --maf 0.05 --recode --out "${POP}"_maf005 --const-fid 0 --allow-extra-chr
done



```


## Copy to UBUNTU local

SNeP sólo corre en Ubunto 14.04 o en windows, por tanto me he tenido que crear una máquina virtual en local que tenga instalado ubuntu. Así que lo primero que tngo que hacer es bajarme los archivos a este ordenador. 

Me meto en mi máquina virtual, y una vez ahí me los bajo.

```{bash}

# En local--> Maquina virtual --> Ubuntu. 

mkdir /home/maria/SneP

scp mlucena@genomics-b.ebd.csic.es:/home/mlucena/recent_demographic_reconstruction/*ped /home/maria/SneP
scp mlucena@genomics-b.ebd.csic.es:/home/mlucena/recent_demographic_reconstruction/*map /home/maria/SneP

```

## SNeP

```{bash}

cd /home/maria/SneP

for PED_FILE in *.ped
do
declare POP=$(echo $PED_FILE | cut -d "." -f 1)
#declare SAMPLE_SIZE=$(grep $POP sample_size_file.csv | cut -d"," -f 2)
SNePv1.1 -ped $PED_FILE -out ./$POP -ld -recrate 1.9e-8  -svedf -samplesize 1 #The sex-averaged recombination rate across the cat genome was 1.9 cM/Mb (see: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4889657/)
done

# Otras variantes del script están en mi máquina virtual en UBUNTU.
```

## Copy back to the server & to mac local

```{bash}
# Copy to server

cd /home/maria/SneP

scp /home/maria/SneP/*Ne* mlucena@genomics-b.ebd.csic.es:/home/mlucena/recent_demographic_reconstruction/

mkdir /Users/marialucenaperez/Owncloud/publico/Eurasian_lynx_phylogeography/recent_demographic_reconstruction

scp mlucena@genomics-b.ebd.csic.es:/home/mlucena/recent_demographic_reconstruction/SNeP/*NeAll /Users/marialucenaperez/Owncloud/publico/PhD/Eurasian_lynx_phylogeography/recent_demographic_reconstruction/SNeP/

```


## R representation

```{r}
# Leo la tabla de Ne.

library (data.table)
library(ggplot2)
library (dplyr)
library (magrittr)
library(plyr)
library (tidyr)
library(viridis)

wd <- "/Users/marialucenaperez/Owncloud/publico/PhD/Eurasian_lynx_phylogeography/recent_demographic_reconstruction/SNeP/"


sample_files = list.files(path = wd, pattern="*NeAll$")
list_Ne<- lapply( sample_files, function (x) 
     # Aquí leo la tabla
  fread(paste0(wd,x)))
#names the list using the basename from `l`
# this also is the step to manipuly the filesnamaes to whatever you like
names(list_Ne) <- basename( sample_files )
#bind the rows from the list togetgher, putting the filenames into the colum "id"
Ne_reconstruction <- rbindlist( list_Ne, idcol = "pop1" ) %>% 
  # Corto este string para que sea igual en los dos dataset
  mutate(pop=substr(.$pop1, 1, 7) ) %>% 
  # Elimino el valor que no me interesa
  select (-pop1)%>% 
  mutate (., Populations =  ifelse (pop == "c_ll_po", "NE-Poland",
                          ifelse (pop == "c_ll_ur", "Urals",
                          ifelse (pop == "c_ll_ki", "Kirov",
                          ifelse (pop == "c_ll_la", "Latvia",
                          ifelse (pop == "c_ll_no", "Norway",
                          ifelse (pop == "c_ll_ba" | pop == "h_ll_ba", "Balkans" ,
                          ifelse (pop == "c_ll_cr","Carpathians",
                          ifelse (pop == "c_ll_to", "Töv",
                          ifelse (pop == "c_ll_tu", "Tuva",
                          ifelse (pop == "c_ll_ka", "Khentii-Aimag",
                          ifelse (pop == "c_ll_mo", "Mongolia",
                          ifelse (pop == "c_ll_og", "Ömnögovi", 
                          ifelse (pop == "c_ll_vl", "Vladivostok", 
                          ifelse (pop == "c_ll_ya", "Yakutia",
                          ifelse (pop == "c_lp_sm", "Sierra Morena",
                          ifelse (pop == "c_lp_do", "Doñana", NA))))))))))))))))) %>% 
  mutate(YBP=GenAgo*5)


cols <- c("NE-Poland"=viridis_pal()(5)[3], 
          "Urals"="#0F4909", 
          "Carpathians"=brewer.pal(12,"Paired")[9], 
          "Kirov"=viridis_pal()(5)[1], 
          "Latvia"=brewer.pal(12,"Paired")[3], 
          "Norway"=viridis_pal()(5)[2], 
          "Mongolia"=brewer.pal(12,"Paired")[12], 
          "Tuva"=brewer.pal(12,"Paired")[8], 
          "Vladivostok"=brewer.pal(12,"Paired")[5], 
          "Yakutia"=brewer.pal(12,"Paired")[6])


 ggplot (Ne_reconstruction, aes(YBP, Ne, fill=Populations, colour=Populations)) +
    geom_point(alpha=0.1) +
    geom_smooth() + 
    theme_classic() +
    scale_colour_manual(values = cols)+
    scale_fill_manual(values = cols) +
   ggsave(paste(wd,"all_pop.pdf", sep=""), device = "pdf")


 
 



for (i in 1:length(finsNeAll))
{
  datNeAll <- read.csv (paste(wd,finsNeAll [i],sep=""), header = T, sep = '\t')  
  name_NeAll <- unlist(strsplit(finsNeAll [i], "[.]"))
  ggplot (datNeAll, aes(GenAgo, Ne)) +
    geom_point(alpha=0.1) +
    geom_smooth(color="grey24", fill="grey64") +
    theme_classic() +
    ggtitle(paste(name_NeAll[1]))
  ggsave(paste(wd,name_NeAll[1],"_", name_NeAll[2],".pdf", sep=""), device = "pdf")
}
 

```

# 2. Stairway plot

Vamos a correr un programa que se llama stairway plot que genera un skyline plot demográfico. Este programa corre en java. Como entrada necesita: numero de sitios monomórficos + polimorficos, el sfs, y el número de alelos (numero de individuos * 2). Todos estos datos los tengo en el espectro de frecuencias alélicas, que aunque está expresado en likelihood, el programa lo acepta. 

Para que corra tienes que generar un archivos txt que el programa transforma en sh usando java, y despues este .sh se lanza. 
Un ejemplo de un archivo de entrada es este (en mi ordenador):


```{bash}
cat /Users/marialucenaperez/Documents/stair_way_plot/stairway_plot_v2/two-epoch.blueprint 
#example blueprint file
#input setting
popid: two-epoch # id of the population (no white space)
nseq: 30 # number of sequences
L: 10000000 # total number of observed nucleic sites, including polymorphic and monomorphic
whether_folded: false # whethr the SFS is folded (true or false)
SFS: 9513.26	3796.47	2106.24	1351.505	962.91	736.865	597.75	499.845	429.99	381.62	341.965	310.27	284.87	261.28	242.11	230.055	217.975	204.48	197.28	185.545	176.055	167.62	161.55	154.935	147.83	142.17	137.31	133.3	124.955   # snp frequency spectrum: number of singleton, number of doubleton, etc. (separated by white space)
#smallest_size_of_SFS_bin_used_for_estimation: 2 # default is 1; to ignore singletons, change this number to 2
#largest_size_of_SFS_bin_used_for_estimation: 28 # default is n-1; to ignore singletons, change this number to nseq-2
pct_training: 0.67 # percentage of sites for training
nrand: 7	15	22	28 # number of random break points for each try (separated by white space)
project_dir: two-epoch # project directory
stairway_plot_dir: stairway_plot_es # directory to the stairway plot files
ninput: 200 # number of input files to be created for each estimation
#output setting
mu: 1.2e-8 # assumed mutation rate per site per generation
year_per_generation: 24 # assumed generation time (in years)
#plot setting
plot_title: two-epoch # title of the plot
xrange: 0.1,10000 # Time (1k year) range; format: xmin,xmax; "0,0" for default
yrange: 0,0 # Ne (1k individual) range; format: xmin,xmax; "0,0" for default
xspacing: 2 # X axis spacing
yspacing: 2 # Y axis spacing
fontsize: 12 # Font size
```

Los parámetros que cambiamos son:
popid --> nombre de la población.
nseq --> numero de individuos * 2
L --> numero total de sitios incluyendo ambos, monomórficos y polimórficos.
whether_folded --> en mi caso, false, porque tengo un unfolded.
pct_training --> se deja igual.
nrand --> se calcula según la formula: number of random break points for each try (separated by white space). We suggest to use 4 numbers, roughly (nseq-2)/4, (nseq-2)/2, (nseq-2)*3/4, nseq-2. The range of the numbers is between 1 and nseq-2. The smaller the number, the more likely the estimation may underfit the training data. The larger the number, the more likely the estimation may overfit the training data. Stairway plot will pick the best number (among the numbers specified here) to control overfitting based on the remaining 1-pct_training sites used as testing data.
project_dir --> en esta carpeta se guarda el resultado.
stairway_plot_dir --> no se toca.
ninput --> no se toca.
mu --> mutation_rate, en mi caso voy a poner la de lince: 6e-9
year_per_generation --> 5 en mi caso.
plot_title --> nombre del plot
xrange --> no se toca
yrange --> no se toca
xspacing --> no se toca
yspacing --> no se toca
fontsize --> no se toca

Lo primero que voy a hacer es hacerme uno base para poder modificarlo.

## Template generation

Creo un template para poder completarlo

nano POPULATION.blueprint

```{}
#!/bin/sh

#define parameters which are passed in
POP=$1
NSEQ=$2
NSITES=$3

#define the template.
cat  << EOF
popid: $POP
nseq: $NSEQ
L: $NSITES
whether_folded: false 
SFS: $SFS
#smallest_size_of_SFS_bin_used_for_estimation: 2 
#largest_size_of_SFS_bin_used_for_estimation: 28 
pct_training: 0.67 
nrand: $NRAD
project_dir: $POP/
stairway_plot_dir: stairway_plot_es 
ninput: 200 
#output setting
mu: 6e-9
year_per_generation: 5
#plot setting
plot_title: $POP
xrange: 0.1,10000 
yrange: 0,0 
xspacing: 2 
yspacing: 2 
fontsize: 12
EOF

```


Ahora hago un loop para que rellene los campos que tiene que modificar

## Loop for generating the files

Primero miro la carpeta donde están mis sfs.

```{bash}
locate *intergenic_sfs*sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_cr_n006.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_ki_n013.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_la_n006.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_no_n008.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_po_n008.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_to-c_ll_ka-c_ll_og_n008.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_tu_n006.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_ur_n006.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_vl_n008.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/c_ll_ya_n008.unfolded-lr.sfs
/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs/x_ll_ba_n003.unfolded-lr.sfs
```

Ahora por cada uno de los sfs, debo hacer el loop correspondiente:

```{bash}

# El script para que rellene los campos serían este:
cd /home/mlucena/recent_demographic_reconstruction/stairway_plot
# RUTA_SFS="/home/mlucena/ANGSD_analysis/intergenic_analysis/intergenic_sfs" # para boreal
# RUTA_SFS="/home/mlucena/ANGSD_analysis/whole_genome_analysis/sfs" # para pardinus

for SFS_FILE in $RUTA_SFS/c_lp*sfs;
do

SFS_FILE_NAME=`echo $SFS_FILE | rev | cut -d"/" -f 1 | rev ` 
POP=${SFS_FILE_NAME/\.unfolded\-lr\.sfs/}
echo $POP
NSEQ=`echo ${POP: -3}*2 | bc`
NSITES=`gawk '{for(i=1;i<=NF;i++)s+=$i;printf("%.0f\n", s)}' $SFS_FILE`
SFS=`cat $SFS_FILE | cut -d" " -f 2- $SFS_FILE | rev | sed -e 's/^[ \t]*//' | cut -d" " -f 2- | rev`
NRAD1=`echo $(( (NSEQ -2) / 4 ))`
NRAD2=`echo $(( (NSEQ -2) / 2 ))`
NRAD3=`echo $(( (NSEQ -2) * 3/4 ))`
NRAD4=`echo $(( NSEQ -2 ))`
NRAD=`echo $NRAD1 $NRAD2 $NRAD3 $NRAD4`

mkdir $POP
cd $POP

scp -r ../stairway_plot_es .

../POPULATION.blueprint """$POP""" """$NSEQ""" """$NSITES""" """$SFS""" """$NRAD""" > $POP.blueprint
# Así creo las carpetas
java -cp ../stairway_plot_es Stairbuilder $POP.blueprint
# Voy a lanzar de una en una, porque quiero lanzar varias a la vez. 
# HOW TO RUN THE ANALYSIS
echo RUN $POP!

chmod 700 $POP.blueprint.sh
./$POP.blueprint.sh

cd ..
touch $POP.borrar

done


```

# Run the analysis

```{bash}
./two-epoch_c_ll_ya_n008.blueprint.sh 

# Para pintar solo el plot

java -Xmx1g -cp stairway_plot_es/ Stairpainter c_lp_sm_n012.blueprint

```


# R: Custom drawing

Primero tengo que coger los dtos de los que se hace el dibujo. Estan en un archivo que se llama .final.summary, en cada carpeta de cada poblacion. Voy a pintarlos todos juntos, así que creo una super carpeta, que ya separaré si lo necesito en R. Aquí solo añado la info que me interesa. 


En el archivo que se llama summary con el que puedo pintar:

1st col: time measured in the expected number of mutation(s) per site
2nd col: number of estimates used
3rd col: the median of the population size measured in θ per site
4th col: the 2.5 percentile estimation of the population size measured in θ per site
5th col: the 97.5 percentile estimation of the population size measured in θ per site
6th col: time measured in years
7th col: the median of the population size measured in individuals
8th col: the 2.5 percentile estimation of the population size measured in individuals
9th col: the 97.5 percentile estimation of the population size measured in individuals
10th col: the 12.5 percentile estimation of the population size measured in individuals
11th col: the 87.5 percentile estimation of the population size measured in individuals

Copio la columna 7, 8, 9, 10, 11.

```{bash}

cd /home/mlucena/recent_demographic_reconstruction/stairway_plot
# Creo la carpeta donde vamos a guardar nuestro archivo de interes =
mkdir /home/mlucena/recent_demographic_reconstruction/stairway_plot/custom_output

# Creo el header para el archivo que voy a generar
cd /home/mlucena/recent_demographic_reconstruction/stairway_plot/c_ll_cr_n006/c_ll_cr_n006
head -n1 c_ll_cr_n006.final.summary |  awk -v OFS='\t' '{print $6, $7, $8, $9, $10, $11, "population", "specie"}' > /home/mlucena/recent_demographic_reconstruction/stairway_plot/custom_output/final_summary_custom_output.tsv 

# First we summarise the output files, and add a column with info of interest
populations=(c_ll_cr_n006 c_ll_ki_n013 c_ll_la_n006 c_ll_no_n008 c_ll_po_n008 c_ll_to-c_ll_ka-c_ll_og_n008 c_ll_tu_n006 c_ll_ur_n006 c_ll_vl_n008 c_ll_ya_n008 c_lp_do_n012 c_lp_sm_n019)


# Loop para concatenar las distintas poblaciones. 
cd /home/mlucena/recent_demographic_reconstruction/stairway_plot
for population in ${populations[@]}
do
echo $population
cd /home/mlucena/recent_demographic_reconstruction/stairway_plot/$population/$population
sp=`echo $population | cut -d'.' -f 1 | cut -d '_' -f 2`
if [ -z ${sp} ]; then  sp=NA;  fi
awk -v OFS='\t' -v pop="$population" -v sp="$sp" '{print $6, $7, $8, $9, $10, $11, pop, sp }' <(tail -n+2 "${population}".final.summary) >> /home/mlucena/recent_demographic_reconstruction/stairway_plot/custom_output/final_summary_custom_output.tsv
unset sp
cd /home/mlucena/recent_demographic_reconstruction/stairway_plot

done

```

Me lo copio al local

```{bash}

scp mlucena@genomics-b.ebd.csic.es://home/mlucena/recent_demographic_reconstruction/stairway_plot/custom_output/final_summary_custom_output.tsv /Users/marialucenaperez/Owncloud/publico/PhD/Eurasian_lynx_phylogeography/recent_demographic_reconstruction/stairway_plot/custom_plot_script 

```

Script para pintarlo

```{r}
library(viridis)
library(ggplot2); theme_set(theme_minimal())
library(tidyr)
library(tidyverse)
library(plyr)
library(dplyr)
library(data.table)
library(RColorBrewer)



wd <- "/Users/marialucenaperez/Owncloud/publico/PhD/Eurasian_lynx_phylogeography/recent_demographic_reconstruction/stairway_plot/custom_plot_script/"
wd_output <- "/Users/marialucenaperez/Owncloud/publico/PhD/Eurasian_lynx_phylogeography/recent_demographic_reconstruction/stairway_plot/custom_plot_script/output_R/"

demographic_data_all_pops <- read.table(paste(wd, "final_summary_custom_output.tsv", sep=""), header=T, na.strings = c("NA", "na")) 

# Lynx pardinus

demographic_data_lp <- demographic_data_all_pops %>% filter(specie=="lp") %>% filter(year>100) %>% filter(year<100000)

# https://ggplot2.tidyverse.org/reference/annotation_logticks.html
ggplot () +
  geom_line(data=demographic_data_lp , aes(x=year, y=Ne_median, group=population, colour=population)) +
  #scale_colour_manual(values = cols) +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))
) +
  annotation_logticks()


# Lynx lynx

demographic_data_ll <- demographic_data_all_pops %>% filter(specie=="ll") %>% filter(year>1) %>% 
  mutate (., Populations =  ifelse (population == "c_ll_po_n008", "NE-Poland",
                           ifelse (population == "c_ll_ur_n006", "Urals", 
                           ifelse (population == "c_ll_ki_n013", "Kirov", 
                           ifelse (population == "c_ll_la_n006", "Latvia", 
                           ifelse (population == "c_ll_no_n008", "Norway", 
                           ifelse (population == "c_ll_cr_n006","Carpathians", 
                           ifelse (population == "c_ll_to-c_ll_ka-c_ll_og_n008", "Mongolia", 
                           ifelse (population == "c_ll_tu_n006", "Tuva", 
                           ifelse (population == "c_ll_vl_n008", "Vladivostok",  
                           ifelse (population == "c_ll_ya_n008", "Yakutia", NA))))))))))) %>% 
  mutate (., region =  ifelse (population == "c_ll_po_n008", "West",
                           ifelse (population == "c_ll_ur_n006", "West", 
                           ifelse (population == "c_ll_ki_n013", "West", 
                           ifelse (population == "c_ll_la_n006", "West", 
                           ifelse (population == "c_ll_no_n008", "West", 
                           ifelse (population == "c_ll_cr_n006","West", 
                           ifelse (population == "c_ll_to-c_ll_ka-c_ll_og_n008", "East", 
                           ifelse (population == "c_ll_tu_n006", "East", 
                           ifelse (population == "c_ll_vl_n008", "East",  
                           ifelse (population == "c_ll_ya_n008", "East", NA))))))))))) %>%  
  mutate (., conservation = ifelse (population == "c_ll_po_n008", "Impacted",
                           ifelse (population == "c_ll_ur_n006", "Not_impacted", 
                           ifelse (population == "c_ll_ki_n013", "Not_impacted", 
                           ifelse (population == "c_ll_la_n006", "Not_impacted", 
                           ifelse (population == "c_ll_no_n008", "Impacted", 
                           ifelse (population == "c_ll_cr_n006","Impacted", 
                           ifelse (population == "c_ll_to-c_ll_ka-c_ll_og_n008", "Not_impacted", 
                           ifelse (population == "c_ll_tu_n006", "Not_impacted", 
                           ifelse (population == "c_ll_vl_n008", "Not_impacted",  
                           ifelse (population == "c_ll_ya_n008", "Not_impacted", NA))))))))))) %>% filter(year<100000) %>% # filter(year>100) %>%
  mutate(.,period = ifelse (year<1000, "recent", 
                            ifelse (year<10000, "holocene",
                                    ifelse(year<100000, "pleistocene", NA)))
)


### PLOTS:



cols <- c("NE-Poland"=viridis_pal()(5)[3], 
          "Urals"="#0F4909", 
          "Carpathians"=brewer.pal(12,"Paired")[9], 
          "Kirov"=viridis_pal()(5)[1], 
          "Latvia"=brewer.pal(12,"Paired")[3], 
          "Norway"=viridis_pal()(5)[2], 
          "Mongolia"=brewer.pal(12,"Paired")[12], 
          "Tuva"=brewer.pal(12,"Paired")[8], 
          "Vladivostok"=brewer.pal(12,"Paired")[5], 
          "Yakutia"=brewer.pal(12,"Paired")[6])



# Last 100 yrs
ggplot () +
  geom_line(data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=Populations, linetype=region)) +
  scale_colour_manual(values = cols) +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))
) +
  annotation_logticks() +
  coord_cartesian(xlim=c(1,100),ylim=c(0,1000)) 
ggsave(paste(wd_output, "stairway_plot_custom_xlim1-100_ylim0-1000_color_per_pop_line_type_region.pdf",sep=""))


twelve_col_pals = brewer.pal.info[brewer.pal.info$maxcolors == '12',] 
col_vector = unlist(mapply(brewer.pal, twelve_col_pals$maxcolors, rownames(twelve_col_pals)))
# pie(rep(1,n), col=sample(col_vector, n))
my_paired_colours <- as.vector(col_vector)


ggplot () +
  geom_line(data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=region, linetype=region)) +
scale_fill_manual(values=my_paired_colours) +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))
) +
  annotation_logticks() +
  coord_cartesian(xlim=c(1,100),ylim=c(0,1000)) 
ggsave(paste(wd_output, "stairway_plot_custom_xlim1-100_ylim0-1000_color_region_line_type_region.pdf",sep=""))



# Last 200 yrs
ggplot () +
  geom_line(data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=Populations, linetype=region)) +
  scale_colour_manual(values = cols) +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))
) +
  annotation_logticks() +
  coord_cartesian(xlim=c(1,200),ylim=c(0,2000)) 
ggsave(paste(wd_output, "stairway_plot_custom_xlim1-200_ylim0-2000_color_per_pop_line_type_region.pdf",sep=""))


twelve_col_pals = brewer.pal.info[brewer.pal.info$maxcolors == '12',] 
col_vector = unlist(mapply(brewer.pal, twelve_col_pals$maxcolors, rownames(twelve_col_pals)))
# pie(rep(1,n), col=sample(col_vector, n))
my_paired_colours <- as.vector(col_vector)


ggplot () +
  geom_line(data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=region, linetype=region)) +
scale_fill_manual(values=my_paired_colours) +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))
) +
  annotation_logticks() +
  coord_cartesian(xlim=c(1,200),ylim=c(0,2000)) 
ggsave(paste(wd_output, "stairway_plot_custom_xlim1-200_ylim0-2000_color_region_line_type_region.pdf",sep=""))


# Last 1000ya
ggplot () +
  geom_line(data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=Populations, linetype=region)) +
  scale_colour_manual(values = cols) +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))
) +
  annotation_logticks() +
  coord_cartesian(xlim=c(1,1000),ylim=c(0,5000)) 
ggsave(paste(wd_output, "stairway_plot_custom_xlim1-1000_ylim0-5000_color_per_pop_line_type_region.pdf",sep=""))


twelve_col_pals = brewer.pal.info[brewer.pal.info$maxcolors == '12',] 
col_vector = unlist(mapply(brewer.pal, twelve_col_pals$maxcolors, rownames(twelve_col_pals)))
# pie(rep(1,n), col=sample(col_vector, n))
my_paired_colours <- as.vector(col_vector)


ggplot () +
  geom_line(data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=region, linetype=region)) +
scale_fill_manual(values=my_paired_colours) +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))
) +
  annotation_logticks() +
  coord_cartesian(xlim=c(1,1000),ylim=c(0,5000)) 
ggsave(paste(wd_output, "stairway_plot_custom_xlim1-1000_ylim0-5000_color_region_line_type_region.pdf",sep=""))




# All periods

ggplot () +
  geom_line(data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=Populations, linetype=region)) +
  scale_colour_manual(values = cols) +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))
) +
  theme_classic() +
  annotation_logticks() +
ggsave(paste(wd_output, "stairway_plot_custom_color_per_pop_line_type_region.pdf",sep=""), width = 5, height = 7)



ggplot () +
  geom_line(data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=Populations, linetype=region)) +
  #geom_point(data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=region))+
  geom_smooth(method="lm", data=demographic_data_ll , aes(x=year, y=Ne_median, group=Populations, colour=Populations)) +
  scale_colour_manual(values = cols) +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))) +
   scale_y_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  annotation_logticks() +
  theme_classic() +
ggsave(paste(wd_output, "stairway_plot_custom_color_region_line_type_region.pdf",sep=""), width = 5, height = 7)


```

#### Effect of drift on the populations
```{r}


# Formula of lost of diversity:

ratio_Hf_Ho_formula <- function(Ne, t) {
  ratio_Hf_Ho <- (1 - 1/Ne)^t
  return(ratio_Hf_Ho)}

# Time
t=5000-200

# 
harmonic_mean_Ne_ratio_Hf_Ho_by_pop <- demographic_data_ll %>%  filter(year>200) %>%  filter(year<5000) %>% group_by(population) %>% summarise(media_harmonica=harmonic.mean(Ne_median), ratio_Hf_Ho=ratio_Hf_Ho_formula(media_harmonica, t))

# Tengo que ratio Hf/Ho para mis poblaciones segun la formula es uno. 
# Como asumo que parten de una población inicial que es igual, puedo ver como se relaciona con mi ratio de diversidad empirica.

# Valor para kirov del ratio: 0.102
# Valor para polonia: 0.00414

# Ratio de ambas Hfhealthy/Hferoded

# kirov-poland
0.102/0.00414
#24.63768
0.153/0.0109
# Kirov-Norway
0.102/0.00104
# 98.07692


# Ratio empírico
# pop     watterson pi
# Yakutia	4,50E-04	5,27E-04
# Ural m.	3,95E-04	4,51E-04
# Tuva	4,89E-04	5,45E-04
# Primorsky Krai	4,25E-04	5,01E-04
# Norway	2,66E-04	3,41E-04
# NE-Poland	2,86E-04	3,67E-04
# Mongolia	4,63E-04	5,36E-04
# Latvia	3,74E-04	4,38E-04
# Kirov	3,58E-04	4,64E-04
# Carpathian m.	3,15E-04	3,74E-04

# kirov-poland

# Pi kirov/Poland
4.64E-04/3.67E-04
# 1.26
# Watterson Kirov/Poland
3.58E-04/2.86E-04
# 1.251748

# Kirov-Norway

# Pi kirov/Norway
3.58E-04/2.66E-04
# 1.345865

# Mi ratio empírico es más pequeño, porque o bien la diversidad de polonia/Norway es mayor que la esperada, o la de kirov, menor. 




```

# 3. NE-Estimator

Primero voy a generar 5 dataset por poblacion con un 1% de los SNPs que tienen en el original para que pueda correr el programa.
Estos SNPs los voy a seleccionar teniendo en cuenta que esten en distintos scaffold (y asegurandome que esos scaffold corresponden a distintos cromosomas en gato).

¿Cuales son los scaffold con más de medio mega?
```{bash}
cd /GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome

sort -k2,2n Length_scaffolds_lp23

lp23.s00001	13188378
lp23.s05213	12220470
lp23.s10425	8802401
lp23.s15637	8424978
lp23.s26064	8029254
lp23.s20850	8028068
lp23.s31278	7976960
lp23.s36488	7826823
lp23.s36489	7582486
lp23.s31279	7139792
lp23.s26065	6924262
lp23.s20851	6824652
lp23.s15638	6589436
lp23.s10426	6347329
lp23.s05214	6149468
lp23.s00002	6085556
lp23.s20852	6074816
```

¿A qué cromosoma pertenecen?
Hago los 6 primeros y ya sería suficiente.

```{bash}
cd /GRUPOS/grupolince/copia_fabascal/MAPPINGS

grep lp23.s00001 lynx2cat_wTiger.sorted.bed | awk '{split($4,a,":"); print $1,a[2]}' | sort -k2,2 | uniq -c 
#  413 lp23.s00001 chrA2
# 6184676 lp23.s00001 chrA3 <--
#    461 lp23.s00001 chrB2
#      9 lp23.s00001 chrB3
#      3 lp23.s00001 chrD1
#   2585 lp23.s00001 chrE2
grep lp23.s05213 lynx2cat_wTiger.sorted.bed | awk '{split($4,a,":"); print $1,a[2]}' | sort -k2,2 | uniq -c 
#    240 lp23.s05213 chrA1
# 6621501 lp23.s05213 chrA2 <--
#    410 lp23.s05213 chrA3
#      6 lp23.s05213 chrC2
#    138 lp23.s05213 chrD1
#    219 lp23.s05213 chrX
grep lp23.s10425 lynx2cat_wTiger.sorted.bed | awk '{split($4,a,":"); print $1,a[2]}' | sort -k2,2 | uniq -c 
# 25 lp23.s10425 chrC1
#    557 lp23.s10425 chrD3
# 4593260 lp23.s10425 chrF1 <--
#    432 lp23.s10425 chrX
grep lp23.s15637 lynx2cat_wTiger.sorted.bed | awk '{split($4,a,":"); print $1,a[2]}' | sort -k2,2 | uniq -c 
# 4174920 lp23.s15637 chrB2 <- 
grep lp23.s26064 lynx2cat_wTiger.sorted.bed | awk '{split($4,a,":"); print $1,a[2]}' | sort -k2,2 | uniq -c
#      1 lp23.s26064 chrA1
# 4074998 lp23.s26064 chrB3 <-- 
#   1811 lp23.s26064 chrF1
#      1 lp23.s26064 chrX
grep lp23.s20850 lynx2cat_wTiger.sorted.bed | awk '{split($4,a,":"); print $1,a[2]}' | sort -k2,2 | uniq -c
# 4228516 lp23.s20850 chrA1 <-- 
#     46 lp23.s20850 chrC1
#     17 lp23.s20850 chrF1
```

¿Cuantos SNPs tiene cada uno de esos scaffold asignados?
```{bash}
grep lp23.s00001 ll_perspecies.trimmed_filtered1.ann.c_ll_ur_intergenic_filtered_more_than_2000_SNPS.vcf | wc -l
11569
grep lp23.s05213 ll_perspecies.trimmed_filtered1.ann.c_ll_ur_intergenic_filtered_more_than_2000_SNPS.vcf | wc -l
5271
grep lp23.s10425 ll_perspecies.trimmed_filtered1.ann.c_ll_ur_intergenic_filtered_more_than_2000_SNPS.vcf | wc -l
8880
grep lp23.s15637 ll_perspecies.trimmed_filtered1.ann.c_ll_ur_intergenic_filtered_more_than_2000_SNPS.vcf | wc -l
6874
grep lp23.s26064 ll_perspecies.trimmed_filtered1.ann.c_ll_ur_intergenic_filtered_more_than_2000_SNPS.vcf | wc -l
8798
grep lp23.s20850 ll_perspecies.trimmed_filtered1.ann.c_ll_ur_intergenic_filtered_more_than_2000_SNPS.vcf | wc -l
7523
```


```{bash}
# los files con SNPs están en la carpeta: home/mlucena/recent_demographic_reconstruction/SNeP

cd /home/mlucena/recent_demographic_reconstruction/SNeP
VCF_FILES=($(ls *intergenic_filtered_more_than_2000_SNPS.vcf | uniq))
mkdir "/home/mlucena/recent_demographic_reconstruction/Ne_Estimator/subsample_few_snps"
OUTPUT_PATH="/home/mlucena/recent_demographic_reconstruction/Ne_Estimator/few_scaffold/1000SNPs"

for VCF_FILE in ${VCF_FILES[@]}
do
echo $VCF_FILE
grep "#" $VCF_FILE > header
grep -v "#" $VCF_FILE | grep "lp23.s00001" | shuf -n 1000 | sort -k1,1 -k2,2n > $OUTPUT_PATH/${VCF_FILE/.vcf/_subset_few_scaffold1.vcf}
grep -v "#" $VCF_FILE | grep "lp23.s05213" | shuf -n 1000 | sort -k1,1 -k2,2n > $OUTPUT_PATH/${VCF_FILE/.vcf/_subset_few_scaffold2.vcf}
grep -v "#" $VCF_FILE | grep "lp23.s10425" | shuf -n 1000 | sort -k1,1 -k2,2n > $OUTPUT_PATH/${VCF_FILE/.vcf/_subset_few_scaffold3.vcf}
grep -v "#" $VCF_FILE | grep "lp23.s15637" | shuf -n 1000 | sort -k1,1 -k2,2n > $OUTPUT_PATH/${VCF_FILE/.vcf/_subset_few_scaffold4.vcf}
grep -v "#" $VCF_FILE | grep "lp23.s26064" | shuf -n 1000 | sort -k1,1 -k2,2n > $OUTPUT_PATH/${VCF_FILE/.vcf/_subset_few_scaffold5.vcf}
grep -v "#" $VCF_FILE | grep "lp23.s20850" | shuf -n 1000 | sort -k1,1 -k2,2n > $OUTPUT_PATH/${VCF_FILE/.vcf/_subset_few_scaffold6.vcf}
cat header $OUTPUT_PATH/${VCF_FILE/.vcf/_subset_few_scaffold1.vcf} $OUTPUT_PATH/${VCF_FILE/.vcf/_subset_few_scaffold2.vcf} $OUTPUT_PATH/${VCF_FILE/.vcf/_subset_few_scaffold3.vcf} $OUTPUT_PATH/${VCF_FILE/.vcf/_subset_few_scaffold4.vcf} $OUTPUT_PATH/${VCF_FILE/.vcf/_subset_few_scaffold5.vcf} $OUTPUT_PATH/${VCF_FILE/.vcf/_subset_few_scaffold6.vcf} > $OUTPUT_PATH/${VCF_FILE/.vcf/_subset_few_scaffold.vcf}
rm header
done


# Copio a local

scp -p mlucena@genomics-b.ebd.csic.es:///home/mlucena/recent_demographic_reconstruction/Ne_Estimator/few_scaffold/1000SNPs/*vcf /Users/marialucenaperez/Owncloud/publico/PhD/Eurasian_lynx_phylogeography/recent_demographic_reconstruction/Ne_estimator/few_scaffolds/1000SNPs 

```

Ahora sobre estos archivos genero los GENEPOP usando PGD spider. 
Despues el archivo genepop generado lo corro en Ne-Estimator. 


## Previous code --> not used. 

```{bash}
# los files con SNPs están en la carpeta: home/mlucena/recent_demographic_reconstruction/SNeP

cd /home/mlucena/recent_demographic_reconstruction/SNeP
VCF_FILES=($(ls *intergenic_filtered_more_than_2000_SNPS.vcf | uniq))
mkdir /home/mlucena/recent_demographic_reconstruction/Ne_Estimator
OUTPUT_PATH="/home/mlucena/recent_demographic_reconstruction/Ne_Estimator"


for VCF_FILE in ${VCF_FILES[@]}
do
echo $VCF_FILE
echo 1
vcfrandomsample -r 0.04 $VCF_FILE > $OUTPUT_PATH/${VCF_FILE/.vcf/_subset1.vcf}
echo 2
vcfrandomsample -r 0.04 $VCF_FILE > $OUTPUT_PATH/${VCF_FILE/.vcf/_subset2.vcf}
echo 3
vcfrandomsample -r 0.04 $VCF_FILE > $OUTPUT_PATH/${VCF_FILE/.vcf/_subset3.vcf}
echo 4
vcfrandomsample -r 0.04 $VCF_FILE > $OUTPUT_PATH/${VCF_FILE/.vcf/_subset4.vcf}
echo 5
vcfrandomsample -r 0.04 $VCF_FILE > $OUTPUT_PATH/${VCF_FILE/.vcf/_subset5.vcf}
done


# ¿Cuantos SNPs me quedan?

cd /home/mlucena/recent_demographic_reconstruction/Ne_Estimator
VCF_FILES=($(ls *.vcf | uniq))
for VCF_FILE in ${VCF_FILES[@]}
do
echo $VCF_FILE
grep -v "#" $VCF_FILE | wc -l
done


# Me los copio

scp -p mlucena@genomics-b.ebd.csic.es:///home/mlucena/recent_demographic_reconstruction/Ne_Estimator/*vcf /Users/marialucenaperez/Owncloud/publico/PhD/Eurasian_lynx_phylogeography/recent_demographic_reconstruction/Ne_estimator

```


Ahora sobre estos archivos genero los GENEPOP usando PGD spider. 
Despues el archivo genepop generado lo corro en Ne-Estimator. 


# 4. LinkNe

Daniel Kleinman y María Lucena. Seguimos las indicaciones de https://github.com/chollenbeck/LinkNe

##Puesta a punto del programa:
```{bash}

#Primero descargo el programa de https://github.com/chollenbeck/LinkNe y lo guardo en mi ordenador en /Users/dani/ownCloud/publico/Eurasian lynx phylogeography/recent_demographic_reconstruction/LinkNe/input/LinkNe-master/

#Pruebo a lanzarlo sin archivos de entrada y me da un error de perl de ausencia de dependencias necesarias. Desde la terminal, descargo en mi ordenador los siguientes módulos:
cpan Data::Dumper
cpan Getopt::Long
cpan Pod::Usage
cpan Statistics::Distributions

```

##Coordenadas de lince:

###Obtención de los archivos input 
####Matrices de tasas de recombinación (muy lento, descartado).
```{bash}

cd /Users/dani/ownCloud/publico/Eurasian\ lynx\ phylogeography/recent_demographic_reconstruction/LinkNe/input/

#En primer lugar, pasamos de vcf a bed para que los archivos sean más manejables.
INPUT_VCFS=$(ls *.vcf)
for vcf in ${INPUT_VCFS[@]}
  do
  POP=$(echo ${vcf} | cut -d'.' -f 4 | cut -d'_' -f-3)
  echo ${POP}
  ggrep -v '#' ${vcf} | awk -F"\t" '{printf ("%s\t%s\t%s\n", $1,$2-1,$2)}' > ${vcf/.vcf/.bed}
  done

#En segundo lugar, para cada archivo de población iteramos sobre cada posición y calculamos la distancia física respecto a cada una de las otras posiciones (si están en el mismo scaffold), y convertimos a distancia genética (asumimos 0.5 si están en distintos scaffolds). Guardamos dichos valores en columnas (una por cada posición) que vamos uniendo en un solo archivo. Es lentísimo, tardaría meses o años.
FILE=lp_perspecies.trimmed_filtered1.ann.c_lp_sm_intergenic_filtered_more_than_2000_SNPS.bed
TOTAL=$(< $FILE wc -l)
COUNTER=0
awk -F"\t" '{printf ("%s_%s\n", $1,$3)}' $FILE > ../output/${FILE/.bed/.rec_matrix}
mapfile -t ROWS < $FILE
for row in "${ROWS[@]}"
  do
  SCAFFOLD=$(echo "$row" | cut -f1)
  rm ../output/temporary_column.borrar
  for row_bis in "${ROWS[@]}"
    do
    SCAFFOLD_BIS=$(echo "$row_bis" | cut -f1)
    if [ $SCAFFOLD == $SCAFFOLD_BIS ]
      then
      POSITION=$(echo "$row" | cut -f3)
      POSITION_BIS=$(echo "$row_bis" | cut -f3)
      PHYSICAL_DISTANCE=$((POSITION-POSITION_BIS))
      GENETIC_DISTANCE=$(echo ${PHYSICAL_DISTANCE#-}*0.000000019 | bc) #1.9cM/Mb means 0.019M for 10^6bp, which means 1.9*10^-8M/bp
      else
      GENETIC_DISTANCE=0.5
    fi
    echo -e "$GENETIC_DISTANCE" >> ../output/temporary_column.borrar
    done
  paste ../output/${FILE/.bed/.rec_matrix} ../output/temporary_column.borrar
  rm ../output/temporary_column.borrar
  ((COUNTER++))
  if [ $(( $COUNTER % 1000 )) == 0 ]
    then
    echo "processed $COUNTER rows out of $TOTAL"
  fi
  done

#Opción alternativa que calcula tasas de recombinación dentro de cada scaffold y las guarda como tabla. Posteriormente, en R se puede importar la tabla y convertirla a matriz (paquete reshape o muchas otras opciones), automáticamente rellenando con NAs las comparaciones que falten. Reemplazar los NAs por 0.5 sería el último paso. Aunque es mucho más rápido que el anterior método, sigue siendo demasiado lento, tardaría muchos días.
cd /Users/dani/ownCloud/publico/Eurasian\ lynx\ phylogeography/recent_demographic_reconstruction/LinkNe/input/
rm ../output/${FILE/.bed/.distance}
FILE=lp_perspecies.trimmed_filtered1.ann.c_lp_sm_intergenic_filtered_more_than_2000_SNPS_subset_few_scaffold.bed
SCAFFOLDS=$(cut -f1 $FILE | uniq)
for s in ${SCAFFOLDS[@]}
  do
  echo ${s}
  SUBSET=$(grep $s $FILE)
  while IFS="\n" read -r row
    do
    #echo $row
    POSITION=$(echo "${row}" | cut -f3)
    while IFS="\n" read -r row_bis
      do
      #echo $row_bis
      POSITION_BIS=$(echo "$row_bis" | cut -f3)
      PHYSICAL_DISTANCE=$((POSITION-POSITION_BIS))
      GENETIC_DISTANCE=$(echo ${PHYSICAL_DISTANCE#-}*0.000000019 | bc) #1.9cM/Mb means 0.019M for 10^6bp, which means 1.9*10^-8M/bp
      echo -e "$s_$POSITION\t$s_$POSITION_BIS\t$GENETIC_DISTANCE" >> ${FILE/.bed/.distance}
      done <<< "$SUBSET"
    done <<< "$SUBSET"
  done

```

####Mapas genéticos:
```{bash}

cd /Users/dani/ownCloud/publico/Eurasian\ lynx\ phylogeography/recent_demographic_reconstruction/LinkNe/lynx_coordinates/input/

#En primer lugar, pasamos de vcf a bed para que los archivos sean más manejables.
INPUT_VCFS=$(ls *.vcf)
for vcf in ${INPUT_VCFS[@]}
  do
  POP=$(echo ${vcf} | cut -d'.' -f 4 | cut -d'_' -f-3)
  echo ${POP}
  ggrep -v '#' ${vcf} | awk -F"\t" '{printf ("%s\t%s\t%s\n", $1,$2-1,$2)}' > ${vcf/.vcf/.bed}
  done

INPUT_BEDS=$(ls *.bed)
for pop in ${INPUT_BEDS[@]}
  do 
  #echo ${pop}
  echo -e "locus\tchromosome\tposition" > ${pop/.bed/.map}
  POP=$(echo ${pop} | cut -d'.' -f 4 | cut -d'_' -f-3)
  echo ${POP}
  LC_NUMERIC=C awk -F"\t" '{printf ("%s_%s\t%s\t%.9f\n", $1,$3,$1,$3*0.0000019)}' ${pop} | sed 's/lp23\.s//g' >> ${pop/.bed/.map} #1.9cM/Mb means 1.9cM for 10^6bp, which means 1.9*10^-6cM/bp.
  #LC_NUMERIC=C to force a dot as the decimal separator. Otherwise it will print commas even though I've set my mac to use dots as the default... 
  done

```

####Genotipos en formato genepop:
```{bash}

#Copio los vcf con mas de 2000 SNPs que hemos usado para SNeP en local para transformarlos a GENEPOP usando PDGSpider:

scp -p mlucena@genomics-b.ebd.csic.es:/home/mlucena/recent_demographic_reconstruction/SNeP/ll*_filtered_more_than_2000_SNPS.vcf /Users/marialucenaperez/Owncloud/publico/PhD/Eurasian_lynx_phylogeography/recent_demographic_reconstruction/LinkNe/input
scp -p mlucena@genomics-b.ebd.csic.es:/home/mlucena/recent_demographic_reconstruction/SNeP/lp*_filtered_more_than_2000_SNPS.vcf /Users/marialucenaperez/Owncloud/publico/PhD/Eurasian_lynx_phylogeography/recent_demographic_reconstruction/LinkNe/input

#Ahora los transformo en local, para que Dani los lance.

#Como los nombres de los SNPs son diferentes que en los map, modifico los genepop.
cd /Users/dani/ownCloud/publico/Eurasian\ lynx\ phylogeography/recent_demographic_reconstruction/LinkNe/input/
GENEPOP_LIST=$(ls *.txt)
for file in ${GENEPOP_LIST[@]}
  do
  #echo ${file}
  POP=$(echo ${file} | cut -d'.' -f 1)
  echo ${POP}
  SPECIES=$(echo ${file} | cut -d'_' -f 2)
  N_PED=$(sed '/Pop/q' ${file} | ghead -n -1 | wc -l)
  N_MAP=$(< ${SPECIES}_perspecies.trimmed_filtered1.ann.${POP}_intergenic_filtered_more_than_2000_SNPS_subset_few_scaffold.map wc -l)
  if [ $N_PED == $N_MAP ]
    then echo "correct SNP number"
    else echo "wrong SNP number"
  fi
  GENOTYPES=$(sed -n '/Pop/,$p' ${file})
  echo $POP > ${file/txt/genepop}
  gtail -n +2 ${SPECIES}_perspecies.trimmed_filtered1.ann.${POP}_intergenic_filtered_more_than_2000_SNPS_subset_few_scaffold.map | cut -f 1 >> ${file/txt/genepop}
  echo "$GENOTYPES" >> ${file/txt/genepop}
  done

```

###Ejecución del programa:
####En modo local:
```{bash}

cd /Users/dani/ownCloud/publico/Eurasian\ lynx\ phylogeography/recent_demographic_reconstruction/LinkNe/lynx_coordinates/input/

POPS=$(ls *.map | cut -d'.' -f 4 | cut -d'_' -f-3)
for pop in ${POPS[@]}
  do
  echo ${pop}
  SPECIES=$(echo ${pop} | cut -d'_' -f 2)
  perl LinkNe-master/LinkNe.pl -i ${pop}.genepop -map ${SPECIES}_perspecies.trimmed_filtered1.ann.${pop}_intergenic_filtered_more_than_2000_SNPS_subset_few_scaffold.map -o ../output/${pop}.linkne
  done


#####caso sm con matriz:
PRIMERO Convertir lp_perspecies.trimmed_filtered1.ann.c_lp_sm_intergenic_filtered_more_than_2000_SNPS_subset_few_scaffold.distance en lp_perspecies.trimmed_filtered1.ann.c_lp_sm_intergenic_filtered_more_than_2000_SNPS_subset_few_scaffold.matrix

perl LinkNe-master/LinkNe.pl -i c_lp_sm.genepop -m lp_perspecies.trimmed_filtered1.ann.c_lp_sm_intergenic_filtered_more_than_2000_SNPS_subset_few_scaffold.matrix -o ../output/c_lp_sm.matriz.linkne

```

####Copio todo lo necesario al servidor para ver si desde allí funciona.
```{bash}

scp /Users/dani/ownCloud/publico/Eurasian\ lynx\ phylogeography/recent_demographic_reconstruction/LinkNe/input/*.genepop dkleinman@10.50.0.65:/home/dkleinman/LinkNe/input/
scp /Users/dani/ownCloud/publico/Eurasian\ lynx\ phylogeography/recent_demographic_reconstruction/LinkNe/input/*.map dkleinman@10.50.0.65:/home/dkleinman/LinkNe/input/
scp -r /Users/dani/ownCloud/publico/Eurasian\ lynx\ phylogeography/recent_demographic_reconstruction/LinkNe/input/LinkNe-master dkleinman@10.50.0.65:/home/dkleinman/LinkNe/input/

```

####En el servidor:
```{bash}

cd /home/dkleinman/LinkNe/input/

POPS=$(ls *.txt | cut -d'.' -f 1)
for pop in ${POPS[@]}
  do
  echo ${pop}
  SPECIES=$(echo ${pop} | cut -d'_' -f 2)
  echo "computing"
  perl LinkNe-master/LinkNe.pl -i ${pop}.genepop -map ${SPECIES}_perspecies.trimmed_filtered1.ann.${pop}_intergenic_filtered_more_than_2000_SNPS_chrA1.cat_sorted.map -o ../output/${pop}.linkne
  echo "done"
  done

```

####Ejemplos:
```{bash}

#Example 1 (using their data):
cd /Users/dani/Downloads/raw_data/simulation/main/1000_expansion_5/

perl /Users/dani/ownCloud/publico/Eurasian\ lynx\ phylogeography/recent_demographic_reconstruction/LinkNe/input/LinkNe-master/LinkNe.pl -i genepop.99.txt -m genepop.99.txt.mat -o testing.linkne #works. Fills outputs after it's done processing everything.


#Example 2 (using their data):
cd /Users/dani/ownCloud/publico/Eurasian\ lynx\ phylogeography/recent_demographic_reconstruction/LinkNe/input/
N=10000
CUT=$((N+3))
head -n $N c_lp_do_intergenic_filtered_more_than_2000_SNPs.genepop > c_lp_do_intergenic_filtered_more_than_2000_SNPs.genepop.test
sed -n '/Pop/,$p' c_lp_do_intergenic_filtered_more_than_2000_SNPs.genepop | cut -d' ' -f -$CUT >> c_lp_do_intergenic_filtered_more_than_2000_SNPs.genepop.test
head -n $N lp_perspecies.trimmed_filtered1.ann.c_lp_do_intergenic_filtered_more_than_2000_SNPS.map > lp_perspecies.trimmed_filtered1.ann.c_lp_do_intergenic_filtered_more_than_2000_SNPS.map.test 

perl LinkNe-master/LinkNe.pl -i c_lp_do_intergenic_filtered_more_than_2000_SNPs.genepop.test -map lp_perspecies.trimmed_filtered1.ann.c_lp_do_intergenic_filtered_more_than_2000_SNPS.map.test -o c_lp_do_intergenic_filtered_more_than_2000_SNPs.out.test #works but it's too slow and there's some strange warning about uninitialized genotype values...

```

##Coordenadas de gato:
###Obtención de los archivos input
####VCFs:
```{bash}

cd /GRUPOS/grupolince/lynx_genomes_5x/LinkNe/input

#En primer lugar filtramos los vcf para quedarnos con las posiciones para las que tenemos las coordenadas de gato, y además expresadas con estas coordenadas en lugar de las de lince:
INPUT_VCFS=$(ls *intergenic_filtered_more_than_2000_SNPS.vcf)
for pop in ${INPUT_VCFS[@]}
  do 
  echo ${pop}
  grep '#' ${pop} > ${pop/.vcf/.cat.vcf} #copy headers
  bedtools intersect -a /GRUPOS/grupolince/copia_fabascal/MAPPINGS/lynx2cat_wTiger.sorted.bed \
  -b ${pop} \
  -wa -wb -sorted -g /GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/Length_scaffolds_lp23_tab_separated |\
  awk -v OFS='\t' '{split($4,a1,":"); split(a1[3],a2, "-")} {$1=$2=$3=$4=$5=$6=""; print a1[2], a2[2], $0}' |\
  sed -r 's:\t+:\t:g' >> ${pop/.vcf/.cat.vcf}
  done

#A continuación ordenamos por cromosoma de gato y por posición dentro de cromosoma:
INPUT_VCFS=$(ls *intergenic_filtered_more_than_2000_SNPS.cat.vcf)
for pop in ${INPUT_VCFS[@]}
  do 
  echo ${pop}
  grep '^#' ${pop} > ${pop/.cat.vcf/.cat_sorted.vcf} && grep -v '^#' ${pop} | LC_ALL=C sort -t $'\t' -k1,1 -k2,2n >> ${pop/.cat.vcf/.cat_sorted.vcf}
  done
  
#A continuación obtenemos un subset (chrA1, y solo 20k SNPs al azar):
CHR="chrA1"
INPUT_VCFS=$(ls *intergenic_filtered_more_than_2000_SNPS.cat_sorted.vcf)
for pop in ${INPUT_VCFS[@]}
  do 
  echo ${pop}
  grep '^#' ${pop} > ${pop/SNPS.cat_sorted.vcf/SNPS_${CHR}.cat_sorted.vcf} && grep $CHR ${pop} | shuf -n 2000 | LC_ALL=C sort -t $'\t' -k1,1 -k2,2n | sed "s/$CHR/1/g" >> ${pop/SNPS.cat_sorted.vcf/SNPS_${CHR}.cat_sorted.vcf}
  done

```

####Genotipos en formato genepop:
```{bash}

#Copio los vcf con coordenadas de gato a la carpeta local para pasarlos a formato GENEPOP usando PDGSpider, versión web start (http://www.cmpg.unibe.ch/software/PGDSpider/jnlp/PGDSpider2.jnlp; si no se puede ejecutar, hay que añadir la ubicación a las excepciones de seguridad del panel de java, ubicado en preferencias de sistema de Mac):
scp -p dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/LinkNe/input/*intergenic_filtered_more_than_2000_SNPS_chrA1.cat_sorted.vcf /Users/dani/ownCloud/publico/Eurasian\ lynx\ phylogeography/recent_demographic_reconstruction/LinkNe/cat_coordinates/input

#Ahora los transformo a GENEPOP en local.

#Se suben de nuevo al servidor:
scp -p /Users/dani/ownCloud/publico/Eurasian\ lynx\ phylogeography/recent_demographic_reconstruction/LinkNe/cat_coordinates/input/*.txt dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/LinkNe/input

#Como los nombres de los SNPs son diferentes que en los map, modifico los genepop.
cd /GRUPOS/grupolince/lynx_genomes_5x/LinkNe/input
GENEPOP_LIST=$(ls *.txt)
for file in ${GENEPOP_LIST[@]}
  do
  #echo ${file}
  POP=$(echo ${file} | cut -d'.' -f 1)
  echo ${POP}
  SPECIES=$(echo ${file} | cut -d'_' -f 2)
  N_PED=$(sed '/Pop/q' ${file} | head -n -1 | wc -l)
  N_MAP=$(< ${SPECIES}_perspecies.trimmed_filtered1.ann.${POP}_intergenic_filtered_more_than_2000_SNPS_chrA1.cat_sorted.map wc -l)
  if [ $N_PED == $N_MAP ]
    then echo "correct SNP number"
    else echo "wrong SNP number"
  fi
  GENOTYPES=$(sed -n '/Pop/,$p' ${file})
  echo $POP > ${file/txt/genepop}
  tail -n +2 ${SPECIES}_perspecies.trimmed_filtered1.ann.${POP}_intergenic_filtered_more_than_2000_SNPS_chrA1.cat_sorted.map | cut -f 1 >> ${file/txt/genepop}
  echo "$GENOTYPES" >> ${file/txt/genepop}
  done

```

####Mapas genéticos:
```{bash}

cd /GRUPOS/grupolince/lynx_genomes_5x/LinkNe/input

#En primer lugar, pasamos de vcf (previamente transformados a coordenadas de gato) a bed para que los archivos sean más manejables.
INPUT_VCFS=$(ls *intergenic_filtered_more_than_2000_SNPS_chrA1.cat_sorted.vcf)
for vcf in ${INPUT_VCFS[@]}
  do
  POP=$(echo ${vcf} | cut -d'.' -f 4 | cut -d'_' -f-3)
  echo ${POP}
  grep -v '#' ${vcf} | awk -F"\t" '{printf ("%s\t%s\t%s\n", $1,$2-1,$2)}' > ${vcf/.vcf/.bed}
  done

#A continuación, obtenemos el map a partir del bed.
INPUT_BEDS=$(ls *intergenic_filtered_more_than_2000_SNPS_chrA1.cat_sorted.bed)
for pop in ${INPUT_BEDS[@]}
  do 
  #echo ${pop}
  echo -e "locus\tchromosome\tposition" > ${pop/.bed/.map}
  POP=$(echo ${pop} | cut -d'.' -f 4 | cut -d'_' -f-3)
  echo ${POP}
  LC_NUMERIC=C awk -F"\t" '{printf ("%s_%s\t%s\t%.9f\n", $1,$3,$1,$3*0.0000019)}' ${pop} | sed 's/lp23\.s//g' >> ${pop/.bed/.map} #1.9cM/Mb means 1.9cM for 10^6bp, which means 1.9*10^-6cM/bp.
  #LC_NUMERIC=C to force a dot as the decimal separator. Otherwise it will print commas even though I've set my mac to use dots as the default... 
  done

```

###Ejecución del programa:
####En el servidor:
```{bash}

#Preparar archivos y carpetas:
cd /home/dkleinman/LinkNe/input/

scp -p /GRUPOS/grupolince/lynx_genomes_5x/LinkNe/input/*.txt ./
scp -p /GRUPOS/grupolince/lynx_genomes_5x/LinkNe/input/*.genepop ./
scp -p /GRUPOS/grupolince/lynx_genomes_5x/LinkNe/input/*_chrA1.cat_sorted.* ./

POPS=$(ls c_*.txt | cut -d'.' -f 1)
for pop in ${POPS[@]}
  do
  echo ${pop}
  mkdir ${pop}
  mv *${pop}* ${pop}
  done

#Lanzar las 4 primeras poblaciones:
cd /home/dkleinman/LinkNe/input/
screen -S linkne_chrA1_2k_snps_batch1.log
script linkne_chrA1_2k_snps_batch1.log

POPS=$(ls -d c_* | head -n4)
for pop in ${POPS[@]}
  do
  echo ${pop}
  cd ${pop}
  SPECIES=$(echo ${pop} | cut -d'_' -f 2)
  echo "computing"
  perl ../LinkNe-master/LinkNe.pl -t -i ${pop}.genepop -map ${SPECIES}_perspecies.trimmed_filtered1.ann.${pop}_intergenic_filtered_more_than_2000_SNPS_chrA1.cat_sorted.map -o ${pop}.linkne
  echo "done"
  cd /home/dkleinman/LinkNe/input/
  done

#Lanzar las 4 siguientes poblaciones:
cd /home/dkleinman/LinkNe/input/
screen -S linkne_chrA1_2k_snps_batch2.log
script linkne_chrA1_2k_snps_batch2.log

POPS=$(ls -d c_* | tail -n +5 | head -n4)
for pop in ${POPS[@]}
  do
  echo ${pop}
  cd ${pop}
  SPECIES=$(echo ${pop} | cut -d'_' -f 2)
  echo "computing"
  perl ../LinkNe-master/LinkNe.pl -t -i ${pop}.genepop -map ${SPECIES}_perspecies.trimmed_filtered1.ann.${pop}_intergenic_filtered_more_than_2000_SNPS_chrA1.cat_sorted.map -o ${pop}.linkne
  echo "done"
  cd /home/dkleinman/LinkNe/input/
  done

#Lanzar las 5 últimas poblaciones:
cd /home/dkleinman/LinkNe/input/
screen -S linkne_chrA1_2k_snps_batch3.log
script linkne_chrA1_2k_snps_batch3.log

POPS=$(ls -d c_* | tail -n 5)
for pop in ${POPS[@]}
  do
  echo ${pop}
  cd ${pop}
  SPECIES=$(echo ${pop} | cut -d'_' -f 2)
  echo "computing"
  perl ../LinkNe-master/LinkNe.pl -t -i ${pop}.genepop -map ${SPECIES}_perspecies.trimmed_filtered1.ann.${pop}_intergenic_filtered_more_than_2000_SNPS_chrA1.cat_sorted.map -o ${pop}.linkne
  echo "done"
  cd /home/dkleinman/LinkNe/input/
  done

```
